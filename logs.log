2023-11-23 01:01:36,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:01:36,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:01:36,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:01:36,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:01:36,903:INFO:PyCaret RegressionExperiment
2023-11-23 01:01:36,903:INFO:Logging name: reg-default-name
2023-11-23 01:01:36,903:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-23 01:01:36,903:INFO:version 3.1.0
2023-11-23 01:01:36,903:INFO:Initializing setup()
2023-11-23 01:01:36,903:INFO:self.USI: 7a1b
2023-11-23 01:01:36,903:INFO:self._variable_keys: {'html_param', 'log_plots_param', 'fold_groups_param', 'data', 'y_train', 'fold_generator', 'X_test', 'target_param', 'gpu_param', 'gpu_n_jobs_param', '_available_plots', 'n_jobs_param', 'exp_id', 'exp_name_log', 'X_train', 'y_test', 'memory', 'logging_param', 'fold_shuffle_param', 'X', '_ml_usecase', 'idx', 'pipeline', 'USI', 'seed', 'y', 'transform_target_param'}
2023-11-23 01:01:36,903:INFO:Checking environment
2023-11-23 01:01:36,903:INFO:python_version: 3.9.16
2023-11-23 01:01:36,903:INFO:python_build: ('main', 'Nov  2 2023 14:11:49')
2023-11-23 01:01:36,903:INFO:machine: arm64
2023-11-23 01:01:36,903:INFO:platform: macOS-13.4.1-arm64-arm-64bit
2023-11-23 01:01:36,903:INFO:Memory: svmem(total=8589934592, available=2060877824, percent=76.0, used=3637886976, free=68698112, active=2004680704, inactive=1962033152, wired=1633206272)
2023-11-23 01:01:36,903:INFO:Physical Core: 8
2023-11-23 01:01:36,903:INFO:Logical Core: 8
2023-11-23 01:01:36,903:INFO:Checking libraries
2023-11-23 01:01:36,903:INFO:System:
2023-11-23 01:01:36,903:INFO:    python: 3.9.16 (main, Nov  2 2023, 14:11:49)  [Clang 14.0.3 (clang-1403.0.22.14.1)]
2023-11-23 01:01:36,903:INFO:executable: /Users/macOs/.pyenv/versions/3.9.16/bin/python
2023-11-23 01:01:36,903:INFO:   machine: macOS-13.4.1-arm64-arm-64bit
2023-11-23 01:01:36,903:INFO:PyCaret required dependencies:
2023-11-23 01:01:36,919:INFO:                 pip: 22.0.4
2023-11-23 01:01:36,919:INFO:          setuptools: 58.1.0
2023-11-23 01:01:36,919:INFO:             pycaret: 3.1.0
2023-11-23 01:01:36,919:INFO:             IPython: 8.17.2
2023-11-23 01:01:36,919:INFO:          ipywidgets: 8.1.1
2023-11-23 01:01:36,919:INFO:                tqdm: 4.66.1
2023-11-23 01:01:36,919:INFO:               numpy: 1.23.5
2023-11-23 01:01:36,919:INFO:              pandas: 1.5.3
2023-11-23 01:01:36,919:INFO:              jinja2: 3.1.2
2023-11-23 01:01:36,920:INFO:               scipy: 1.10.1
2023-11-23 01:01:36,920:INFO:              joblib: 1.3.2
2023-11-23 01:01:36,920:INFO:             sklearn: 1.2.2
2023-11-23 01:01:36,920:INFO:                pyod: 1.1.1
2023-11-23 01:01:36,920:INFO:            imblearn: 0.11.0
2023-11-23 01:01:36,920:INFO:   category_encoders: 2.6.3
2023-11-23 01:01:36,920:INFO:            lightgbm: 4.1.0
2023-11-23 01:01:36,920:INFO:               numba: 0.58.1
2023-11-23 01:01:36,920:INFO:            requests: 2.31.0
2023-11-23 01:01:36,920:INFO:          matplotlib: 3.8.1
2023-11-23 01:01:36,920:INFO:          scikitplot: 0.3.7
2023-11-23 01:01:36,920:INFO:         yellowbrick: 1.5
2023-11-23 01:01:36,920:INFO:              plotly: 5.18.0
2023-11-23 01:01:36,920:INFO:    plotly-resampler: Not installed
2023-11-23 01:01:36,920:INFO:             kaleido: 0.2.1
2023-11-23 01:01:36,920:INFO:           schemdraw: 0.15
2023-11-23 01:01:36,920:INFO:         statsmodels: 0.14.0
2023-11-23 01:01:36,920:INFO:              sktime: 0.21.1
2023-11-23 01:01:36,920:INFO:               tbats: 1.1.3
2023-11-23 01:01:36,920:INFO:            pmdarima: 2.0.4
2023-11-23 01:01:36,920:INFO:              psutil: 5.9.6
2023-11-23 01:01:36,920:INFO:          markupsafe: 2.1.3
2023-11-23 01:01:36,920:INFO:             pickle5: Not installed
2023-11-23 01:01:36,920:INFO:         cloudpickle: 3.0.0
2023-11-23 01:01:36,920:INFO:         deprecation: 2.1.0
2023-11-23 01:01:36,920:INFO:              xxhash: 3.4.1
2023-11-23 01:01:36,920:INFO:           wurlitzer: 3.0.3
2023-11-23 01:01:36,920:INFO:PyCaret optional dependencies:
2023-11-23 01:01:36,926:INFO:                shap: Not installed
2023-11-23 01:01:36,926:INFO:           interpret: Not installed
2023-11-23 01:01:36,926:INFO:                umap: Not installed
2023-11-23 01:01:36,926:INFO:     ydata_profiling: Not installed
2023-11-23 01:01:36,926:INFO:  explainerdashboard: Not installed
2023-11-23 01:01:36,926:INFO:             autoviz: Not installed
2023-11-23 01:01:36,926:INFO:           fairlearn: Not installed
2023-11-23 01:01:36,926:INFO:          deepchecks: Not installed
2023-11-23 01:01:36,926:INFO:             xgboost: 2.0.2
2023-11-23 01:01:36,926:INFO:            catboost: Not installed
2023-11-23 01:01:36,926:INFO:              kmodes: Not installed
2023-11-23 01:01:36,926:INFO:             mlxtend: Not installed
2023-11-23 01:01:36,926:INFO:       statsforecast: Not installed
2023-11-23 01:01:36,926:INFO:        tune_sklearn: Not installed
2023-11-23 01:01:36,926:INFO:                 ray: Not installed
2023-11-23 01:01:36,926:INFO:            hyperopt: Not installed
2023-11-23 01:01:36,926:INFO:              optuna: Not installed
2023-11-23 01:01:36,926:INFO:               skopt: Not installed
2023-11-23 01:01:36,926:INFO:              mlflow: Not installed
2023-11-23 01:01:36,926:INFO:              gradio: Not installed
2023-11-23 01:01:36,926:INFO:             fastapi: Not installed
2023-11-23 01:01:36,926:INFO:             uvicorn: Not installed
2023-11-23 01:01:36,926:INFO:              m2cgen: Not installed
2023-11-23 01:01:36,926:INFO:           evidently: Not installed
2023-11-23 01:01:36,926:INFO:               fugue: Not installed
2023-11-23 01:01:36,926:INFO:           streamlit: Not installed
2023-11-23 01:01:36,926:INFO:             prophet: Not installed
2023-11-23 01:01:36,926:INFO:None
2023-11-23 01:01:36,926:INFO:Set up data.
2023-11-23 01:01:36,930:INFO:Set up folding strategy.
2023-11-23 01:01:36,930:INFO:Set up train/test split.
2023-11-23 01:01:36,933:INFO:Set up index.
2023-11-23 01:01:36,933:INFO:Assigning column types.
2023-11-23 01:01:36,934:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-23 01:01:36,934:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 01:01:36,936:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:01:36,938:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:01:36,964:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:01:36,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:01:36,984:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:36,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:36,985:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 01:01:36,987:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:01:36,989:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,014:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,033:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,035:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-23 01:01:37,037:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,064:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,085:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,086:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,088:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,090:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,116:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,136:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,136:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,137:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,138:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-23 01:01:37,142:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,187:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,187:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,192:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,237:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,238:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,239:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,239:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-23 01:01:37,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,288:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,319:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,338:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,341:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-23 01:01:37,370:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,390:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,420:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:01:37,439:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,440:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-23 01:01:37,490:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,541:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,544:INFO:Set up custom pipeline.
2023-11-23 01:01:37,553:INFO:Finished creating preprocessing pipeline.
2023-11-23 01:01:37,575:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/8h/q7dbs5196q9fcktcxkc2__dh0000gn/T/joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))])))])
2023-11-23 01:01:37,575:INFO:Creating final display dataframe.
2023-11-23 01:01:37,609:INFO:Setup _display_container:                    Description             Value
0                   Session id               123
1                       Target  MedianHouseValue
2                  Target type        Regression
3          Original data shape        (7560, 10)
4       Transformed data shape        (7560, 13)
5  Transformed train set shape        (5292, 13)
6   Transformed test set shape        (2268, 13)
7             Numeric features                 8
8         Categorical features                 1
2023-11-23 01:01:37,662:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,713:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:01:37,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:01:37,714:INFO:setup() successfully completed in 0.81s...............
2023-11-23 01:01:37,719:INFO:Initializing compare_models()
2023-11-23 01:01:37,719:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-23 01:01:37,719:INFO:Checking exceptions
2023-11-23 01:01:37,720:INFO:Preparing display monitor
2023-11-23 01:01:37,742:INFO:Initializing Linear Regression
2023-11-23 01:01:37,742:INFO:Total runtime is 3.5683314005533854e-06 minutes
2023-11-23 01:01:37,743:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:37,744:INFO:Initializing create_model()
2023-11-23 01:01:37,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:37,744:INFO:Checking exceptions
2023-11-23 01:01:37,744:INFO:Importing libraries
2023-11-23 01:01:37,744:INFO:Copying training dataset
2023-11-23 01:01:37,748:INFO:Defining folds
2023-11-23 01:01:37,748:INFO:Declaring metric variables
2023-11-23 01:01:37,750:INFO:Importing untrained model
2023-11-23 01:01:37,752:INFO:Linear Regression Imported successfully
2023-11-23 01:01:37,756:INFO:Starting cross validation
2023-11-23 01:01:37,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:39,571:INFO:Calculating mean and std
2023-11-23 01:01:39,575:INFO:Creating metrics dataframe
2023-11-23 01:01:39,581:INFO:Uploading results into container
2023-11-23 01:01:39,581:INFO:Uploading model into container now
2023-11-23 01:01:39,582:INFO:_master_model_container: 1
2023-11-23 01:01:39,582:INFO:_display_container: 2
2023-11-23 01:01:39,583:INFO:LinearRegression(n_jobs=-1)
2023-11-23 01:01:39,583:INFO:create_model() successfully completed......................................
2023-11-23 01:01:39,660:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:39,660:INFO:Creating metrics dataframe
2023-11-23 01:01:39,664:INFO:Initializing Lasso Regression
2023-11-23 01:01:39,664:INFO:Total runtime is 0.032044267654418944 minutes
2023-11-23 01:01:39,666:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:39,666:INFO:Initializing create_model()
2023-11-23 01:01:39,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:39,666:INFO:Checking exceptions
2023-11-23 01:01:39,666:INFO:Importing libraries
2023-11-23 01:01:39,666:INFO:Copying training dataset
2023-11-23 01:01:39,668:INFO:Defining folds
2023-11-23 01:01:39,668:INFO:Declaring metric variables
2023-11-23 01:01:39,670:INFO:Importing untrained model
2023-11-23 01:01:39,671:INFO:Lasso Regression Imported successfully
2023-11-23 01:01:39,674:INFO:Starting cross validation
2023-11-23 01:01:39,675:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:39,779:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.169e+11, tolerance: 4.122e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:01:39,779:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.084e+11, tolerance: 4.143e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:01:39,789:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.205e+11, tolerance: 4.189e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:01:39,794:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.344e+11, tolerance: 4.125e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:01:39,795:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.235e+11, tolerance: 4.117e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:01:39,811:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.019e+11, tolerance: 4.116e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:01:39,812:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.174e+11, tolerance: 4.140e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:01:39,822:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.134e+11, tolerance: 4.121e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:01:39,863:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.070e+11, tolerance: 4.120e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:01:39,869:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.060e+11, tolerance: 4.135e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:01:39,885:INFO:Calculating mean and std
2023-11-23 01:01:39,885:INFO:Creating metrics dataframe
2023-11-23 01:01:39,887:INFO:Uploading results into container
2023-11-23 01:01:39,887:INFO:Uploading model into container now
2023-11-23 01:01:39,887:INFO:_master_model_container: 2
2023-11-23 01:01:39,887:INFO:_display_container: 2
2023-11-23 01:01:39,887:INFO:Lasso(random_state=123)
2023-11-23 01:01:39,887:INFO:create_model() successfully completed......................................
2023-11-23 01:01:39,932:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:39,932:INFO:Creating metrics dataframe
2023-11-23 01:01:39,937:INFO:Initializing Ridge Regression
2023-11-23 01:01:39,938:INFO:Total runtime is 0.03659987052281698 minutes
2023-11-23 01:01:39,939:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:39,939:INFO:Initializing create_model()
2023-11-23 01:01:39,939:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:39,939:INFO:Checking exceptions
2023-11-23 01:01:39,939:INFO:Importing libraries
2023-11-23 01:01:39,939:INFO:Copying training dataset
2023-11-23 01:01:39,941:INFO:Defining folds
2023-11-23 01:01:39,941:INFO:Declaring metric variables
2023-11-23 01:01:39,942:INFO:Importing untrained model
2023-11-23 01:01:39,944:INFO:Ridge Regression Imported successfully
2023-11-23 01:01:39,946:INFO:Starting cross validation
2023-11-23 01:01:39,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:40,005:INFO:Calculating mean and std
2023-11-23 01:01:40,005:INFO:Creating metrics dataframe
2023-11-23 01:01:40,007:INFO:Uploading results into container
2023-11-23 01:01:40,007:INFO:Uploading model into container now
2023-11-23 01:01:40,007:INFO:_master_model_container: 3
2023-11-23 01:01:40,007:INFO:_display_container: 2
2023-11-23 01:01:40,007:INFO:Ridge(random_state=123)
2023-11-23 01:01:40,007:INFO:create_model() successfully completed......................................
2023-11-23 01:01:40,052:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:40,052:INFO:Creating metrics dataframe
2023-11-23 01:01:40,056:INFO:Initializing Elastic Net
2023-11-23 01:01:40,057:INFO:Total runtime is 0.038582154115041095 minutes
2023-11-23 01:01:40,058:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:40,058:INFO:Initializing create_model()
2023-11-23 01:01:40,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:40,058:INFO:Checking exceptions
2023-11-23 01:01:40,058:INFO:Importing libraries
2023-11-23 01:01:40,059:INFO:Copying training dataset
2023-11-23 01:01:40,061:INFO:Defining folds
2023-11-23 01:01:40,061:INFO:Declaring metric variables
2023-11-23 01:01:40,062:INFO:Importing untrained model
2023-11-23 01:01:40,063:INFO:Elastic Net Imported successfully
2023-11-23 01:01:40,066:INFO:Starting cross validation
2023-11-23 01:01:40,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:40,133:INFO:Calculating mean and std
2023-11-23 01:01:40,134:INFO:Creating metrics dataframe
2023-11-23 01:01:40,136:INFO:Uploading results into container
2023-11-23 01:01:40,136:INFO:Uploading model into container now
2023-11-23 01:01:40,136:INFO:_master_model_container: 4
2023-11-23 01:01:40,136:INFO:_display_container: 2
2023-11-23 01:01:40,136:INFO:ElasticNet(random_state=123)
2023-11-23 01:01:40,136:INFO:create_model() successfully completed......................................
2023-11-23 01:01:40,181:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:40,181:INFO:Creating metrics dataframe
2023-11-23 01:01:40,185:INFO:Initializing Least Angle Regression
2023-11-23 01:01:40,185:INFO:Total runtime is 0.04073065121968587 minutes
2023-11-23 01:01:40,187:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:40,187:INFO:Initializing create_model()
2023-11-23 01:01:40,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:40,187:INFO:Checking exceptions
2023-11-23 01:01:40,187:INFO:Importing libraries
2023-11-23 01:01:40,187:INFO:Copying training dataset
2023-11-23 01:01:40,189:INFO:Defining folds
2023-11-23 01:01:40,189:INFO:Declaring metric variables
2023-11-23 01:01:40,190:INFO:Importing untrained model
2023-11-23 01:01:40,192:INFO:Least Angle Regression Imported successfully
2023-11-23 01:01:40,194:INFO:Starting cross validation
2023-11-23 01:01:40,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:40,251:INFO:Calculating mean and std
2023-11-23 01:01:40,252:INFO:Creating metrics dataframe
2023-11-23 01:01:40,253:INFO:Uploading results into container
2023-11-23 01:01:40,254:INFO:Uploading model into container now
2023-11-23 01:01:40,254:INFO:_master_model_container: 5
2023-11-23 01:01:40,254:INFO:_display_container: 2
2023-11-23 01:01:40,254:INFO:Lars(random_state=123)
2023-11-23 01:01:40,254:INFO:create_model() successfully completed......................................
2023-11-23 01:01:40,299:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:40,299:INFO:Creating metrics dataframe
2023-11-23 01:01:40,303:INFO:Initializing Lasso Least Angle Regression
2023-11-23 01:01:40,304:INFO:Total runtime is 0.04269996881484985 minutes
2023-11-23 01:01:40,305:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:40,305:INFO:Initializing create_model()
2023-11-23 01:01:40,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:40,305:INFO:Checking exceptions
2023-11-23 01:01:40,306:INFO:Importing libraries
2023-11-23 01:01:40,306:INFO:Copying training dataset
2023-11-23 01:01:40,308:INFO:Defining folds
2023-11-23 01:01:40,308:INFO:Declaring metric variables
2023-11-23 01:01:40,309:INFO:Importing untrained model
2023-11-23 01:01:40,311:INFO:Lasso Least Angle Regression Imported successfully
2023-11-23 01:01:40,313:INFO:Starting cross validation
2023-11-23 01:01:40,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:40,370:INFO:Calculating mean and std
2023-11-23 01:01:40,371:INFO:Creating metrics dataframe
2023-11-23 01:01:40,372:INFO:Uploading results into container
2023-11-23 01:01:40,373:INFO:Uploading model into container now
2023-11-23 01:01:40,373:INFO:_master_model_container: 6
2023-11-23 01:01:40,373:INFO:_display_container: 2
2023-11-23 01:01:40,373:INFO:LassoLars(random_state=123)
2023-11-23 01:01:40,373:INFO:create_model() successfully completed......................................
2023-11-23 01:01:40,417:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:40,417:INFO:Creating metrics dataframe
2023-11-23 01:01:40,421:INFO:Initializing Orthogonal Matching Pursuit
2023-11-23 01:01:40,422:INFO:Total runtime is 0.04466748634974162 minutes
2023-11-23 01:01:40,423:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:40,423:INFO:Initializing create_model()
2023-11-23 01:01:40,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:40,423:INFO:Checking exceptions
2023-11-23 01:01:40,423:INFO:Importing libraries
2023-11-23 01:01:40,423:INFO:Copying training dataset
2023-11-23 01:01:40,425:INFO:Defining folds
2023-11-23 01:01:40,425:INFO:Declaring metric variables
2023-11-23 01:01:40,426:INFO:Importing untrained model
2023-11-23 01:01:40,428:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-23 01:01:40,430:INFO:Starting cross validation
2023-11-23 01:01:40,431:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:40,490:INFO:Calculating mean and std
2023-11-23 01:01:40,491:INFO:Creating metrics dataframe
2023-11-23 01:01:40,492:INFO:Uploading results into container
2023-11-23 01:01:40,492:INFO:Uploading model into container now
2023-11-23 01:01:40,493:INFO:_master_model_container: 7
2023-11-23 01:01:40,493:INFO:_display_container: 2
2023-11-23 01:01:40,493:INFO:OrthogonalMatchingPursuit()
2023-11-23 01:01:40,493:INFO:create_model() successfully completed......................................
2023-11-23 01:01:40,538:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:40,538:INFO:Creating metrics dataframe
2023-11-23 01:01:40,544:INFO:Initializing Bayesian Ridge
2023-11-23 01:01:40,544:INFO:Total runtime is 0.046709418296813965 minutes
2023-11-23 01:01:40,546:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:40,547:INFO:Initializing create_model()
2023-11-23 01:01:40,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:40,547:INFO:Checking exceptions
2023-11-23 01:01:40,547:INFO:Importing libraries
2023-11-23 01:01:40,547:INFO:Copying training dataset
2023-11-23 01:01:40,550:INFO:Defining folds
2023-11-23 01:01:40,550:INFO:Declaring metric variables
2023-11-23 01:01:40,551:INFO:Importing untrained model
2023-11-23 01:01:40,553:INFO:Bayesian Ridge Imported successfully
2023-11-23 01:01:40,557:INFO:Starting cross validation
2023-11-23 01:01:40,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:40,635:INFO:Calculating mean and std
2023-11-23 01:01:40,636:INFO:Creating metrics dataframe
2023-11-23 01:01:40,638:INFO:Uploading results into container
2023-11-23 01:01:40,639:INFO:Uploading model into container now
2023-11-23 01:01:40,639:INFO:_master_model_container: 8
2023-11-23 01:01:40,639:INFO:_display_container: 2
2023-11-23 01:01:40,639:INFO:BayesianRidge()
2023-11-23 01:01:40,639:INFO:create_model() successfully completed......................................
2023-11-23 01:01:40,692:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:40,692:INFO:Creating metrics dataframe
2023-11-23 01:01:40,697:INFO:Initializing Passive Aggressive Regressor
2023-11-23 01:01:40,697:INFO:Total runtime is 0.04925891955693563 minutes
2023-11-23 01:01:40,698:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:40,699:INFO:Initializing create_model()
2023-11-23 01:01:40,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:40,699:INFO:Checking exceptions
2023-11-23 01:01:40,699:INFO:Importing libraries
2023-11-23 01:01:40,699:INFO:Copying training dataset
2023-11-23 01:01:40,701:INFO:Defining folds
2023-11-23 01:01:40,701:INFO:Declaring metric variables
2023-11-23 01:01:40,702:INFO:Importing untrained model
2023-11-23 01:01:40,704:INFO:Passive Aggressive Regressor Imported successfully
2023-11-23 01:01:40,708:INFO:Starting cross validation
2023-11-23 01:01:40,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:40,806:INFO:Calculating mean and std
2023-11-23 01:01:40,806:INFO:Creating metrics dataframe
2023-11-23 01:01:40,808:INFO:Uploading results into container
2023-11-23 01:01:40,808:INFO:Uploading model into container now
2023-11-23 01:01:40,808:INFO:_master_model_container: 9
2023-11-23 01:01:40,808:INFO:_display_container: 2
2023-11-23 01:01:40,808:INFO:PassiveAggressiveRegressor(random_state=123)
2023-11-23 01:01:40,808:INFO:create_model() successfully completed......................................
2023-11-23 01:01:40,858:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:40,858:INFO:Creating metrics dataframe
2023-11-23 01:01:40,863:INFO:Initializing Huber Regressor
2023-11-23 01:01:40,863:INFO:Total runtime is 0.05201840400695801 minutes
2023-11-23 01:01:40,864:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:40,865:INFO:Initializing create_model()
2023-11-23 01:01:40,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:40,865:INFO:Checking exceptions
2023-11-23 01:01:40,865:INFO:Importing libraries
2023-11-23 01:01:40,865:INFO:Copying training dataset
2023-11-23 01:01:40,867:INFO:Defining folds
2023-11-23 01:01:40,868:INFO:Declaring metric variables
2023-11-23 01:01:40,869:INFO:Importing untrained model
2023-11-23 01:01:40,871:INFO:Huber Regressor Imported successfully
2023-11-23 01:01:40,873:INFO:Starting cross validation
2023-11-23 01:01:40,874:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:40,964:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:01:40,964:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:01:40,964:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:01:40,972:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:01:40,974:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:01:40,975:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:01:40,992:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:01:40,996:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:01:41,024:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:01:41,028:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:01:41,034:INFO:Calculating mean and std
2023-11-23 01:01:41,035:INFO:Creating metrics dataframe
2023-11-23 01:01:41,037:INFO:Uploading results into container
2023-11-23 01:01:41,038:INFO:Uploading model into container now
2023-11-23 01:01:41,038:INFO:_master_model_container: 10
2023-11-23 01:01:41,038:INFO:_display_container: 2
2023-11-23 01:01:41,038:INFO:HuberRegressor()
2023-11-23 01:01:41,038:INFO:create_model() successfully completed......................................
2023-11-23 01:01:41,090:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:41,090:INFO:Creating metrics dataframe
2023-11-23 01:01:41,095:INFO:Initializing K Neighbors Regressor
2023-11-23 01:01:41,095:INFO:Total runtime is 0.05589543183644612 minutes
2023-11-23 01:01:41,097:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:41,097:INFO:Initializing create_model()
2023-11-23 01:01:41,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:41,097:INFO:Checking exceptions
2023-11-23 01:01:41,097:INFO:Importing libraries
2023-11-23 01:01:41,097:INFO:Copying training dataset
2023-11-23 01:01:41,099:INFO:Defining folds
2023-11-23 01:01:41,099:INFO:Declaring metric variables
2023-11-23 01:01:41,101:INFO:Importing untrained model
2023-11-23 01:01:41,103:INFO:K Neighbors Regressor Imported successfully
2023-11-23 01:01:41,106:INFO:Starting cross validation
2023-11-23 01:01:41,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:41,192:INFO:Calculating mean and std
2023-11-23 01:01:41,192:INFO:Creating metrics dataframe
2023-11-23 01:01:41,194:INFO:Uploading results into container
2023-11-23 01:01:41,194:INFO:Uploading model into container now
2023-11-23 01:01:41,194:INFO:_master_model_container: 11
2023-11-23 01:01:41,194:INFO:_display_container: 2
2023-11-23 01:01:41,194:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-23 01:01:41,194:INFO:create_model() successfully completed......................................
2023-11-23 01:01:41,239:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:41,239:INFO:Creating metrics dataframe
2023-11-23 01:01:41,244:INFO:Initializing Decision Tree Regressor
2023-11-23 01:01:41,244:INFO:Total runtime is 0.05837331612904866 minutes
2023-11-23 01:01:41,246:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:41,246:INFO:Initializing create_model()
2023-11-23 01:01:41,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:41,246:INFO:Checking exceptions
2023-11-23 01:01:41,246:INFO:Importing libraries
2023-11-23 01:01:41,246:INFO:Copying training dataset
2023-11-23 01:01:41,248:INFO:Defining folds
2023-11-23 01:01:41,248:INFO:Declaring metric variables
2023-11-23 01:01:41,249:INFO:Importing untrained model
2023-11-23 01:01:41,250:INFO:Decision Tree Regressor Imported successfully
2023-11-23 01:01:41,253:INFO:Starting cross validation
2023-11-23 01:01:41,254:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:41,375:INFO:Calculating mean and std
2023-11-23 01:01:41,376:INFO:Creating metrics dataframe
2023-11-23 01:01:41,377:INFO:Uploading results into container
2023-11-23 01:01:41,378:INFO:Uploading model into container now
2023-11-23 01:01:41,378:INFO:_master_model_container: 12
2023-11-23 01:01:41,378:INFO:_display_container: 2
2023-11-23 01:01:41,378:INFO:DecisionTreeRegressor(random_state=123)
2023-11-23 01:01:41,378:INFO:create_model() successfully completed......................................
2023-11-23 01:01:41,423:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:41,423:INFO:Creating metrics dataframe
2023-11-23 01:01:41,429:INFO:Initializing Random Forest Regressor
2023-11-23 01:01:41,429:INFO:Total runtime is 0.06145166953404744 minutes
2023-11-23 01:01:41,430:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:41,430:INFO:Initializing create_model()
2023-11-23 01:01:41,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:41,430:INFO:Checking exceptions
2023-11-23 01:01:41,430:INFO:Importing libraries
2023-11-23 01:01:41,430:INFO:Copying training dataset
2023-11-23 01:01:41,433:INFO:Defining folds
2023-11-23 01:01:41,433:INFO:Declaring metric variables
2023-11-23 01:01:41,434:INFO:Importing untrained model
2023-11-23 01:01:41,435:INFO:Random Forest Regressor Imported successfully
2023-11-23 01:01:41,438:INFO:Starting cross validation
2023-11-23 01:01:41,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:44,904:INFO:Calculating mean and std
2023-11-23 01:01:44,905:INFO:Creating metrics dataframe
2023-11-23 01:01:44,907:INFO:Uploading results into container
2023-11-23 01:01:44,907:INFO:Uploading model into container now
2023-11-23 01:01:44,908:INFO:_master_model_container: 13
2023-11-23 01:01:44,908:INFO:_display_container: 2
2023-11-23 01:01:44,908:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:01:44,908:INFO:create_model() successfully completed......................................
2023-11-23 01:01:44,964:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:44,964:INFO:Creating metrics dataframe
2023-11-23 01:01:44,971:INFO:Initializing Extra Trees Regressor
2023-11-23 01:01:44,971:INFO:Total runtime is 0.12048931916554768 minutes
2023-11-23 01:01:44,973:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:44,974:INFO:Initializing create_model()
2023-11-23 01:01:44,974:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:44,974:INFO:Checking exceptions
2023-11-23 01:01:44,974:INFO:Importing libraries
2023-11-23 01:01:44,974:INFO:Copying training dataset
2023-11-23 01:01:44,976:INFO:Defining folds
2023-11-23 01:01:44,976:INFO:Declaring metric variables
2023-11-23 01:01:44,977:INFO:Importing untrained model
2023-11-23 01:01:44,978:INFO:Extra Trees Regressor Imported successfully
2023-11-23 01:01:44,981:INFO:Starting cross validation
2023-11-23 01:01:44,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:46,707:INFO:Calculating mean and std
2023-11-23 01:01:46,709:INFO:Creating metrics dataframe
2023-11-23 01:01:46,712:INFO:Uploading results into container
2023-11-23 01:01:46,713:INFO:Uploading model into container now
2023-11-23 01:01:46,713:INFO:_master_model_container: 14
2023-11-23 01:01:46,713:INFO:_display_container: 2
2023-11-23 01:01:46,713:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:01:46,713:INFO:create_model() successfully completed......................................
2023-11-23 01:01:46,785:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:46,785:INFO:Creating metrics dataframe
2023-11-23 01:01:46,791:INFO:Initializing AdaBoost Regressor
2023-11-23 01:01:46,791:INFO:Total runtime is 0.15082660516103108 minutes
2023-11-23 01:01:46,793:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:46,793:INFO:Initializing create_model()
2023-11-23 01:01:46,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:46,793:INFO:Checking exceptions
2023-11-23 01:01:46,793:INFO:Importing libraries
2023-11-23 01:01:46,793:INFO:Copying training dataset
2023-11-23 01:01:46,795:INFO:Defining folds
2023-11-23 01:01:46,795:INFO:Declaring metric variables
2023-11-23 01:01:46,797:INFO:Importing untrained model
2023-11-23 01:01:46,798:INFO:AdaBoost Regressor Imported successfully
2023-11-23 01:01:46,801:INFO:Starting cross validation
2023-11-23 01:01:46,801:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:47,294:INFO:Calculating mean and std
2023-11-23 01:01:47,295:INFO:Creating metrics dataframe
2023-11-23 01:01:47,297:INFO:Uploading results into container
2023-11-23 01:01:47,297:INFO:Uploading model into container now
2023-11-23 01:01:47,297:INFO:_master_model_container: 15
2023-11-23 01:01:47,297:INFO:_display_container: 2
2023-11-23 01:01:47,297:INFO:AdaBoostRegressor(random_state=123)
2023-11-23 01:01:47,297:INFO:create_model() successfully completed......................................
2023-11-23 01:01:47,342:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:47,343:INFO:Creating metrics dataframe
2023-11-23 01:01:47,348:INFO:Initializing Gradient Boosting Regressor
2023-11-23 01:01:47,348:INFO:Total runtime is 0.16011328697204588 minutes
2023-11-23 01:01:47,350:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:47,350:INFO:Initializing create_model()
2023-11-23 01:01:47,350:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:47,350:INFO:Checking exceptions
2023-11-23 01:01:47,350:INFO:Importing libraries
2023-11-23 01:01:47,350:INFO:Copying training dataset
2023-11-23 01:01:47,353:INFO:Defining folds
2023-11-23 01:01:47,353:INFO:Declaring metric variables
2023-11-23 01:01:47,354:INFO:Importing untrained model
2023-11-23 01:01:47,355:INFO:Gradient Boosting Regressor Imported successfully
2023-11-23 01:01:47,358:INFO:Starting cross validation
2023-11-23 01:01:47,358:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:49,122:INFO:Calculating mean and std
2023-11-23 01:01:49,122:INFO:Creating metrics dataframe
2023-11-23 01:01:49,124:INFO:Uploading results into container
2023-11-23 01:01:49,124:INFO:Uploading model into container now
2023-11-23 01:01:49,124:INFO:_master_model_container: 16
2023-11-23 01:01:49,124:INFO:_display_container: 2
2023-11-23 01:01:49,124:INFO:GradientBoostingRegressor(random_state=123)
2023-11-23 01:01:49,124:INFO:create_model() successfully completed......................................
2023-11-23 01:01:49,172:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:49,172:INFO:Creating metrics dataframe
2023-11-23 01:01:49,177:INFO:Initializing Extreme Gradient Boosting
2023-11-23 01:01:49,178:INFO:Total runtime is 0.19060064951578776 minutes
2023-11-23 01:01:49,179:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:49,179:INFO:Initializing create_model()
2023-11-23 01:01:49,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:49,180:INFO:Checking exceptions
2023-11-23 01:01:49,180:INFO:Importing libraries
2023-11-23 01:01:49,180:INFO:Copying training dataset
2023-11-23 01:01:49,182:INFO:Defining folds
2023-11-23 01:01:49,182:INFO:Declaring metric variables
2023-11-23 01:01:49,183:INFO:Importing untrained model
2023-11-23 01:01:49,185:INFO:Extreme Gradient Boosting Imported successfully
2023-11-23 01:01:49,189:INFO:Starting cross validation
2023-11-23 01:01:49,190:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:49,285:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-23 01:01:49,287:WARNING:Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


2023-11-23 01:01:49,287:INFO:Initializing create_model()
2023-11-23 01:01:49,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:49,287:INFO:Checking exceptions
2023-11-23 01:01:49,287:INFO:Importing libraries
2023-11-23 01:01:49,287:INFO:Copying training dataset
2023-11-23 01:01:49,290:INFO:Defining folds
2023-11-23 01:01:49,290:INFO:Declaring metric variables
2023-11-23 01:01:49,292:INFO:Importing untrained model
2023-11-23 01:01:49,294:INFO:Extreme Gradient Boosting Imported successfully
2023-11-23 01:01:49,297:INFO:Starting cross validation
2023-11-23 01:01:49,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:49,357:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2023-11-23 01:01:49,357:ERROR:Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


2023-11-23 01:01:49,357:INFO:Initializing Light Gradient Boosting Machine
2023-11-23 01:01:49,357:INFO:Total runtime is 0.19359246889750162 minutes
2023-11-23 01:01:49,359:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:49,359:INFO:Initializing create_model()
2023-11-23 01:01:49,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:49,359:INFO:Checking exceptions
2023-11-23 01:01:49,359:INFO:Importing libraries
2023-11-23 01:01:49,359:INFO:Copying training dataset
2023-11-23 01:01:49,361:INFO:Defining folds
2023-11-23 01:01:49,361:INFO:Declaring metric variables
2023-11-23 01:01:49,363:INFO:Importing untrained model
2023-11-23 01:01:49,364:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 01:01:49,368:INFO:Starting cross validation
2023-11-23 01:01:49,369:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:51,949:INFO:Calculating mean and std
2023-11-23 01:01:51,949:INFO:Creating metrics dataframe
2023-11-23 01:01:51,951:INFO:Uploading results into container
2023-11-23 01:01:51,951:INFO:Uploading model into container now
2023-11-23 01:01:51,951:INFO:_master_model_container: 17
2023-11-23 01:01:51,951:INFO:_display_container: 2
2023-11-23 01:01:51,952:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:01:51,952:INFO:create_model() successfully completed......................................
2023-11-23 01:01:52,000:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:52,001:INFO:Creating metrics dataframe
2023-11-23 01:01:52,008:INFO:Initializing Dummy Regressor
2023-11-23 01:01:52,008:INFO:Total runtime is 0.237773068745931 minutes
2023-11-23 01:01:52,010:INFO:SubProcess create_model() called ==================================
2023-11-23 01:01:52,010:INFO:Initializing create_model()
2023-11-23 01:01:52,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x147c9a820>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:52,010:INFO:Checking exceptions
2023-11-23 01:01:52,010:INFO:Importing libraries
2023-11-23 01:01:52,010:INFO:Copying training dataset
2023-11-23 01:01:52,012:INFO:Defining folds
2023-11-23 01:01:52,012:INFO:Declaring metric variables
2023-11-23 01:01:52,013:INFO:Importing untrained model
2023-11-23 01:01:52,015:INFO:Dummy Regressor Imported successfully
2023-11-23 01:01:52,018:INFO:Starting cross validation
2023-11-23 01:01:52,018:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:52,078:INFO:Calculating mean and std
2023-11-23 01:01:52,079:INFO:Creating metrics dataframe
2023-11-23 01:01:52,080:INFO:Uploading results into container
2023-11-23 01:01:52,081:INFO:Uploading model into container now
2023-11-23 01:01:52,081:INFO:_master_model_container: 18
2023-11-23 01:01:52,081:INFO:_display_container: 2
2023-11-23 01:01:52,081:INFO:DummyRegressor()
2023-11-23 01:01:52,081:INFO:create_model() successfully completed......................................
2023-11-23 01:01:52,130:INFO:SubProcess create_model() end ==================================
2023-11-23 01:01:52,130:INFO:Creating metrics dataframe
2023-11-23 01:01:52,140:INFO:Initializing create_model()
2023-11-23 01:01:52,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:52,140:INFO:Checking exceptions
2023-11-23 01:01:52,141:INFO:Importing libraries
2023-11-23 01:01:52,141:INFO:Copying training dataset
2023-11-23 01:01:52,143:INFO:Defining folds
2023-11-23 01:01:52,143:INFO:Declaring metric variables
2023-11-23 01:01:52,143:INFO:Importing untrained model
2023-11-23 01:01:52,143:INFO:Declaring custom model
2023-11-23 01:01:52,143:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 01:01:52,144:INFO:Cross validation set to False
2023-11-23 01:01:52,144:INFO:Fitting Model
2023-11-23 01:01:52,156:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:01:52,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2023-11-23 01:01:52,156:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:01:52,156:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:01:52,157:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 01:01:52,157:INFO:[LightGBM] [Info] Start training from score 186277.890967
2023-11-23 01:01:52,395:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:01:52,395:INFO:create_model() successfully completed......................................
2023-11-23 01:01:52,441:INFO:Initializing create_model()
2023-11-23 01:01:52,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:52,442:INFO:Checking exceptions
2023-11-23 01:01:52,442:INFO:Importing libraries
2023-11-23 01:01:52,443:INFO:Copying training dataset
2023-11-23 01:01:52,444:INFO:Defining folds
2023-11-23 01:01:52,444:INFO:Declaring metric variables
2023-11-23 01:01:52,444:INFO:Importing untrained model
2023-11-23 01:01:52,444:INFO:Declaring custom model
2023-11-23 01:01:52,445:INFO:Random Forest Regressor Imported successfully
2023-11-23 01:01:52,445:INFO:Cross validation set to False
2023-11-23 01:01:52,445:INFO:Fitting Model
2023-11-23 01:01:52,846:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:01:52,846:INFO:create_model() successfully completed......................................
2023-11-23 01:01:52,897:INFO:Initializing create_model()
2023-11-23 01:01:52,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:52,897:INFO:Checking exceptions
2023-11-23 01:01:52,897:INFO:Importing libraries
2023-11-23 01:01:52,898:INFO:Copying training dataset
2023-11-23 01:01:52,899:INFO:Defining folds
2023-11-23 01:01:52,900:INFO:Declaring metric variables
2023-11-23 01:01:52,900:INFO:Importing untrained model
2023-11-23 01:01:52,900:INFO:Declaring custom model
2023-11-23 01:01:52,900:INFO:Extra Trees Regressor Imported successfully
2023-11-23 01:01:52,900:INFO:Cross validation set to False
2023-11-23 01:01:52,900:INFO:Fitting Model
2023-11-23 01:01:53,113:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:01:53,113:INFO:create_model() successfully completed......................................
2023-11-23 01:01:53,176:INFO:_master_model_container: 18
2023-11-23 01:01:53,176:INFO:_display_container: 2
2023-11-23 01:01:53,177:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)]
2023-11-23 01:01:53,177:INFO:compare_models() successfully completed......................................
2023-11-23 01:01:53,216:INFO:Initializing create_model()
2023-11-23 01:01:53,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:53,217:INFO:Checking exceptions
2023-11-23 01:01:53,225:INFO:Importing libraries
2023-11-23 01:01:53,225:INFO:Copying training dataset
2023-11-23 01:01:53,228:INFO:Defining folds
2023-11-23 01:01:53,228:INFO:Declaring metric variables
2023-11-23 01:01:53,230:INFO:Importing untrained model
2023-11-23 01:01:53,230:INFO:Declaring custom model
2023-11-23 01:01:53,232:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 01:01:53,235:INFO:Starting cross validation
2023-11-23 01:01:53,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:55,918:INFO:Calculating mean and std
2023-11-23 01:01:55,919:INFO:Creating metrics dataframe
2023-11-23 01:01:55,922:INFO:Finalizing model
2023-11-23 01:01:55,935:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:01:55,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.
2023-11-23 01:01:55,936:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:01:55,936:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:01:55,937:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 01:01:55,937:INFO:[LightGBM] [Info] Start training from score 186277.890967
2023-11-23 01:01:56,184:INFO:Uploading results into container
2023-11-23 01:01:56,184:INFO:Uploading model into container now
2023-11-23 01:01:56,189:INFO:_master_model_container: 19
2023-11-23 01:01:56,189:INFO:_display_container: 3
2023-11-23 01:01:56,190:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:01:56,190:INFO:create_model() successfully completed......................................
2023-11-23 01:01:56,242:INFO:Initializing create_model()
2023-11-23 01:01:56,243:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:01:56,243:INFO:Checking exceptions
2023-11-23 01:01:56,249:INFO:Importing libraries
2023-11-23 01:01:56,249:INFO:Copying training dataset
2023-11-23 01:01:56,252:INFO:Defining folds
2023-11-23 01:01:56,252:INFO:Declaring metric variables
2023-11-23 01:01:56,254:INFO:Importing untrained model
2023-11-23 01:01:56,254:INFO:Declaring custom model
2023-11-23 01:01:56,255:INFO:Random Forest Regressor Imported successfully
2023-11-23 01:01:56,258:INFO:Starting cross validation
2023-11-23 01:01:56,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:01:59,883:INFO:Calculating mean and std
2023-11-23 01:01:59,884:INFO:Creating metrics dataframe
2023-11-23 01:01:59,888:INFO:Finalizing model
2023-11-23 01:02:00,329:INFO:Uploading results into container
2023-11-23 01:02:00,329:INFO:Uploading model into container now
2023-11-23 01:02:00,335:INFO:_master_model_container: 20
2023-11-23 01:02:00,335:INFO:_display_container: 4
2023-11-23 01:02:00,335:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:02:00,335:INFO:create_model() successfully completed......................................
2023-11-23 01:02:00,395:INFO:Initializing create_model()
2023-11-23 01:02:00,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x147c2adf0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:02:00,395:INFO:Checking exceptions
2023-11-23 01:02:00,402:INFO:Importing libraries
2023-11-23 01:02:00,402:INFO:Copying training dataset
2023-11-23 01:02:00,405:INFO:Defining folds
2023-11-23 01:02:00,405:INFO:Declaring metric variables
2023-11-23 01:02:00,407:INFO:Importing untrained model
2023-11-23 01:02:00,407:INFO:Declaring custom model
2023-11-23 01:02:00,408:INFO:Extra Trees Regressor Imported successfully
2023-11-23 01:02:00,411:INFO:Starting cross validation
2023-11-23 01:02:00,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:02:41,578:INFO:PyCaret RegressionExperiment
2023-11-23 01:02:41,578:INFO:Logging name: reg-default-name
2023-11-23 01:02:41,579:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-23 01:02:41,579:INFO:version 3.1.0
2023-11-23 01:02:41,579:INFO:Initializing setup()
2023-11-23 01:02:41,579:INFO:self.USI: 4226
2023-11-23 01:02:41,579:INFO:self._variable_keys: {'html_param', 'log_plots_param', 'fold_groups_param', 'data', 'y_train', 'fold_generator', 'X_test', 'target_param', 'gpu_param', 'gpu_n_jobs_param', '_available_plots', 'n_jobs_param', 'exp_id', 'exp_name_log', 'X_train', 'y_test', 'memory', 'logging_param', 'fold_shuffle_param', 'X', '_ml_usecase', 'idx', 'pipeline', 'USI', 'seed', 'y', 'transform_target_param'}
2023-11-23 01:02:41,579:INFO:Checking environment
2023-11-23 01:02:41,579:INFO:python_version: 3.9.16
2023-11-23 01:02:41,579:INFO:python_build: ('main', 'Nov  2 2023 14:11:49')
2023-11-23 01:02:41,579:INFO:machine: arm64
2023-11-23 01:02:41,579:INFO:platform: macOS-13.4.1-arm64-arm-64bit
2023-11-23 01:02:41,579:INFO:Memory: svmem(total=8589934592, available=2143633408, percent=75.0, used=3404988416, free=263143424, active=1891008512, inactive=1838874624, wired=1513979904)
2023-11-23 01:02:41,579:INFO:Physical Core: 8
2023-11-23 01:02:41,579:INFO:Logical Core: 8
2023-11-23 01:02:41,579:INFO:Checking libraries
2023-11-23 01:02:41,579:INFO:System:
2023-11-23 01:02:41,579:INFO:    python: 3.9.16 (main, Nov  2 2023, 14:11:49)  [Clang 14.0.3 (clang-1403.0.22.14.1)]
2023-11-23 01:02:41,579:INFO:executable: /Users/macOs/.pyenv/versions/3.9.16/bin/python
2023-11-23 01:02:41,579:INFO:   machine: macOS-13.4.1-arm64-arm-64bit
2023-11-23 01:02:41,579:INFO:PyCaret required dependencies:
2023-11-23 01:02:41,579:INFO:                 pip: 22.0.4
2023-11-23 01:02:41,579:INFO:          setuptools: 58.1.0
2023-11-23 01:02:41,579:INFO:             pycaret: 3.1.0
2023-11-23 01:02:41,579:INFO:             IPython: 8.17.2
2023-11-23 01:02:41,579:INFO:          ipywidgets: 8.1.1
2023-11-23 01:02:41,579:INFO:                tqdm: 4.66.1
2023-11-23 01:02:41,579:INFO:               numpy: 1.23.5
2023-11-23 01:02:41,579:INFO:              pandas: 1.5.3
2023-11-23 01:02:41,579:INFO:              jinja2: 3.1.2
2023-11-23 01:02:41,579:INFO:               scipy: 1.10.1
2023-11-23 01:02:41,579:INFO:              joblib: 1.3.2
2023-11-23 01:02:41,579:INFO:             sklearn: 1.2.2
2023-11-23 01:02:41,579:INFO:                pyod: 1.1.1
2023-11-23 01:02:41,579:INFO:            imblearn: 0.11.0
2023-11-23 01:02:41,579:INFO:   category_encoders: 2.6.3
2023-11-23 01:02:41,579:INFO:            lightgbm: 4.1.0
2023-11-23 01:02:41,579:INFO:               numba: 0.58.1
2023-11-23 01:02:41,580:INFO:            requests: 2.31.0
2023-11-23 01:02:41,580:INFO:          matplotlib: 3.8.1
2023-11-23 01:02:41,580:INFO:          scikitplot: 0.3.7
2023-11-23 01:02:41,580:INFO:         yellowbrick: 1.5
2023-11-23 01:02:41,580:INFO:              plotly: 5.18.0
2023-11-23 01:02:41,580:INFO:    plotly-resampler: Not installed
2023-11-23 01:02:41,580:INFO:             kaleido: 0.2.1
2023-11-23 01:02:41,580:INFO:           schemdraw: 0.15
2023-11-23 01:02:41,580:INFO:         statsmodels: 0.14.0
2023-11-23 01:02:41,580:INFO:              sktime: 0.21.1
2023-11-23 01:02:41,580:INFO:               tbats: 1.1.3
2023-11-23 01:02:41,580:INFO:            pmdarima: 2.0.4
2023-11-23 01:02:41,580:INFO:              psutil: 5.9.6
2023-11-23 01:02:41,580:INFO:          markupsafe: 2.1.3
2023-11-23 01:02:41,580:INFO:             pickle5: Not installed
2023-11-23 01:02:41,580:INFO:         cloudpickle: 3.0.0
2023-11-23 01:02:41,580:INFO:         deprecation: 2.1.0
2023-11-23 01:02:41,580:INFO:              xxhash: 3.4.1
2023-11-23 01:02:41,580:INFO:           wurlitzer: 3.0.3
2023-11-23 01:02:41,580:INFO:PyCaret optional dependencies:
2023-11-23 01:02:41,580:INFO:                shap: Not installed
2023-11-23 01:02:41,580:INFO:           interpret: Not installed
2023-11-23 01:02:41,580:INFO:                umap: Not installed
2023-11-23 01:02:41,580:INFO:     ydata_profiling: Not installed
2023-11-23 01:02:41,580:INFO:  explainerdashboard: Not installed
2023-11-23 01:02:41,580:INFO:             autoviz: Not installed
2023-11-23 01:02:41,580:INFO:           fairlearn: Not installed
2023-11-23 01:02:41,580:INFO:          deepchecks: Not installed
2023-11-23 01:02:41,580:INFO:             xgboost: 2.0.2
2023-11-23 01:02:41,580:INFO:            catboost: Not installed
2023-11-23 01:02:41,580:INFO:              kmodes: Not installed
2023-11-23 01:02:41,580:INFO:             mlxtend: Not installed
2023-11-23 01:02:41,580:INFO:       statsforecast: Not installed
2023-11-23 01:02:41,580:INFO:        tune_sklearn: Not installed
2023-11-23 01:02:41,580:INFO:                 ray: Not installed
2023-11-23 01:02:41,580:INFO:            hyperopt: Not installed
2023-11-23 01:02:41,580:INFO:              optuna: Not installed
2023-11-23 01:02:41,580:INFO:               skopt: Not installed
2023-11-23 01:02:41,580:INFO:              mlflow: Not installed
2023-11-23 01:02:41,580:INFO:              gradio: Not installed
2023-11-23 01:02:41,580:INFO:             fastapi: Not installed
2023-11-23 01:02:41,580:INFO:             uvicorn: Not installed
2023-11-23 01:02:41,580:INFO:              m2cgen: Not installed
2023-11-23 01:02:41,580:INFO:           evidently: Not installed
2023-11-23 01:02:41,580:INFO:               fugue: Not installed
2023-11-23 01:02:41,581:INFO:           streamlit: Not installed
2023-11-23 01:02:41,581:INFO:             prophet: Not installed
2023-11-23 01:02:41,581:INFO:None
2023-11-23 01:02:41,581:INFO:Set up data.
2023-11-23 01:02:41,585:INFO:Set up folding strategy.
2023-11-23 01:02:41,585:INFO:Set up train/test split.
2023-11-23 01:02:41,587:INFO:Set up index.
2023-11-23 01:02:41,588:INFO:Assigning column types.
2023-11-23 01:02:41,589:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-23 01:02:41,589:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,592:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,595:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,624:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,644:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:41,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:41,645:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,647:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,650:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,674:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,694:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:41,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:41,695:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-23 01:02:41,697:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,699:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,724:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,744:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,744:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:41,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:41,747:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,749:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,774:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,794:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,794:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:41,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:41,795:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-23 01:02:41,799:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,825:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,844:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:41,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:41,851:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,876:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,895:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:41,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:41,896:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-23 01:02:41,926:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,945:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:41,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:41,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,995:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:02:41,995:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:41,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:41,996:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-23 01:02:42,025:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:02:42,045:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:42,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:42,075:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:02:42,095:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:42,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:42,096:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-23 01:02:42,144:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:42,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:42,194:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:42,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:42,196:INFO:Set up custom pipeline.
2023-11-23 01:02:42,205:INFO:Finished creating preprocessing pipeline.
2023-11-23 01:02:42,227:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/8h/q7dbs5196q9fcktcxkc2__dh0000gn/T/joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))])))])
2023-11-23 01:02:42,227:INFO:Creating final display dataframe.
2023-11-23 01:02:42,260:INFO:Setup _display_container:                    Description             Value
0                   Session id               123
1                       Target  MedianHouseValue
2                  Target type        Regression
3          Original data shape        (7560, 10)
4       Transformed data shape        (7560, 13)
5  Transformed train set shape        (5292, 13)
6   Transformed test set shape        (2268, 13)
7             Numeric features                 8
8         Categorical features                 1
2023-11-23 01:02:42,314:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:42,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:42,366:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:02:42,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:02:42,368:INFO:setup() successfully completed in 0.79s...............
2023-11-23 01:04:14,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:04:14,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:04:14,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:04:14,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:13:57,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:13:57,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:13:57,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:13:57,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 01:13:57,424:INFO:PyCaret RegressionExperiment
2023-11-23 01:13:57,424:INFO:Logging name: reg-default-name
2023-11-23 01:13:57,424:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-23 01:13:57,425:INFO:version 3.1.0
2023-11-23 01:13:57,425:INFO:Initializing setup()
2023-11-23 01:13:57,425:INFO:self.USI: da95
2023-11-23 01:13:57,425:INFO:self._variable_keys: {'_available_plots', 'exp_id', 'X', 'fold_groups_param', 'pipeline', '_ml_usecase', 'fold_generator', 'X_test', 'X_train', 'gpu_n_jobs_param', 'idx', 'seed', 'y_train', 'gpu_param', 'y', 'n_jobs_param', 'y_test', 'exp_name_log', 'transform_target_param', 'memory', 'logging_param', 'log_plots_param', 'html_param', 'USI', 'target_param', 'fold_shuffle_param', 'data'}
2023-11-23 01:13:57,425:INFO:Checking environment
2023-11-23 01:13:57,425:INFO:python_version: 3.9.16
2023-11-23 01:13:57,425:INFO:python_build: ('main', 'Nov  2 2023 14:11:49')
2023-11-23 01:13:57,425:INFO:machine: arm64
2023-11-23 01:13:57,425:INFO:platform: macOS-13.4.1-arm64-arm-64bit
2023-11-23 01:13:57,425:INFO:Memory: svmem(total=8589934592, available=2439315456, percent=71.6, used=3679059968, free=27492352, active=2420293632, inactive=2394947584, wired=1258766336)
2023-11-23 01:13:57,425:INFO:Physical Core: 8
2023-11-23 01:13:57,425:INFO:Logical Core: 8
2023-11-23 01:13:57,425:INFO:Checking libraries
2023-11-23 01:13:57,425:INFO:System:
2023-11-23 01:13:57,425:INFO:    python: 3.9.16 (main, Nov  2 2023, 14:11:49)  [Clang 14.0.3 (clang-1403.0.22.14.1)]
2023-11-23 01:13:57,425:INFO:executable: /Users/macOs/.pyenv/versions/3.9.16/bin/python
2023-11-23 01:13:57,425:INFO:   machine: macOS-13.4.1-arm64-arm-64bit
2023-11-23 01:13:57,425:INFO:PyCaret required dependencies:
2023-11-23 01:13:57,443:INFO:                 pip: 22.0.4
2023-11-23 01:13:57,443:INFO:          setuptools: 58.1.0
2023-11-23 01:13:57,443:INFO:             pycaret: 3.1.0
2023-11-23 01:13:57,443:INFO:             IPython: 8.17.2
2023-11-23 01:13:57,443:INFO:          ipywidgets: 8.1.1
2023-11-23 01:13:57,443:INFO:                tqdm: 4.66.1
2023-11-23 01:13:57,443:INFO:               numpy: 1.23.5
2023-11-23 01:13:57,443:INFO:              pandas: 1.5.3
2023-11-23 01:13:57,443:INFO:              jinja2: 3.1.2
2023-11-23 01:13:57,443:INFO:               scipy: 1.10.1
2023-11-23 01:13:57,443:INFO:              joblib: 1.3.2
2023-11-23 01:13:57,443:INFO:             sklearn: 1.2.2
2023-11-23 01:13:57,443:INFO:                pyod: 1.1.1
2023-11-23 01:13:57,443:INFO:            imblearn: 0.11.0
2023-11-23 01:13:57,443:INFO:   category_encoders: 2.6.3
2023-11-23 01:13:57,443:INFO:            lightgbm: 4.1.0
2023-11-23 01:13:57,443:INFO:               numba: 0.58.1
2023-11-23 01:13:57,443:INFO:            requests: 2.31.0
2023-11-23 01:13:57,443:INFO:          matplotlib: 3.8.1
2023-11-23 01:13:57,443:INFO:          scikitplot: 0.3.7
2023-11-23 01:13:57,443:INFO:         yellowbrick: 1.5
2023-11-23 01:13:57,443:INFO:              plotly: 5.18.0
2023-11-23 01:13:57,443:INFO:    plotly-resampler: Not installed
2023-11-23 01:13:57,443:INFO:             kaleido: 0.2.1
2023-11-23 01:13:57,443:INFO:           schemdraw: 0.15
2023-11-23 01:13:57,443:INFO:         statsmodels: 0.14.0
2023-11-23 01:13:57,443:INFO:              sktime: 0.21.1
2023-11-23 01:13:57,443:INFO:               tbats: 1.1.3
2023-11-23 01:13:57,443:INFO:            pmdarima: 2.0.4
2023-11-23 01:13:57,443:INFO:              psutil: 5.9.6
2023-11-23 01:13:57,443:INFO:          markupsafe: 2.1.3
2023-11-23 01:13:57,443:INFO:             pickle5: Not installed
2023-11-23 01:13:57,443:INFO:         cloudpickle: 3.0.0
2023-11-23 01:13:57,443:INFO:         deprecation: 2.1.0
2023-11-23 01:13:57,443:INFO:              xxhash: 3.4.1
2023-11-23 01:13:57,443:INFO:           wurlitzer: 3.0.3
2023-11-23 01:13:57,443:INFO:PyCaret optional dependencies:
2023-11-23 01:13:57,449:INFO:                shap: Not installed
2023-11-23 01:13:57,449:INFO:           interpret: Not installed
2023-11-23 01:13:57,450:INFO:                umap: Not installed
2023-11-23 01:13:57,450:INFO:     ydata_profiling: Not installed
2023-11-23 01:13:57,450:INFO:  explainerdashboard: Not installed
2023-11-23 01:13:57,450:INFO:             autoviz: Not installed
2023-11-23 01:13:57,450:INFO:           fairlearn: Not installed
2023-11-23 01:13:57,450:INFO:          deepchecks: Not installed
2023-11-23 01:13:57,450:INFO:             xgboost: 2.0.2
2023-11-23 01:13:57,450:INFO:            catboost: Not installed
2023-11-23 01:13:57,450:INFO:              kmodes: Not installed
2023-11-23 01:13:57,450:INFO:             mlxtend: Not installed
2023-11-23 01:13:57,450:INFO:       statsforecast: Not installed
2023-11-23 01:13:57,450:INFO:        tune_sklearn: Not installed
2023-11-23 01:13:57,450:INFO:                 ray: Not installed
2023-11-23 01:13:57,450:INFO:            hyperopt: Not installed
2023-11-23 01:13:57,450:INFO:              optuna: Not installed
2023-11-23 01:13:57,450:INFO:               skopt: Not installed
2023-11-23 01:13:57,450:INFO:              mlflow: Not installed
2023-11-23 01:13:57,450:INFO:              gradio: Not installed
2023-11-23 01:13:57,450:INFO:             fastapi: Not installed
2023-11-23 01:13:57,450:INFO:             uvicorn: Not installed
2023-11-23 01:13:57,450:INFO:              m2cgen: Not installed
2023-11-23 01:13:57,450:INFO:           evidently: Not installed
2023-11-23 01:13:57,450:INFO:               fugue: Not installed
2023-11-23 01:13:57,450:INFO:           streamlit: Not installed
2023-11-23 01:13:57,450:INFO:             prophet: Not installed
2023-11-23 01:13:57,450:INFO:None
2023-11-23 01:13:57,450:INFO:Set up data.
2023-11-23 01:13:57,454:INFO:Set up folding strategy.
2023-11-23 01:13:57,454:INFO:Set up train/test split.
2023-11-23 01:13:57,456:INFO:Set up index.
2023-11-23 01:13:57,456:INFO:Assigning column types.
2023-11-23 01:13:57,457:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-23 01:13:57,457:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,459:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,461:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,507:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:57,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:57,508:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,510:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,512:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,538:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,557:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,557:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:57,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:57,559:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-23 01:13:57,561:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,563:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,607:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,607:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:57,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:57,611:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,613:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,638:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,658:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,658:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:57,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:57,659:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-23 01:13:57,663:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,688:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,708:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,708:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:57,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:57,713:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,739:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,758:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,759:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:57,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:57,760:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-23 01:13:57,789:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,809:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,809:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:57,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:57,840:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,860:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,860:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:57,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:57,861:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-23 01:13:57,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,910:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:57,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:57,941:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 01:13:57,962:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:57,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:57,963:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-23 01:13:58,012:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:58,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:58,065:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:58,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:58,068:INFO:Set up custom pipeline.
2023-11-23 01:13:58,077:INFO:Finished creating preprocessing pipeline.
2023-11-23 01:13:58,099:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/8h/q7dbs5196q9fcktcxkc2__dh0000gn/T/joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))])))])
2023-11-23 01:13:58,099:INFO:Creating final display dataframe.
2023-11-23 01:13:58,134:INFO:Setup _display_container:                    Description               Value
0                   Session id                 123
1                       Target  median_house_value
2                  Target type          Regression
3          Original data shape          (9450, 10)
4       Transformed data shape          (9450, 13)
5  Transformed train set shape          (6615, 13)
6   Transformed test set shape          (2835, 13)
7             Numeric features                   8
8         Categorical features                   1
2023-11-23 01:13:58,188:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:58,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:58,239:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 01:13:58,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 01:13:58,240:INFO:setup() successfully completed in 0.82s...............
2023-11-23 01:14:06,895:INFO:Initializing compare_models()
2023-11-23 01:14:06,895:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-23 01:14:06,895:INFO:Checking exceptions
2023-11-23 01:14:06,898:INFO:Preparing display monitor
2023-11-23 01:14:06,923:INFO:Initializing Linear Regression
2023-11-23 01:14:06,923:INFO:Total runtime is 3.3179918924967447e-06 minutes
2023-11-23 01:14:06,925:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:06,926:INFO:Initializing create_model()
2023-11-23 01:14:06,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:06,926:INFO:Checking exceptions
2023-11-23 01:14:06,927:INFO:Importing libraries
2023-11-23 01:14:06,927:INFO:Copying training dataset
2023-11-23 01:14:06,930:INFO:Defining folds
2023-11-23 01:14:06,930:INFO:Declaring metric variables
2023-11-23 01:14:06,932:INFO:Importing untrained model
2023-11-23 01:14:06,934:INFO:Linear Regression Imported successfully
2023-11-23 01:14:06,937:INFO:Starting cross validation
2023-11-23 01:14:06,941:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:08,864:INFO:Calculating mean and std
2023-11-23 01:14:08,865:INFO:Creating metrics dataframe
2023-11-23 01:14:08,869:INFO:Uploading results into container
2023-11-23 01:14:08,869:INFO:Uploading model into container now
2023-11-23 01:14:08,869:INFO:_master_model_container: 1
2023-11-23 01:14:08,869:INFO:_display_container: 2
2023-11-23 01:14:08,870:INFO:LinearRegression(n_jobs=-1)
2023-11-23 01:14:08,870:INFO:create_model() successfully completed......................................
2023-11-23 01:14:08,953:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:08,953:INFO:Creating metrics dataframe
2023-11-23 01:14:08,957:INFO:Initializing Lasso Regression
2023-11-23 01:14:08,957:INFO:Total runtime is 0.03390321731567383 minutes
2023-11-23 01:14:08,959:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:08,959:INFO:Initializing create_model()
2023-11-23 01:14:08,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:08,959:INFO:Checking exceptions
2023-11-23 01:14:08,959:INFO:Importing libraries
2023-11-23 01:14:08,959:INFO:Copying training dataset
2023-11-23 01:14:08,962:INFO:Defining folds
2023-11-23 01:14:08,962:INFO:Declaring metric variables
2023-11-23 01:14:08,964:INFO:Importing untrained model
2023-11-23 01:14:08,965:INFO:Lasso Regression Imported successfully
2023-11-23 01:14:08,969:INFO:Starting cross validation
2023-11-23 01:14:08,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:09,112:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.042e+12, tolerance: 5.236e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:14:09,116:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.032e+12, tolerance: 5.225e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:14:09,125:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+12, tolerance: 5.196e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:14:09,125:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+12, tolerance: 5.094e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:14:09,128:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+12, tolerance: 5.178e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:14:09,146:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.000e+12, tolerance: 5.124e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:14:09,147:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+12, tolerance: 5.166e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:14:09,154:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+12, tolerance: 5.188e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:14:09,207:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+12, tolerance: 5.160e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:14:09,219:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+12, tolerance: 5.223e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 01:14:09,233:INFO:Calculating mean and std
2023-11-23 01:14:09,233:INFO:Creating metrics dataframe
2023-11-23 01:14:09,235:INFO:Uploading results into container
2023-11-23 01:14:09,236:INFO:Uploading model into container now
2023-11-23 01:14:09,236:INFO:_master_model_container: 2
2023-11-23 01:14:09,236:INFO:_display_container: 2
2023-11-23 01:14:09,236:INFO:Lasso(random_state=123)
2023-11-23 01:14:09,236:INFO:create_model() successfully completed......................................
2023-11-23 01:14:09,279:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:09,280:INFO:Creating metrics dataframe
2023-11-23 01:14:09,285:INFO:Initializing Ridge Regression
2023-11-23 01:14:09,285:INFO:Total runtime is 0.03936793406804402 minutes
2023-11-23 01:14:09,286:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:09,286:INFO:Initializing create_model()
2023-11-23 01:14:09,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:09,287:INFO:Checking exceptions
2023-11-23 01:14:09,287:INFO:Importing libraries
2023-11-23 01:14:09,287:INFO:Copying training dataset
2023-11-23 01:14:09,289:INFO:Defining folds
2023-11-23 01:14:09,289:INFO:Declaring metric variables
2023-11-23 01:14:09,291:INFO:Importing untrained model
2023-11-23 01:14:09,292:INFO:Ridge Regression Imported successfully
2023-11-23 01:14:09,295:INFO:Starting cross validation
2023-11-23 01:14:09,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:09,368:INFO:Calculating mean and std
2023-11-23 01:14:09,368:INFO:Creating metrics dataframe
2023-11-23 01:14:09,370:INFO:Uploading results into container
2023-11-23 01:14:09,370:INFO:Uploading model into container now
2023-11-23 01:14:09,370:INFO:_master_model_container: 3
2023-11-23 01:14:09,370:INFO:_display_container: 2
2023-11-23 01:14:09,370:INFO:Ridge(random_state=123)
2023-11-23 01:14:09,370:INFO:create_model() successfully completed......................................
2023-11-23 01:14:09,413:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:09,413:INFO:Creating metrics dataframe
2023-11-23 01:14:09,418:INFO:Initializing Elastic Net
2023-11-23 01:14:09,418:INFO:Total runtime is 0.0415811538696289 minutes
2023-11-23 01:14:09,419:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:09,419:INFO:Initializing create_model()
2023-11-23 01:14:09,419:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:09,420:INFO:Checking exceptions
2023-11-23 01:14:09,420:INFO:Importing libraries
2023-11-23 01:14:09,420:INFO:Copying training dataset
2023-11-23 01:14:09,422:INFO:Defining folds
2023-11-23 01:14:09,422:INFO:Declaring metric variables
2023-11-23 01:14:09,423:INFO:Importing untrained model
2023-11-23 01:14:09,425:INFO:Elastic Net Imported successfully
2023-11-23 01:14:09,428:INFO:Starting cross validation
2023-11-23 01:14:09,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:09,509:INFO:Calculating mean and std
2023-11-23 01:14:09,509:INFO:Creating metrics dataframe
2023-11-23 01:14:09,511:INFO:Uploading results into container
2023-11-23 01:14:09,511:INFO:Uploading model into container now
2023-11-23 01:14:09,511:INFO:_master_model_container: 4
2023-11-23 01:14:09,511:INFO:_display_container: 2
2023-11-23 01:14:09,511:INFO:ElasticNet(random_state=123)
2023-11-23 01:14:09,511:INFO:create_model() successfully completed......................................
2023-11-23 01:14:09,553:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:09,553:INFO:Creating metrics dataframe
2023-11-23 01:14:09,558:INFO:Initializing Least Angle Regression
2023-11-23 01:14:09,558:INFO:Total runtime is 0.043910415967305494 minutes
2023-11-23 01:14:09,559:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:09,560:INFO:Initializing create_model()
2023-11-23 01:14:09,560:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:09,560:INFO:Checking exceptions
2023-11-23 01:14:09,560:INFO:Importing libraries
2023-11-23 01:14:09,560:INFO:Copying training dataset
2023-11-23 01:14:09,562:INFO:Defining folds
2023-11-23 01:14:09,562:INFO:Declaring metric variables
2023-11-23 01:14:09,564:INFO:Importing untrained model
2023-11-23 01:14:09,565:INFO:Least Angle Regression Imported successfully
2023-11-23 01:14:09,568:INFO:Starting cross validation
2023-11-23 01:14:09,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:09,637:INFO:Calculating mean and std
2023-11-23 01:14:09,638:INFO:Creating metrics dataframe
2023-11-23 01:14:09,639:INFO:Uploading results into container
2023-11-23 01:14:09,639:INFO:Uploading model into container now
2023-11-23 01:14:09,640:INFO:_master_model_container: 5
2023-11-23 01:14:09,640:INFO:_display_container: 2
2023-11-23 01:14:09,640:INFO:Lars(random_state=123)
2023-11-23 01:14:09,640:INFO:create_model() successfully completed......................................
2023-11-23 01:14:09,683:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:09,683:INFO:Creating metrics dataframe
2023-11-23 01:14:09,687:INFO:Initializing Lasso Least Angle Regression
2023-11-23 01:14:09,687:INFO:Total runtime is 0.04606886704762776 minutes
2023-11-23 01:14:09,688:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:09,689:INFO:Initializing create_model()
2023-11-23 01:14:09,689:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:09,689:INFO:Checking exceptions
2023-11-23 01:14:09,689:INFO:Importing libraries
2023-11-23 01:14:09,689:INFO:Copying training dataset
2023-11-23 01:14:09,691:INFO:Defining folds
2023-11-23 01:14:09,691:INFO:Declaring metric variables
2023-11-23 01:14:09,692:INFO:Importing untrained model
2023-11-23 01:14:09,694:INFO:Lasso Least Angle Regression Imported successfully
2023-11-23 01:14:09,697:INFO:Starting cross validation
2023-11-23 01:14:09,697:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:09,766:INFO:Calculating mean and std
2023-11-23 01:14:09,766:INFO:Creating metrics dataframe
2023-11-23 01:14:09,768:INFO:Uploading results into container
2023-11-23 01:14:09,768:INFO:Uploading model into container now
2023-11-23 01:14:09,768:INFO:_master_model_container: 6
2023-11-23 01:14:09,768:INFO:_display_container: 2
2023-11-23 01:14:09,768:INFO:LassoLars(random_state=123)
2023-11-23 01:14:09,768:INFO:create_model() successfully completed......................................
2023-11-23 01:14:09,810:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:09,810:INFO:Creating metrics dataframe
2023-11-23 01:14:09,815:INFO:Initializing Orthogonal Matching Pursuit
2023-11-23 01:14:09,815:INFO:Total runtime is 0.04820530017217 minutes
2023-11-23 01:14:09,817:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:09,817:INFO:Initializing create_model()
2023-11-23 01:14:09,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:09,817:INFO:Checking exceptions
2023-11-23 01:14:09,817:INFO:Importing libraries
2023-11-23 01:14:09,817:INFO:Copying training dataset
2023-11-23 01:14:09,820:INFO:Defining folds
2023-11-23 01:14:09,820:INFO:Declaring metric variables
2023-11-23 01:14:09,821:INFO:Importing untrained model
2023-11-23 01:14:09,823:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-23 01:14:09,825:INFO:Starting cross validation
2023-11-23 01:14:09,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:09,887:INFO:Calculating mean and std
2023-11-23 01:14:09,887:INFO:Creating metrics dataframe
2023-11-23 01:14:09,889:INFO:Uploading results into container
2023-11-23 01:14:09,889:INFO:Uploading model into container now
2023-11-23 01:14:09,889:INFO:_master_model_container: 7
2023-11-23 01:14:09,889:INFO:_display_container: 2
2023-11-23 01:14:09,889:INFO:OrthogonalMatchingPursuit()
2023-11-23 01:14:09,889:INFO:create_model() successfully completed......................................
2023-11-23 01:14:09,931:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:09,931:INFO:Creating metrics dataframe
2023-11-23 01:14:09,936:INFO:Initializing Bayesian Ridge
2023-11-23 01:14:09,936:INFO:Total runtime is 0.05021804968516032 minutes
2023-11-23 01:14:09,938:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:09,938:INFO:Initializing create_model()
2023-11-23 01:14:09,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:09,938:INFO:Checking exceptions
2023-11-23 01:14:09,938:INFO:Importing libraries
2023-11-23 01:14:09,938:INFO:Copying training dataset
2023-11-23 01:14:09,941:INFO:Defining folds
2023-11-23 01:14:09,941:INFO:Declaring metric variables
2023-11-23 01:14:09,942:INFO:Importing untrained model
2023-11-23 01:14:09,943:INFO:Bayesian Ridge Imported successfully
2023-11-23 01:14:09,947:INFO:Starting cross validation
2023-11-23 01:14:09,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:10,016:INFO:Calculating mean and std
2023-11-23 01:14:10,017:INFO:Creating metrics dataframe
2023-11-23 01:14:10,018:INFO:Uploading results into container
2023-11-23 01:14:10,018:INFO:Uploading model into container now
2023-11-23 01:14:10,019:INFO:_master_model_container: 8
2023-11-23 01:14:10,019:INFO:_display_container: 2
2023-11-23 01:14:10,019:INFO:BayesianRidge()
2023-11-23 01:14:10,019:INFO:create_model() successfully completed......................................
2023-11-23 01:14:10,063:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:10,063:INFO:Creating metrics dataframe
2023-11-23 01:14:10,068:INFO:Initializing Passive Aggressive Regressor
2023-11-23 01:14:10,068:INFO:Total runtime is 0.05241513252258301 minutes
2023-11-23 01:14:10,069:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:10,069:INFO:Initializing create_model()
2023-11-23 01:14:10,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:10,069:INFO:Checking exceptions
2023-11-23 01:14:10,069:INFO:Importing libraries
2023-11-23 01:14:10,069:INFO:Copying training dataset
2023-11-23 01:14:10,072:INFO:Defining folds
2023-11-23 01:14:10,072:INFO:Declaring metric variables
2023-11-23 01:14:10,073:INFO:Importing untrained model
2023-11-23 01:14:10,074:INFO:Passive Aggressive Regressor Imported successfully
2023-11-23 01:14:10,077:INFO:Starting cross validation
2023-11-23 01:14:10,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:10,172:INFO:Calculating mean and std
2023-11-23 01:14:10,173:INFO:Creating metrics dataframe
2023-11-23 01:14:10,174:INFO:Uploading results into container
2023-11-23 01:14:10,174:INFO:Uploading model into container now
2023-11-23 01:14:10,175:INFO:_master_model_container: 9
2023-11-23 01:14:10,175:INFO:_display_container: 2
2023-11-23 01:14:10,175:INFO:PassiveAggressiveRegressor(random_state=123)
2023-11-23 01:14:10,175:INFO:create_model() successfully completed......................................
2023-11-23 01:14:10,220:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:10,220:INFO:Creating metrics dataframe
2023-11-23 01:14:10,225:INFO:Initializing Huber Regressor
2023-11-23 01:14:10,225:INFO:Total runtime is 0.055035098393758135 minutes
2023-11-23 01:14:10,226:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:10,227:INFO:Initializing create_model()
2023-11-23 01:14:10,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:10,227:INFO:Checking exceptions
2023-11-23 01:14:10,227:INFO:Importing libraries
2023-11-23 01:14:10,227:INFO:Copying training dataset
2023-11-23 01:14:10,230:INFO:Defining folds
2023-11-23 01:14:10,230:INFO:Declaring metric variables
2023-11-23 01:14:10,232:INFO:Importing untrained model
2023-11-23 01:14:10,233:INFO:Huber Regressor Imported successfully
2023-11-23 01:14:10,236:INFO:Starting cross validation
2023-11-23 01:14:10,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:10,325:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:14:10,371:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:14:10,382:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:14:10,397:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:14:10,401:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:14:10,407:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:14:10,416:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:14:10,420:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:14:10,423:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:14:10,449:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 01:14:10,453:INFO:Calculating mean and std
2023-11-23 01:14:10,454:INFO:Creating metrics dataframe
2023-11-23 01:14:10,455:INFO:Uploading results into container
2023-11-23 01:14:10,455:INFO:Uploading model into container now
2023-11-23 01:14:10,455:INFO:_master_model_container: 10
2023-11-23 01:14:10,455:INFO:_display_container: 2
2023-11-23 01:14:10,455:INFO:HuberRegressor()
2023-11-23 01:14:10,456:INFO:create_model() successfully completed......................................
2023-11-23 01:14:10,498:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:10,498:INFO:Creating metrics dataframe
2023-11-23 01:14:10,503:INFO:Initializing K Neighbors Regressor
2023-11-23 01:14:10,503:INFO:Total runtime is 0.059667615095774326 minutes
2023-11-23 01:14:10,505:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:10,505:INFO:Initializing create_model()
2023-11-23 01:14:10,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:10,505:INFO:Checking exceptions
2023-11-23 01:14:10,505:INFO:Importing libraries
2023-11-23 01:14:10,505:INFO:Copying training dataset
2023-11-23 01:14:10,508:INFO:Defining folds
2023-11-23 01:14:10,508:INFO:Declaring metric variables
2023-11-23 01:14:10,509:INFO:Importing untrained model
2023-11-23 01:14:10,510:INFO:K Neighbors Regressor Imported successfully
2023-11-23 01:14:10,514:INFO:Starting cross validation
2023-11-23 01:14:10,514:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:10,606:INFO:Calculating mean and std
2023-11-23 01:14:10,607:INFO:Creating metrics dataframe
2023-11-23 01:14:10,608:INFO:Uploading results into container
2023-11-23 01:14:10,608:INFO:Uploading model into container now
2023-11-23 01:14:10,608:INFO:_master_model_container: 11
2023-11-23 01:14:10,608:INFO:_display_container: 2
2023-11-23 01:14:10,609:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-23 01:14:10,609:INFO:create_model() successfully completed......................................
2023-11-23 01:14:10,651:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:10,651:INFO:Creating metrics dataframe
2023-11-23 01:14:10,656:INFO:Initializing Decision Tree Regressor
2023-11-23 01:14:10,656:INFO:Total runtime is 0.06222096681594848 minutes
2023-11-23 01:14:10,658:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:10,658:INFO:Initializing create_model()
2023-11-23 01:14:10,658:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:10,658:INFO:Checking exceptions
2023-11-23 01:14:10,658:INFO:Importing libraries
2023-11-23 01:14:10,658:INFO:Copying training dataset
2023-11-23 01:14:10,660:INFO:Defining folds
2023-11-23 01:14:10,660:INFO:Declaring metric variables
2023-11-23 01:14:10,662:INFO:Importing untrained model
2023-11-23 01:14:10,663:INFO:Decision Tree Regressor Imported successfully
2023-11-23 01:14:10,666:INFO:Starting cross validation
2023-11-23 01:14:10,667:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:10,803:INFO:Calculating mean and std
2023-11-23 01:14:10,804:INFO:Creating metrics dataframe
2023-11-23 01:14:10,805:INFO:Uploading results into container
2023-11-23 01:14:10,806:INFO:Uploading model into container now
2023-11-23 01:14:10,806:INFO:_master_model_container: 12
2023-11-23 01:14:10,806:INFO:_display_container: 2
2023-11-23 01:14:10,806:INFO:DecisionTreeRegressor(random_state=123)
2023-11-23 01:14:10,806:INFO:create_model() successfully completed......................................
2023-11-23 01:14:10,849:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:10,849:INFO:Creating metrics dataframe
2023-11-23 01:14:10,854:INFO:Initializing Random Forest Regressor
2023-11-23 01:14:10,854:INFO:Total runtime is 0.0655230164527893 minutes
2023-11-23 01:14:10,856:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:10,856:INFO:Initializing create_model()
2023-11-23 01:14:10,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:10,856:INFO:Checking exceptions
2023-11-23 01:14:10,856:INFO:Importing libraries
2023-11-23 01:14:10,856:INFO:Copying training dataset
2023-11-23 01:14:10,859:INFO:Defining folds
2023-11-23 01:14:10,859:INFO:Declaring metric variables
2023-11-23 01:14:10,860:INFO:Importing untrained model
2023-11-23 01:14:10,862:INFO:Random Forest Regressor Imported successfully
2023-11-23 01:14:10,864:INFO:Starting cross validation
2023-11-23 01:14:10,865:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:15,177:INFO:Calculating mean and std
2023-11-23 01:14:15,178:INFO:Creating metrics dataframe
2023-11-23 01:14:15,180:INFO:Uploading results into container
2023-11-23 01:14:15,180:INFO:Uploading model into container now
2023-11-23 01:14:15,180:INFO:_master_model_container: 13
2023-11-23 01:14:15,180:INFO:_display_container: 2
2023-11-23 01:14:15,181:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:14:15,181:INFO:create_model() successfully completed......................................
2023-11-23 01:14:15,225:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:15,225:INFO:Creating metrics dataframe
2023-11-23 01:14:15,231:INFO:Initializing Extra Trees Regressor
2023-11-23 01:14:15,231:INFO:Total runtime is 0.1384640336036682 minutes
2023-11-23 01:14:15,232:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:15,233:INFO:Initializing create_model()
2023-11-23 01:14:15,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:15,233:INFO:Checking exceptions
2023-11-23 01:14:15,233:INFO:Importing libraries
2023-11-23 01:14:15,233:INFO:Copying training dataset
2023-11-23 01:14:15,237:INFO:Defining folds
2023-11-23 01:14:15,237:INFO:Declaring metric variables
2023-11-23 01:14:15,240:INFO:Importing untrained model
2023-11-23 01:14:15,243:INFO:Extra Trees Regressor Imported successfully
2023-11-23 01:14:15,257:INFO:Starting cross validation
2023-11-23 01:14:15,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:17,268:INFO:Calculating mean and std
2023-11-23 01:14:17,269:INFO:Creating metrics dataframe
2023-11-23 01:14:17,272:INFO:Uploading results into container
2023-11-23 01:14:17,272:INFO:Uploading model into container now
2023-11-23 01:14:17,273:INFO:_master_model_container: 14
2023-11-23 01:14:17,273:INFO:_display_container: 2
2023-11-23 01:14:17,273:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:14:17,273:INFO:create_model() successfully completed......................................
2023-11-23 01:14:17,336:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:17,336:INFO:Creating metrics dataframe
2023-11-23 01:14:17,342:INFO:Initializing AdaBoost Regressor
2023-11-23 01:14:17,342:INFO:Total runtime is 0.17364768187204996 minutes
2023-11-23 01:14:17,343:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:17,343:INFO:Initializing create_model()
2023-11-23 01:14:17,343:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:17,343:INFO:Checking exceptions
2023-11-23 01:14:17,344:INFO:Importing libraries
2023-11-23 01:14:17,344:INFO:Copying training dataset
2023-11-23 01:14:17,346:INFO:Defining folds
2023-11-23 01:14:17,346:INFO:Declaring metric variables
2023-11-23 01:14:17,348:INFO:Importing untrained model
2023-11-23 01:14:17,349:INFO:AdaBoost Regressor Imported successfully
2023-11-23 01:14:17,351:INFO:Starting cross validation
2023-11-23 01:14:17,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:18,071:INFO:Calculating mean and std
2023-11-23 01:14:18,072:INFO:Creating metrics dataframe
2023-11-23 01:14:18,073:INFO:Uploading results into container
2023-11-23 01:14:18,074:INFO:Uploading model into container now
2023-11-23 01:14:18,074:INFO:_master_model_container: 15
2023-11-23 01:14:18,074:INFO:_display_container: 2
2023-11-23 01:14:18,074:INFO:AdaBoostRegressor(random_state=123)
2023-11-23 01:14:18,074:INFO:create_model() successfully completed......................................
2023-11-23 01:14:18,116:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:18,117:INFO:Creating metrics dataframe
2023-11-23 01:14:18,123:INFO:Initializing Gradient Boosting Regressor
2023-11-23 01:14:18,123:INFO:Total runtime is 0.1866636355717977 minutes
2023-11-23 01:14:18,124:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:18,124:INFO:Initializing create_model()
2023-11-23 01:14:18,124:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:18,124:INFO:Checking exceptions
2023-11-23 01:14:18,124:INFO:Importing libraries
2023-11-23 01:14:18,124:INFO:Copying training dataset
2023-11-23 01:14:18,127:INFO:Defining folds
2023-11-23 01:14:18,127:INFO:Declaring metric variables
2023-11-23 01:14:18,129:INFO:Importing untrained model
2023-11-23 01:14:18,130:INFO:Gradient Boosting Regressor Imported successfully
2023-11-23 01:14:18,133:INFO:Starting cross validation
2023-11-23 01:14:18,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:20,228:INFO:Calculating mean and std
2023-11-23 01:14:20,229:INFO:Creating metrics dataframe
2023-11-23 01:14:20,231:INFO:Uploading results into container
2023-11-23 01:14:20,231:INFO:Uploading model into container now
2023-11-23 01:14:20,231:INFO:_master_model_container: 16
2023-11-23 01:14:20,231:INFO:_display_container: 2
2023-11-23 01:14:20,231:INFO:GradientBoostingRegressor(random_state=123)
2023-11-23 01:14:20,231:INFO:create_model() successfully completed......................................
2023-11-23 01:14:20,274:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:20,274:INFO:Creating metrics dataframe
2023-11-23 01:14:20,280:INFO:Initializing Extreme Gradient Boosting
2023-11-23 01:14:20,280:INFO:Total runtime is 0.22262589931488036 minutes
2023-11-23 01:14:20,282:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:20,282:INFO:Initializing create_model()
2023-11-23 01:14:20,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:20,282:INFO:Checking exceptions
2023-11-23 01:14:20,282:INFO:Importing libraries
2023-11-23 01:14:20,282:INFO:Copying training dataset
2023-11-23 01:14:20,285:INFO:Defining folds
2023-11-23 01:14:20,285:INFO:Declaring metric variables
2023-11-23 01:14:20,286:INFO:Importing untrained model
2023-11-23 01:14:20,287:INFO:Extreme Gradient Boosting Imported successfully
2023-11-23 01:14:20,290:INFO:Starting cross validation
2023-11-23 01:14:20,291:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:20,385:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-23 01:14:20,386:WARNING:Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


2023-11-23 01:14:20,386:INFO:Initializing create_model()
2023-11-23 01:14:20,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:20,386:INFO:Checking exceptions
2023-11-23 01:14:20,386:INFO:Importing libraries
2023-11-23 01:14:20,386:INFO:Copying training dataset
2023-11-23 01:14:20,388:INFO:Defining folds
2023-11-23 01:14:20,388:INFO:Declaring metric variables
2023-11-23 01:14:20,390:INFO:Importing untrained model
2023-11-23 01:14:20,392:INFO:Extreme Gradient Boosting Imported successfully
2023-11-23 01:14:20,395:INFO:Starting cross validation
2023-11-23 01:14:20,396:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:20,450:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2023-11-23 01:14:20,451:ERROR:Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


2023-11-23 01:14:20,451:INFO:Initializing Light Gradient Boosting Machine
2023-11-23 01:14:20,451:INFO:Total runtime is 0.22546459833780924 minutes
2023-11-23 01:14:20,452:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:20,453:INFO:Initializing create_model()
2023-11-23 01:14:20,453:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:20,453:INFO:Checking exceptions
2023-11-23 01:14:20,453:INFO:Importing libraries
2023-11-23 01:14:20,453:INFO:Copying training dataset
2023-11-23 01:14:20,455:INFO:Defining folds
2023-11-23 01:14:20,455:INFO:Declaring metric variables
2023-11-23 01:14:20,456:INFO:Importing untrained model
2023-11-23 01:14:20,458:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 01:14:20,461:INFO:Starting cross validation
2023-11-23 01:14:20,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:23,193:INFO:Calculating mean and std
2023-11-23 01:14:23,193:INFO:Creating metrics dataframe
2023-11-23 01:14:23,195:INFO:Uploading results into container
2023-11-23 01:14:23,195:INFO:Uploading model into container now
2023-11-23 01:14:23,196:INFO:_master_model_container: 17
2023-11-23 01:14:23,196:INFO:_display_container: 2
2023-11-23 01:14:23,196:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:14:23,196:INFO:create_model() successfully completed......................................
2023-11-23 01:14:23,239:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:23,239:INFO:Creating metrics dataframe
2023-11-23 01:14:23,245:INFO:Initializing Dummy Regressor
2023-11-23 01:14:23,245:INFO:Total runtime is 0.27203896443049114 minutes
2023-11-23 01:14:23,247:INFO:SubProcess create_model() called ==================================
2023-11-23 01:14:23,247:INFO:Initializing create_model()
2023-11-23 01:14:23,247:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1543b77f0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:23,247:INFO:Checking exceptions
2023-11-23 01:14:23,247:INFO:Importing libraries
2023-11-23 01:14:23,247:INFO:Copying training dataset
2023-11-23 01:14:23,249:INFO:Defining folds
2023-11-23 01:14:23,249:INFO:Declaring metric variables
2023-11-23 01:14:23,251:INFO:Importing untrained model
2023-11-23 01:14:23,252:INFO:Dummy Regressor Imported successfully
2023-11-23 01:14:23,255:INFO:Starting cross validation
2023-11-23 01:14:23,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:23,316:INFO:Calculating mean and std
2023-11-23 01:14:23,316:INFO:Creating metrics dataframe
2023-11-23 01:14:23,318:INFO:Uploading results into container
2023-11-23 01:14:23,318:INFO:Uploading model into container now
2023-11-23 01:14:23,318:INFO:_master_model_container: 18
2023-11-23 01:14:23,318:INFO:_display_container: 2
2023-11-23 01:14:23,318:INFO:DummyRegressor()
2023-11-23 01:14:23,318:INFO:create_model() successfully completed......................................
2023-11-23 01:14:23,360:INFO:SubProcess create_model() end ==================================
2023-11-23 01:14:23,360:INFO:Creating metrics dataframe
2023-11-23 01:14:23,370:INFO:Initializing create_model()
2023-11-23 01:14:23,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:23,371:INFO:Checking exceptions
2023-11-23 01:14:23,371:INFO:Importing libraries
2023-11-23 01:14:23,371:INFO:Copying training dataset
2023-11-23 01:14:23,374:INFO:Defining folds
2023-11-23 01:14:23,374:INFO:Declaring metric variables
2023-11-23 01:14:23,374:INFO:Importing untrained model
2023-11-23 01:14:23,374:INFO:Declaring custom model
2023-11-23 01:14:23,374:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 01:14:23,374:INFO:Cross validation set to False
2023-11-23 01:14:23,374:INFO:Fitting Model
2023-11-23 01:14:23,388:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:14:23,389:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
2023-11-23 01:14:23,389:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:14:23,389:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:14:23,390:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:14:23,390:INFO:[LightGBM] [Info] Start training from score 184916.265760
2023-11-23 01:14:23,637:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:14:23,637:INFO:create_model() successfully completed......................................
2023-11-23 01:14:23,682:INFO:Initializing create_model()
2023-11-23 01:14:23,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:23,682:INFO:Checking exceptions
2023-11-23 01:14:23,683:INFO:Importing libraries
2023-11-23 01:14:23,683:INFO:Copying training dataset
2023-11-23 01:14:23,685:INFO:Defining folds
2023-11-23 01:14:23,685:INFO:Declaring metric variables
2023-11-23 01:14:23,686:INFO:Importing untrained model
2023-11-23 01:14:23,686:INFO:Declaring custom model
2023-11-23 01:14:23,686:INFO:Random Forest Regressor Imported successfully
2023-11-23 01:14:23,686:INFO:Cross validation set to False
2023-11-23 01:14:23,686:INFO:Fitting Model
2023-11-23 01:14:24,209:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:14:24,209:INFO:create_model() successfully completed......................................
2023-11-23 01:14:24,256:INFO:Initializing create_model()
2023-11-23 01:14:24,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:24,256:INFO:Checking exceptions
2023-11-23 01:14:24,257:INFO:Importing libraries
2023-11-23 01:14:24,257:INFO:Copying training dataset
2023-11-23 01:14:24,259:INFO:Defining folds
2023-11-23 01:14:24,259:INFO:Declaring metric variables
2023-11-23 01:14:24,259:INFO:Importing untrained model
2023-11-23 01:14:24,259:INFO:Declaring custom model
2023-11-23 01:14:24,260:INFO:Extra Trees Regressor Imported successfully
2023-11-23 01:14:24,260:INFO:Cross validation set to False
2023-11-23 01:14:24,260:INFO:Fitting Model
2023-11-23 01:14:24,489:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:14:24,489:INFO:create_model() successfully completed......................................
2023-11-23 01:14:24,545:INFO:_master_model_container: 18
2023-11-23 01:14:24,545:INFO:_display_container: 2
2023-11-23 01:14:24,545:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)]
2023-11-23 01:14:24,546:INFO:compare_models() successfully completed......................................
2023-11-23 01:14:48,556:INFO:Initializing create_model()
2023-11-23 01:14:48,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:48,557:INFO:Checking exceptions
2023-11-23 01:14:48,585:INFO:Importing libraries
2023-11-23 01:14:48,585:INFO:Copying training dataset
2023-11-23 01:14:48,589:INFO:Defining folds
2023-11-23 01:14:48,589:INFO:Declaring metric variables
2023-11-23 01:14:48,591:INFO:Importing untrained model
2023-11-23 01:14:48,591:INFO:Declaring custom model
2023-11-23 01:14:48,593:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 01:14:48,597:INFO:Starting cross validation
2023-11-23 01:14:48,598:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:51,130:INFO:Calculating mean and std
2023-11-23 01:14:51,131:INFO:Creating metrics dataframe
2023-11-23 01:14:51,133:INFO:Finalizing model
2023-11-23 01:14:51,147:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:14:51,148:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000251 seconds.
2023-11-23 01:14:51,148:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 01:14:51,148:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 01:14:51,148:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:14:51,148:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:14:51,148:INFO:[LightGBM] [Info] Start training from score 184916.265760
2023-11-23 01:14:51,444:INFO:Uploading results into container
2023-11-23 01:14:51,445:INFO:Uploading model into container now
2023-11-23 01:14:51,450:INFO:_master_model_container: 19
2023-11-23 01:14:51,450:INFO:_display_container: 3
2023-11-23 01:14:51,450:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:14:51,450:INFO:create_model() successfully completed......................................
2023-11-23 01:14:51,516:INFO:Initializing create_model()
2023-11-23 01:14:51,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:51,516:INFO:Checking exceptions
2023-11-23 01:14:51,522:INFO:Importing libraries
2023-11-23 01:14:51,522:INFO:Copying training dataset
2023-11-23 01:14:51,525:INFO:Defining folds
2023-11-23 01:14:51,525:INFO:Declaring metric variables
2023-11-23 01:14:51,527:INFO:Importing untrained model
2023-11-23 01:14:51,527:INFO:Declaring custom model
2023-11-23 01:14:51,528:INFO:Random Forest Regressor Imported successfully
2023-11-23 01:14:51,532:INFO:Starting cross validation
2023-11-23 01:14:51,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:55,817:INFO:Calculating mean and std
2023-11-23 01:14:55,818:INFO:Creating metrics dataframe
2023-11-23 01:14:55,821:INFO:Finalizing model
2023-11-23 01:14:56,322:INFO:Uploading results into container
2023-11-23 01:14:56,323:INFO:Uploading model into container now
2023-11-23 01:14:56,328:INFO:_master_model_container: 20
2023-11-23 01:14:56,328:INFO:_display_container: 4
2023-11-23 01:14:56,328:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:14:56,329:INFO:create_model() successfully completed......................................
2023-11-23 01:14:56,385:INFO:Initializing create_model()
2023-11-23 01:14:56,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:14:56,385:INFO:Checking exceptions
2023-11-23 01:14:56,392:INFO:Importing libraries
2023-11-23 01:14:56,392:INFO:Copying training dataset
2023-11-23 01:14:56,399:INFO:Defining folds
2023-11-23 01:14:56,399:INFO:Declaring metric variables
2023-11-23 01:14:56,400:INFO:Importing untrained model
2023-11-23 01:14:56,401:INFO:Declaring custom model
2023-11-23 01:14:56,403:INFO:Extra Trees Regressor Imported successfully
2023-11-23 01:14:56,406:INFO:Starting cross validation
2023-11-23 01:14:56,407:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:14:58,474:INFO:Calculating mean and std
2023-11-23 01:14:58,475:INFO:Creating metrics dataframe
2023-11-23 01:14:58,481:INFO:Finalizing model
2023-11-23 01:14:58,728:INFO:Uploading results into container
2023-11-23 01:14:58,729:INFO:Uploading model into container now
2023-11-23 01:14:58,734:INFO:_master_model_container: 21
2023-11-23 01:14:58,735:INFO:_display_container: 5
2023-11-23 01:14:58,735:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:14:58,735:INFO:create_model() successfully completed......................................
2023-11-23 01:15:51,123:INFO:Initializing tune_model()
2023-11-23 01:15:51,123:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=100, custom_grid={'num_leaves': [50, 75, 100], 'max_depth': [-1, 10, 20], 'min_child_samples': [10, 20, 30], 'subsample': [0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [50, 100, 200], 'reg_alpha': [0, 0.1, 0.5, 1], 'reg_lambda': [0, 0.1, 0.5, 1], 'max_bin': [255, 355, 455], 'boosting_type': ['gbdt', 'dart']}, optimize=mape, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>)
2023-11-23 01:15:51,123:INFO:Checking exceptions
2023-11-23 01:15:51,139:INFO:Copying training dataset
2023-11-23 01:15:51,143:INFO:Checking base model
2023-11-23 01:15:51,143:INFO:Base model : Light Gradient Boosting Machine
2023-11-23 01:15:51,145:INFO:Declaring metric variables
2023-11-23 01:15:51,146:INFO:Defining Hyperparameters
2023-11-23 01:15:51,241:INFO:custom_grid: {'actual_estimator__num_leaves': [50, 75, 100], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__min_child_samples': [10, 20, 30], 'actual_estimator__subsample': [0.7, 0.8, 0.9, 1.0], 'actual_estimator__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [50, 100, 200], 'actual_estimator__reg_alpha': [0, 0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0, 0.1, 0.5, 1], 'actual_estimator__max_bin': [255, 355, 455], 'actual_estimator__boosting_type': ['gbdt', 'dart']}
2023-11-23 01:15:51,241:INFO:Tuning with n_jobs=-1
2023-11-23 01:15:51,241:INFO:Initializing RandomizedSearchCV
2023-11-23 01:26:37,044:INFO:best_params: {'actual_estimator__subsample': 1.0, 'actual_estimator__reg_lambda': 1, 'actual_estimator__reg_alpha': 0, 'actual_estimator__num_leaves': 75, 'actual_estimator__n_estimators': 200, 'actual_estimator__min_child_samples': 20, 'actual_estimator__max_depth': 20, 'actual_estimator__max_bin': 255, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__colsample_bytree': 0.9, 'actual_estimator__boosting_type': 'dart'}
2023-11-23 01:26:37,051:INFO:Hyperparameter search completed
2023-11-23 01:26:37,052:INFO:SubProcess create_model() called ==================================
2023-11-23 01:26:37,053:INFO:Initializing create_model()
2023-11-23 01:26:37,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x166942f70>, model_only=True, return_train_score=True, kwargs={'subsample': 1.0, 'reg_lambda': 1, 'reg_alpha': 0, 'num_leaves': 75, 'n_estimators': 200, 'min_child_samples': 20, 'max_depth': 20, 'max_bin': 255, 'learning_rate': 0.1, 'colsample_bytree': 0.9, 'boosting_type': 'dart'})
2023-11-23 01:26:37,053:INFO:Checking exceptions
2023-11-23 01:26:37,053:INFO:Importing libraries
2023-11-23 01:26:37,054:INFO:Copying training dataset
2023-11-23 01:26:37,058:INFO:Defining folds
2023-11-23 01:26:37,058:INFO:Declaring metric variables
2023-11-23 01:26:37,061:INFO:Importing untrained model
2023-11-23 01:26:37,061:INFO:Declaring custom model
2023-11-23 01:26:37,063:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 01:26:37,066:INFO:Starting cross validation
2023-11-23 01:26:37,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:26:50,805:INFO:Calculating mean and std
2023-11-23 01:26:50,806:INFO:Creating metrics dataframe
2023-11-23 01:26:50,812:INFO:Finalizing model
2023-11-23 01:26:50,826:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:26:50,827:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000551 seconds.
2023-11-23 01:26:50,827:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:26:50,827:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:26:50,827:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:26:50,827:INFO:[LightGBM] [Info] Start training from score 184916.265760
2023-11-23 01:26:50,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:26:51,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:26:51,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:26:51,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:26:51,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:26:51,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:26:51,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:26:51,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:26:52,384:INFO:Initializing predict_model()
2023-11-23 01:26:52,384:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=255, max_depth=20, n_estimators=200,
                               n_jobs=-1, num_leaves=75, random_state=123,
                               reg_alpha=0, reg_lambda=1))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x1578ffe50>)
2023-11-23 01:26:52,384:INFO:Checking exceptions
2023-11-23 01:26:52,384:INFO:Preloading libraries
2023-11-23 01:26:52,384:INFO:Set up data.
2023-11-23 01:26:52,389:INFO:Set up index.
2023-11-23 01:26:52,504:INFO:Uploading results into container
2023-11-23 01:26:52,505:INFO:Uploading model into container now
2023-11-23 01:26:52,505:INFO:_master_model_container: 22
2023-11-23 01:26:52,506:INFO:_display_container: 6
2023-11-23 01:26:52,506:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=255,
              max_depth=20, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=0, reg_lambda=1)
2023-11-23 01:26:52,506:INFO:create_model() successfully completed......................................
2023-11-23 01:26:52,552:INFO:SubProcess create_model() end ==================================
2023-11-23 01:26:52,553:INFO:choose_better activated
2023-11-23 01:26:52,554:INFO:SubProcess create_model() called ==================================
2023-11-23 01:26:52,554:INFO:Initializing create_model()
2023-11-23 01:26:52,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:26:52,555:INFO:Checking exceptions
2023-11-23 01:26:52,556:INFO:Importing libraries
2023-11-23 01:26:52,556:INFO:Copying training dataset
2023-11-23 01:26:52,557:INFO:Defining folds
2023-11-23 01:26:52,557:INFO:Declaring metric variables
2023-11-23 01:26:52,558:INFO:Importing untrained model
2023-11-23 01:26:52,558:INFO:Declaring custom model
2023-11-23 01:26:52,558:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 01:26:52,558:INFO:Starting cross validation
2023-11-23 01:26:52,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:26:55,101:INFO:Calculating mean and std
2023-11-23 01:26:55,101:INFO:Creating metrics dataframe
2023-11-23 01:26:55,102:INFO:Finalizing model
2023-11-23 01:26:55,114:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:26:55,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
2023-11-23 01:26:55,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:26:55,115:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:26:55,115:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:26:55,115:INFO:[LightGBM] [Info] Start training from score 184916.265760
2023-11-23 01:26:55,358:INFO:Uploading results into container
2023-11-23 01:26:55,358:INFO:Uploading model into container now
2023-11-23 01:26:55,358:INFO:_master_model_container: 23
2023-11-23 01:26:55,358:INFO:_display_container: 7
2023-11-23 01:26:55,359:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:26:55,359:INFO:create_model() successfully completed......................................
2023-11-23 01:26:55,401:INFO:SubProcess create_model() end ==================================
2023-11-23 01:26:55,401:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.1859
2023-11-23 01:26:55,403:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=255,
              max_depth=20, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=0, reg_lambda=1) result for MAPE is 0.1748
2023-11-23 01:26:55,403:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=255,
              max_depth=20, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=0, reg_lambda=1) is best model
2023-11-23 01:26:55,403:INFO:choose_better completed
2023-11-23 01:26:55,411:INFO:_master_model_container: 23
2023-11-23 01:26:55,411:INFO:_display_container: 6
2023-11-23 01:26:55,411:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=255,
              max_depth=20, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=0, reg_lambda=1)
2023-11-23 01:26:55,411:INFO:tune_model() successfully completed......................................
2023-11-23 01:26:55,454:INFO:Initializing tune_model()
2023-11-23 01:26:55,455:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150], 'max_depth': [None, 3, 5, 7, 9], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2'], 'bootstrap': [True, False]}, optimize=mape, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>)
2023-11-23 01:26:55,455:INFO:Checking exceptions
2023-11-23 01:26:55,462:INFO:Copying training dataset
2023-11-23 01:26:55,464:INFO:Checking base model
2023-11-23 01:26:55,464:INFO:Base model : Random Forest Regressor
2023-11-23 01:26:55,466:INFO:Declaring metric variables
2023-11-23 01:26:55,467:INFO:Defining Hyperparameters
2023-11-23 01:26:55,512:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150], 'actual_estimator__max_depth': [None, 3, 5, 7, 9], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__min_samples_leaf': [1, 2, 4], 'actual_estimator__max_features': ['auto', 'sqrt', 'log2'], 'actual_estimator__bootstrap': [True, False]}
2023-11-23 01:26:55,513:INFO:Tuning with n_jobs=-1
2023-11-23 01:26:55,513:INFO:Initializing RandomizedSearchCV
2023-11-23 01:26:55,537:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:26:55,541:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:26:55,542:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:26:55,551:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:26:55,561:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:26:55,565:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:26:55,697:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:26:55,744:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:26:58,818:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:26:58,891:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:00,386:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:00,483:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:01,280:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:01,293:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:01,301:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:01,334:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:01,394:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:01,707:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:05,498:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:05,797:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:06,228:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:06,303:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:06,332:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:06,474:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:06,539:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:06,546:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:06,562:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:06,682:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:06,827:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:06,862:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:07,994:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:08,207:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:08,518:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:08,563:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:08,753:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:08,846:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:08,860:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:08,925:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:08,940:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:09,055:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:14,228:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:14,236:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:14,248:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:14,367:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:14,670:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:14,804:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:14,809:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:15,002:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:15,161:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:15,255:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:15,332:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:15,350:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:15,354:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:15,428:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:15,497:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:15,678:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:15,774:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:16,119:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:22,196:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:22,315:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:35,136:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:35,393:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:35,444:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:35,557:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:35,570:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:35,800:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:35,987:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:35,993:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:36,598:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:36,709:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:36,789:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:36,892:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:36,894:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:37,032:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:37,220:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:37,245:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:37,421:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:37,500:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:37,538:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:37,631:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:41,364:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:41,425:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:41,493:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:41,719:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:41,926:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:42,218:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:42,398:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:42,415:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:42,610:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:42,818:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:42,920:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:42,961:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:43,468:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:43,471:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:43,827:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:43,856:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:43,996:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:44,168:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:44,263:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:44,307:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:44,837:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:44,839:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:44,962:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,044:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,084:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,170:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,190:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,196:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,201:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,256:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,710:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,728:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,808:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,826:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,831:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:45,964:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:46,119:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:46,166:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:46,299:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:46,301:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:48,368:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:48,386:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:48,394:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:48,412:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:48,471:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:48,512:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:48,538:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:48,541:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:48,543:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:48,558:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:49,164:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:49,337:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:49,354:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:49,372:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:49,430:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:49,477:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:49,820:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:49,876:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:50,858:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:51,246:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:51,325:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:51,335:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:51,420:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:51,531:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:51,705:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:51,755:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:52,515:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:53,035:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:54,174:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:54,310:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:54,459:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:54,570:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:54,618:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:54,674:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:55,415:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:56,045:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:56,199:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:56,682:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:56,746:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:56,747:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:59,628:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:59,671:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:59,699:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:59,704:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:59,791:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:59,805:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:59,867:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:27:59,968:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:00,548:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:00,645:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:09,688:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:09,698:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:09,710:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:09,875:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:09,893:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:09,928:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:09,945:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:09,962:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:09,967:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:10,053:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:10,084:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:10,099:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:10,128:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:10,132:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:10,136:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:10,200:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:10,227:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:10,286:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:11,783:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:11,796:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:12,715:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:12,816:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:13,028:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:13,121:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:13,163:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:13,315:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:13,322:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:13,512:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:16,520:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:16,600:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:16,778:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:16,816:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:16,945:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:17,213:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:17,309:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:17,315:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:19,571:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:19,619:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:19,638:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:19,812:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:21,916:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:21,994:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,154:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,263:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,291:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,358:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,359:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,431:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,446:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,490:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,524:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,527:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,588:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,617:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,626:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,710:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,821:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:22,949:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:23,714:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:23,875:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:28,288:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:28,295:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:28,446:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:28,496:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:28,622:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:28,628:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:28,964:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:28,971:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:30,229:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:30,569:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:31,863:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:31,983:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:32,023:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:32,136:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:32,150:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:32,276:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:32,306:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:32,799:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:34,060:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:34,065:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:35,592:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:36,114:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:36,134:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:36,145:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:36,252:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:36,315:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:36,514:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:36,751:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:38,548:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,160:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,341:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,343:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,399:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,528:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,541:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,575:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,575:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,780:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,822:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,835:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,859:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,860:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:39,916:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:40,062:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:40,070:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:40,077:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:41,598:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:42,453:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:42,935:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:43,020:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:43,073:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:43,094:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:43,114:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:43,453:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:44,676:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:45,616:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:46,054:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:46,287:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:47,436:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:47,574:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:52,025:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:52,029:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:52,042:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:52,050:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:52,059:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:52,068:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:52,165:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:52,216:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:54,871:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:54,970:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:55,379:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:55,397:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:55,420:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:55,440:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:55,503:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:55,518:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:57,578:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:57,751:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:59,763:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:28:59,997:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:02,388:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_features': 'auto', 'actual_estimator__max_depth': None, 'actual_estimator__bootstrap': True}
2023-11-23 01:29:02,389:INFO:Hyperparameter search completed
2023-11-23 01:29:02,390:INFO:SubProcess create_model() called ==================================
2023-11-23 01:29:02,390:INFO:Initializing create_model()
2023-11-23 01:29:02,390:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1697a2130>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': None, 'bootstrap': True})
2023-11-23 01:29:02,390:INFO:Checking exceptions
2023-11-23 01:29:02,391:INFO:Importing libraries
2023-11-23 01:29:02,391:INFO:Copying training dataset
2023-11-23 01:29:02,395:INFO:Defining folds
2023-11-23 01:29:02,395:INFO:Declaring metric variables
2023-11-23 01:29:02,398:INFO:Importing untrained model
2023-11-23 01:29:02,398:INFO:Declaring custom model
2023-11-23 01:29:02,400:INFO:Random Forest Regressor Imported successfully
2023-11-23 01:29:02,403:INFO:Starting cross validation
2023-11-23 01:29:02,404:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:29:02,427:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:02,433:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:02,433:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:02,435:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:02,436:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:02,438:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:02,447:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:02,466:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:07,369:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:07,620:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:08,936:INFO:Calculating mean and std
2023-11-23 01:29:08,937:INFO:Creating metrics dataframe
2023-11-23 01:29:08,943:INFO:Finalizing model
2023-11-23 01:29:09,712:INFO:Initializing predict_model()
2023-11-23 01:29:09,712:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 RandomForestRegressor(max_features='auto', n_estimators=150,
                                       n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x166bef790>)
2023-11-23 01:29:09,712:INFO:Checking exceptions
2023-11-23 01:29:09,712:INFO:Preloading libraries
2023-11-23 01:29:09,712:INFO:Set up data.
2023-11-23 01:29:09,715:INFO:Set up index.
2023-11-23 01:29:09,840:INFO:Uploading results into container
2023-11-23 01:29:09,840:INFO:Uploading model into container now
2023-11-23 01:29:09,841:INFO:_master_model_container: 24
2023-11-23 01:29:09,841:INFO:_display_container: 7
2023-11-23 01:29:09,842:INFO:RandomForestRegressor(max_features='auto', n_estimators=150, n_jobs=-1,
                      random_state=123)
2023-11-23 01:29:09,842:INFO:create_model() successfully completed......................................
2023-11-23 01:29:09,884:INFO:SubProcess create_model() end ==================================
2023-11-23 01:29:09,884:INFO:choose_better activated
2023-11-23 01:29:09,886:INFO:SubProcess create_model() called ==================================
2023-11-23 01:29:09,886:INFO:Initializing create_model()
2023-11-23 01:29:09,886:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:29:09,886:INFO:Checking exceptions
2023-11-23 01:29:09,887:INFO:Importing libraries
2023-11-23 01:29:09,887:INFO:Copying training dataset
2023-11-23 01:29:09,890:INFO:Defining folds
2023-11-23 01:29:09,890:INFO:Declaring metric variables
2023-11-23 01:29:09,890:INFO:Importing untrained model
2023-11-23 01:29:09,890:INFO:Declaring custom model
2023-11-23 01:29:09,890:INFO:Random Forest Regressor Imported successfully
2023-11-23 01:29:09,890:INFO:Starting cross validation
2023-11-23 01:29:09,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:29:14,074:INFO:Calculating mean and std
2023-11-23 01:29:14,075:INFO:Creating metrics dataframe
2023-11-23 01:29:14,076:INFO:Finalizing model
2023-11-23 01:29:14,571:INFO:Uploading results into container
2023-11-23 01:29:14,571:INFO:Uploading model into container now
2023-11-23 01:29:14,572:INFO:_master_model_container: 25
2023-11-23 01:29:14,572:INFO:_display_container: 8
2023-11-23 01:29:14,572:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:29:14,572:INFO:create_model() successfully completed......................................
2023-11-23 01:29:14,616:INFO:SubProcess create_model() end ==================================
2023-11-23 01:29:14,617:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.1978
2023-11-23 01:29:14,617:INFO:RandomForestRegressor(max_features='auto', n_estimators=150, n_jobs=-1,
                      random_state=123) result for MAPE is 0.1977
2023-11-23 01:29:14,617:INFO:RandomForestRegressor(max_features='auto', n_estimators=150, n_jobs=-1,
                      random_state=123) is best model
2023-11-23 01:29:14,617:INFO:choose_better completed
2023-11-23 01:29:14,624:INFO:_master_model_container: 25
2023-11-23 01:29:14,624:INFO:_display_container: 7
2023-11-23 01:29:14,624:INFO:RandomForestRegressor(max_features='auto', n_estimators=150, n_jobs=-1,
                      random_state=123)
2023-11-23 01:29:14,624:INFO:tune_model() successfully completed......................................
2023-11-23 01:29:14,667:INFO:Initializing tune_model()
2023-11-23 01:29:14,667:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150], 'max_depth': [None, 3, 5, 7, 9], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2'], 'bootstrap': [True, False]}, optimize=mape, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>)
2023-11-23 01:29:14,667:INFO:Checking exceptions
2023-11-23 01:29:14,675:INFO:Copying training dataset
2023-11-23 01:29:14,677:INFO:Checking base model
2023-11-23 01:29:14,677:INFO:Base model : Extra Trees Regressor
2023-11-23 01:29:14,679:INFO:Declaring metric variables
2023-11-23 01:29:14,680:INFO:Defining Hyperparameters
2023-11-23 01:29:14,726:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150], 'actual_estimator__max_depth': [None, 3, 5, 7, 9], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__min_samples_leaf': [1, 2, 4], 'actual_estimator__max_features': ['auto', 'sqrt', 'log2'], 'actual_estimator__bootstrap': [True, False]}
2023-11-23 01:29:14,726:INFO:Tuning with n_jobs=-1
2023-11-23 01:29:14,726:INFO:Initializing RandomizedSearchCV
2023-11-23 01:29:14,745:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:14,760:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:14,770:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:14,777:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:14,794:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:14,852:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:14,993:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:15,002:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:15,433:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:15,613:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:16,411:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:16,513:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:16,519:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:16,523:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:16,747:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:16,805:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:16,808:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:16,827:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:17,876:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:17,947:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:17,971:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,133:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,155:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,246:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,270:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,339:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,346:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,347:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,350:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,352:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,817:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,818:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,916:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,963:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,971:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:18,996:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:19,009:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:19,012:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:19,038:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:19,044:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,018:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,091:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,109:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,178:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,252:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,271:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,293:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,348:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,354:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,423:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,464:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,467:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,469:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,494:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,521:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,544:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,552:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:21,684:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:22,971:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:22,985:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:27,881:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:27,918:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:27,919:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,051:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,059:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,094:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,233:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,243:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,317:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,317:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,442:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,446:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,501:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,512:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,515:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,594:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,630:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,639:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,663:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:28,754:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:29,619:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:29,658:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:29,726:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:29,737:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:29,745:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:29,955:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,062:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,075:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,075:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,113:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,132:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,203:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,347:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,351:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,450:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,461:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,474:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,490:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,565:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,624:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,649:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,653:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,675:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,682:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,695:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,715:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,717:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,729:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,751:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:30,789:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:31,007:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:31,015:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:31,025:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:31,147:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:31,148:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:31,166:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:31,189:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:31,213:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:31,341:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:31,364:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,239:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,240:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,247:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,332:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,333:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,338:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,340:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,348:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,412:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,423:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,456:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,534:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,534:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,699:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,766:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,792:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,888:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,907:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,911:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,931:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:32,939:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,002:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,010:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,187:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,222:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,223:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,415:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,417:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,445:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,503:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,506:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,584:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,600:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,607:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,834:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,843:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,889:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:33,926:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:34,164:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:34,168:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:34,976:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:34,979:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:35,020:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:35,084:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:35,111:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:35,115:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:35,123:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:35,238:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:35,244:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:35,292:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,656:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,698:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,705:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,753:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,770:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,770:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,770:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,780:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,786:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,835:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,853:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,868:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,876:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,884:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:38,906:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,054:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,190:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,202:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,202:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,336:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,475:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,568:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,569:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,573:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,582:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:39,700:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,028:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,035:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,051:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,074:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,078:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,086:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,109:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,476:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,591:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,662:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,667:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:40,669:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,025:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,256:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,324:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,505:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,519:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,637:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,639:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,644:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,647:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,656:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,717:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,725:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,733:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,737:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,756:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,760:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,782:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,818:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,863:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,893:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:41,958:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:42,014:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:43,566:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:43,593:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:43,602:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:43,865:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:43,886:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:43,959:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:43,962:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:44,027:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:44,283:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:44,434:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:44,449:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:44,518:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:44,665:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:44,709:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:44,720:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:44,765:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,054:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,059:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,109:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,169:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,430:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,447:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,545:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,589:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,655:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,716:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,899:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,935:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:45,995:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,059:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,075:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,090:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,095:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,161:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,201:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,247:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,254:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,255:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,335:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,392:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,407:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,411:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,521:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,587:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,700:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,712:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,844:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:46,996:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:47,056:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:47,121:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:47,258:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:47,349:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:47,398:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:47,439:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:47,525:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:47,673:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:47,780:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:47,857:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:48,432:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:48,510:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:49,321:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:49,323:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:49,328:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:49,335:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:49,366:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:49,383:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:49,527:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:49,586:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:49,679:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:49,700:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:50,059:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:50,064:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:50,068:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:50,086:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:50,158:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:50,178:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:50,198:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:50,210:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:50,684:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:50,703:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:51,435:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_features': 'auto', 'actual_estimator__max_depth': None, 'actual_estimator__bootstrap': False}
2023-11-23 01:29:51,437:INFO:Hyperparameter search completed
2023-11-23 01:29:51,437:INFO:SubProcess create_model() called ==================================
2023-11-23 01:29:51,438:INFO:Initializing create_model()
2023-11-23 01:29:51,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x11f77e040>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': None, 'bootstrap': False})
2023-11-23 01:29:51,438:INFO:Checking exceptions
2023-11-23 01:29:51,438:INFO:Importing libraries
2023-11-23 01:29:51,438:INFO:Copying training dataset
2023-11-23 01:29:51,442:INFO:Defining folds
2023-11-23 01:29:51,442:INFO:Declaring metric variables
2023-11-23 01:29:51,444:INFO:Importing untrained model
2023-11-23 01:29:51,444:INFO:Declaring custom model
2023-11-23 01:29:51,446:INFO:Extra Trees Regressor Imported successfully
2023-11-23 01:29:51,449:INFO:Starting cross validation
2023-11-23 01:29:51,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:29:51,468:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:51,469:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:51,472:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:51,473:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:51,484:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:51,490:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:51,494:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:51,505:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:53,127:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:53,157:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:29:53,865:INFO:Calculating mean and std
2023-11-23 01:29:53,866:INFO:Creating metrics dataframe
2023-11-23 01:29:53,869:INFO:Finalizing model
2023-11-23 01:29:54,166:INFO:Initializing predict_model()
2023-11-23 01:29:54,166:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 ExtraTreesRegressor(max_features='auto', min_samples_leaf=2,
                                     n_estimators=150, n_jobs=-1,
                                     random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x169586940>)
2023-11-23 01:29:54,166:INFO:Checking exceptions
2023-11-23 01:29:54,166:INFO:Preloading libraries
2023-11-23 01:29:54,166:INFO:Set up data.
2023-11-23 01:29:54,169:INFO:Set up index.
2023-11-23 01:29:54,292:INFO:Uploading results into container
2023-11-23 01:29:54,292:INFO:Uploading model into container now
2023-11-23 01:29:54,293:INFO:_master_model_container: 26
2023-11-23 01:29:54,293:INFO:_display_container: 8
2023-11-23 01:29:54,293:INFO:ExtraTreesRegressor(max_features='auto', min_samples_leaf=2, n_estimators=150,
                    n_jobs=-1, random_state=123)
2023-11-23 01:29:54,293:INFO:create_model() successfully completed......................................
2023-11-23 01:29:54,336:INFO:SubProcess create_model() end ==================================
2023-11-23 01:29:54,336:INFO:choose_better activated
2023-11-23 01:29:54,337:INFO:SubProcess create_model() called ==================================
2023-11-23 01:29:54,338:INFO:Initializing create_model()
2023-11-23 01:29:54,338:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:29:54,338:INFO:Checking exceptions
2023-11-23 01:29:54,339:INFO:Importing libraries
2023-11-23 01:29:54,339:INFO:Copying training dataset
2023-11-23 01:29:54,341:INFO:Defining folds
2023-11-23 01:29:54,341:INFO:Declaring metric variables
2023-11-23 01:29:54,341:INFO:Importing untrained model
2023-11-23 01:29:54,341:INFO:Declaring custom model
2023-11-23 01:29:54,341:INFO:Extra Trees Regressor Imported successfully
2023-11-23 01:29:54,342:INFO:Starting cross validation
2023-11-23 01:29:54,342:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:29:56,310:INFO:Calculating mean and std
2023-11-23 01:29:56,310:INFO:Creating metrics dataframe
2023-11-23 01:29:56,313:INFO:Finalizing model
2023-11-23 01:29:56,554:INFO:Uploading results into container
2023-11-23 01:29:56,555:INFO:Uploading model into container now
2023-11-23 01:29:56,555:INFO:_master_model_container: 27
2023-11-23 01:29:56,555:INFO:_display_container: 9
2023-11-23 01:29:56,555:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:29:56,555:INFO:create_model() successfully completed......................................
2023-11-23 01:29:56,601:INFO:SubProcess create_model() end ==================================
2023-11-23 01:29:56,602:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.2117
2023-11-23 01:29:56,602:INFO:ExtraTreesRegressor(max_features='auto', min_samples_leaf=2, n_estimators=150,
                    n_jobs=-1, random_state=123) result for MAPE is 0.2127
2023-11-23 01:29:56,602:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2023-11-23 01:29:56,602:INFO:choose_better completed
2023-11-23 01:29:56,602:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-11-23 01:29:56,609:INFO:_master_model_container: 27
2023-11-23 01:29:56,609:INFO:_display_container: 8
2023-11-23 01:29:56,610:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:29:56,610:INFO:tune_model() successfully completed......................................
2023-11-23 01:48:40,307:INFO:Initializing create_model()
2023-11-23 01:48:40,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=lightgbm, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:48:40,308:INFO:Checking exceptions
2023-11-23 01:48:40,331:INFO:Importing libraries
2023-11-23 01:48:40,332:INFO:Copying training dataset
2023-11-23 01:48:40,338:INFO:Defining folds
2023-11-23 01:48:40,338:INFO:Declaring metric variables
2023-11-23 01:48:40,340:INFO:Importing untrained model
2023-11-23 01:48:40,342:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 01:48:40,346:INFO:Cross validation set to False
2023-11-23 01:48:40,346:INFO:Fitting Model
2023-11-23 01:48:40,373:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:40,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.
2023-11-23 01:48:40,377:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 01:48:40,377:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 01:48:40,377:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:48:40,377:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:48:40,378:INFO:[LightGBM] [Info] Start training from score 184916.265760
2023-11-23 01:48:40,691:INFO:Initializing predict_model()
2023-11-23 01:48:40,692:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x1695deee0>)
2023-11-23 01:48:40,692:INFO:Checking exceptions
2023-11-23 01:48:40,692:INFO:Preloading libraries
2023-11-23 01:48:40,820:INFO:_display_container: 9
2023-11-23 01:48:40,820:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:48:40,820:INFO:create_model() successfully completed......................................
2023-11-23 01:48:40,881:INFO:Initializing create_model()
2023-11-23 01:48:40,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=rf, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:48:40,881:INFO:Checking exceptions
2023-11-23 01:48:40,888:INFO:Importing libraries
2023-11-23 01:48:40,888:INFO:Copying training dataset
2023-11-23 01:48:40,892:INFO:Defining folds
2023-11-23 01:48:40,892:INFO:Declaring metric variables
2023-11-23 01:48:40,894:INFO:Importing untrained model
2023-11-23 01:48:40,896:INFO:Random Forest Regressor Imported successfully
2023-11-23 01:48:40,900:INFO:Cross validation set to False
2023-11-23 01:48:40,900:INFO:Fitting Model
2023-11-23 01:48:41,482:INFO:Initializing predict_model()
2023-11-23 01:48:41,482:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x169586af0>)
2023-11-23 01:48:41,482:INFO:Checking exceptions
2023-11-23 01:48:41,482:INFO:Preloading libraries
2023-11-23 01:48:41,593:INFO:_display_container: 10
2023-11-23 01:48:41,593:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:48:41,593:INFO:create_model() successfully completed......................................
2023-11-23 01:48:41,645:INFO:Initializing create_model()
2023-11-23 01:48:41,645:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=et, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:48:41,645:INFO:Checking exceptions
2023-11-23 01:48:41,651:INFO:Importing libraries
2023-11-23 01:48:41,651:INFO:Copying training dataset
2023-11-23 01:48:41,655:INFO:Defining folds
2023-11-23 01:48:41,655:INFO:Declaring metric variables
2023-11-23 01:48:41,657:INFO:Importing untrained model
2023-11-23 01:48:41,658:INFO:Extra Trees Regressor Imported successfully
2023-11-23 01:48:41,661:INFO:Cross validation set to False
2023-11-23 01:48:41,661:INFO:Fitting Model
2023-11-23 01:48:41,964:INFO:Initializing predict_model()
2023-11-23 01:48:41,965:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x16201fca0>)
2023-11-23 01:48:41,965:INFO:Checking exceptions
2023-11-23 01:48:41,965:INFO:Preloading libraries
2023-11-23 01:48:42,060:INFO:_display_container: 11
2023-11-23 01:48:42,060:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:48:42,060:INFO:create_model() successfully completed......................................
2023-11-23 01:48:51,532:INFO:Initializing create_model()
2023-11-23 01:48:51,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:48:51,532:INFO:Checking exceptions
2023-11-23 01:48:51,542:INFO:Importing libraries
2023-11-23 01:48:51,542:INFO:Copying training dataset
2023-11-23 01:48:51,546:INFO:Defining folds
2023-11-23 01:48:51,546:INFO:Declaring metric variables
2023-11-23 01:48:51,548:INFO:Importing untrained model
2023-11-23 01:48:51,551:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 01:48:51,555:INFO:Starting cross validation
2023-11-23 01:48:51,556:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:48:53,607:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:53,608:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:53,609:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.
2023-11-23 01:48:53,609:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:48:53,609:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:48:53,609:INFO:[LightGBM] [Info] Number of data points in the train set: 5953, number of used features: 12
2023-11-23 01:48:53,610:INFO:[LightGBM] [Info] Start training from score 184922.996472
2023-11-23 01:48:53,610:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001468 seconds.
2023-11-23 01:48:53,611:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:48:53,611:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:48:53,611:INFO:[LightGBM] [Info] Number of data points in the train set: 5954, number of used features: 12
2023-11-23 01:48:53,615:INFO:[LightGBM] [Info] Start training from score 185064.695667
2023-11-23 01:48:53,615:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:53,615:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:53,618:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001791 seconds.
2023-11-23 01:48:53,618:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:48:53,618:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:48:53,618:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001545 seconds.
2023-11-23 01:48:53,618:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:48:53,618:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:48:53,618:INFO:[LightGBM] [Info] Number of data points in the train set: 5953, number of used features: 12
2023-11-23 01:48:53,618:INFO:[LightGBM] [Info] Number of data points in the train set: 5953, number of used features: 12
2023-11-23 01:48:53,619:INFO:[LightGBM] [Info] Start training from score 185643.608097
2023-11-23 01:48:53,619:INFO:[LightGBM] [Info] Start training from score 184899.596506
2023-11-23 01:48:53,620:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:53,624:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:53,625:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000956 seconds.
2023-11-23 01:48:53,625:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:48:53,626:INFO:[LightGBM] [Info] Total Bins 1845
2023-11-23 01:48:53,626:INFO:[LightGBM] [Info] Number of data points in the train set: 5954, number of used features: 12
2023-11-23 01:48:53,626:INFO:[LightGBM] [Info] Start training from score 184408.481357
2023-11-23 01:48:53,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002163 seconds.
2023-11-23 01:48:53,635:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 01:48:53,635:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 01:48:53,636:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:48:53,639:INFO:[LightGBM] [Info] Number of data points in the train set: 5954, number of used features: 12
2023-11-23 01:48:53,640:INFO:[LightGBM] [Info] Start training from score 184632.817938
2023-11-23 01:48:53,672:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:53,673:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000590 seconds.
2023-11-23 01:48:53,673:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:48:53,673:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:48:53,673:INFO:[LightGBM] [Info] Number of data points in the train set: 5953, number of used features: 12
2023-11-23 01:48:53,673:INFO:[LightGBM] [Info] Start training from score 184832.554678
2023-11-23 01:48:53,799:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:53,807:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002792 seconds.
2023-11-23 01:48:53,807:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:48:53,808:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:48:53,808:INFO:[LightGBM] [Info] Number of data points in the train set: 5953, number of used features: 12
2023-11-23 01:48:53,811:INFO:[LightGBM] [Info] Start training from score 185118.696120
2023-11-23 01:48:55,623:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:55,636:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010889 seconds.
2023-11-23 01:48:55,636:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:48:55,636:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:48:55,640:INFO:[LightGBM] [Info] Number of data points in the train set: 5954, number of used features: 12
2023-11-23 01:48:55,641:INFO:[LightGBM] [Info] Start training from score 184820.943567
2023-11-23 01:48:55,660:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:55,662:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001292 seconds.
2023-11-23 01:48:55,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:48:55,662:INFO:[LightGBM] [Info] Total Bins 1845
2023-11-23 01:48:55,662:INFO:[LightGBM] [Info] Number of data points in the train set: 5954, number of used features: 12
2023-11-23 01:48:55,663:INFO:[LightGBM] [Info] Start training from score 184818.407625
2023-11-23 01:48:56,112:INFO:Calculating mean and std
2023-11-23 01:48:56,113:INFO:Creating metrics dataframe
2023-11-23 01:48:56,119:INFO:Finalizing model
2023-11-23 01:48:56,137:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 01:48:56,138:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000705 seconds.
2023-11-23 01:48:56,138:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:48:56,139:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:48:56,139:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:48:56,140:INFO:[LightGBM] [Info] Start training from score 184916.265760
2023-11-23 01:48:56,405:INFO:Uploading results into container
2023-11-23 01:48:56,406:INFO:Uploading model into container now
2023-11-23 01:48:56,413:INFO:_master_model_container: 28
2023-11-23 01:48:56,413:INFO:_display_container: 12
2023-11-23 01:48:56,413:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:48:56,413:INFO:create_model() successfully completed......................................
2023-11-23 01:48:56,496:INFO:Initializing create_model()
2023-11-23 01:48:56,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:48:56,496:INFO:Checking exceptions
2023-11-23 01:48:56,502:INFO:Importing libraries
2023-11-23 01:48:56,503:INFO:Copying training dataset
2023-11-23 01:48:56,506:INFO:Defining folds
2023-11-23 01:48:56,506:INFO:Declaring metric variables
2023-11-23 01:48:56,508:INFO:Importing untrained model
2023-11-23 01:48:56,509:INFO:Random Forest Regressor Imported successfully
2023-11-23 01:48:56,512:INFO:Starting cross validation
2023-11-23 01:48:56,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:49:00,870:INFO:Calculating mean and std
2023-11-23 01:49:00,872:INFO:Creating metrics dataframe
2023-11-23 01:49:00,878:INFO:Finalizing model
2023-11-23 01:49:01,420:INFO:Uploading results into container
2023-11-23 01:49:01,421:INFO:Uploading model into container now
2023-11-23 01:49:01,428:INFO:_master_model_container: 29
2023-11-23 01:49:01,428:INFO:_display_container: 13
2023-11-23 01:49:01,428:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:49:01,428:INFO:create_model() successfully completed......................................
2023-11-23 01:49:01,513:INFO:Initializing create_model()
2023-11-23 01:49:01,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:49:01,513:INFO:Checking exceptions
2023-11-23 01:49:01,519:INFO:Importing libraries
2023-11-23 01:49:01,519:INFO:Copying training dataset
2023-11-23 01:49:01,527:INFO:Defining folds
2023-11-23 01:49:01,527:INFO:Declaring metric variables
2023-11-23 01:49:01,529:INFO:Importing untrained model
2023-11-23 01:49:01,530:INFO:Extra Trees Regressor Imported successfully
2023-11-23 01:49:01,533:INFO:Starting cross validation
2023-11-23 01:49:01,534:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:49:03,827:INFO:Calculating mean and std
2023-11-23 01:49:03,829:INFO:Creating metrics dataframe
2023-11-23 01:49:03,834:INFO:Finalizing model
2023-11-23 01:49:04,092:INFO:Uploading results into container
2023-11-23 01:49:04,093:INFO:Uploading model into container now
2023-11-23 01:49:04,100:INFO:_master_model_container: 30
2023-11-23 01:49:04,100:INFO:_display_container: 14
2023-11-23 01:49:04,100:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 01:49:04,100:INFO:create_model() successfully completed......................................
2023-11-23 01:49:18,128:INFO:Initializing predict_model()
2023-11-23 01:49:18,129:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=255,
              max_depth=20, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=0, reg_lambda=1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x16a5ba9d0>)
2023-11-23 01:49:18,129:INFO:Checking exceptions
2023-11-23 01:49:18,129:INFO:Preloading libraries
2023-11-23 01:49:18,255:INFO:Initializing predict_model()
2023-11-23 01:49:18,255:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=RandomForestRegressor(max_features='auto', n_estimators=150, n_jobs=-1,
                      random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x16a5ba9d0>)
2023-11-23 01:49:18,255:INFO:Checking exceptions
2023-11-23 01:49:18,255:INFO:Preloading libraries
2023-11-23 01:49:18,354:INFO:Initializing predict_model()
2023-11-23 01:49:18,354:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x16a5ba9d0>)
2023-11-23 01:49:18,354:INFO:Checking exceptions
2023-11-23 01:49:18,354:INFO:Preloading libraries
2023-11-23 01:49:24,424:INFO:Initializing ensemble_model()
2023-11-23 01:49:24,424:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=255,
              max_depth=20, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=0, reg_lambda=1), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-11-23 01:49:24,424:INFO:Checking exceptions
2023-11-23 01:49:24,433:INFO:Importing libraries
2023-11-23 01:49:24,433:INFO:Copying training dataset
2023-11-23 01:49:24,433:INFO:Checking base model
2023-11-23 01:49:24,433:INFO:Base model : Light Gradient Boosting Machine
2023-11-23 01:49:24,437:INFO:Importing untrained ensembler
2023-11-23 01:49:24,437:INFO:Ensemble method set to Bagging
2023-11-23 01:49:24,437:INFO:SubProcess create_model() called ==================================
2023-11-23 01:49:24,438:INFO:Initializing create_model()
2023-11-23 01:49:24,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=BaggingRegressor(estimator=LGBMRegressor(boosting_type='dart',
                                         colsample_bytree=0.9, max_bin=255,
                                         max_depth=20, n_estimators=200,
                                         n_jobs=-1, num_leaves=75,
                                         random_state=123, reg_alpha=0,
                                         reg_lambda=1),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x162d3bb20>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:49:24,438:INFO:Checking exceptions
2023-11-23 01:49:24,438:INFO:Importing libraries
2023-11-23 01:49:24,438:INFO:Copying training dataset
2023-11-23 01:49:24,441:INFO:Defining folds
2023-11-23 01:49:24,441:INFO:Declaring metric variables
2023-11-23 01:49:24,443:INFO:Importing untrained model
2023-11-23 01:49:24,443:INFO:Declaring custom model
2023-11-23 01:49:24,445:INFO:Bagging Regressor Imported successfully
2023-11-23 01:49:24,448:INFO:Starting cross validation
2023-11-23 01:49:24,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:51:40,152:INFO:Calculating mean and std
2023-11-23 01:51:40,161:INFO:Creating metrics dataframe
2023-11-23 01:51:40,169:INFO:Finalizing model
2023-11-23 01:51:40,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2023-11-23 01:51:40,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:51:40,191:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:51:40,192:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:51:40,192:INFO:[LightGBM] [Info] Start training from score 184515.676039
2023-11-23 01:51:40,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:41,824:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2023-11-23 01:51:41,824:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:51:41,824:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:51:41,824:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:51:41,824:INFO:[LightGBM] [Info] Start training from score 185567.014210
2023-11-23 01:51:43,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000543 seconds.
2023-11-23 01:51:43,469:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:51:43,469:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:51:43,469:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:51:43,470:INFO:[LightGBM] [Info] Start training from score 185613.287982
2023-11-23 01:51:43,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:43,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:43,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:43,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:44,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:44,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:44,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:44,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:44,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:44,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:44,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:44,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:44,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:44,925:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2023-11-23 01:51:44,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:51:44,925:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:51:44,925:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:51:44,925:INFO:[LightGBM] [Info] Start training from score 186134.527286
2023-11-23 01:51:45,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:45,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:45,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:45,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:45,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:45,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:46,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:46,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:46,428:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2023-11-23 01:51:46,428:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:51:46,428:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:51:46,428:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:51:46,429:INFO:[LightGBM] [Info] Start training from score 185030.476039
2023-11-23 01:51:46,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:46,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:46,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:47,923:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
2023-11-23 01:51:47,923:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:51:47,923:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:51:47,923:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:51:47,924:INFO:[LightGBM] [Info] Start training from score 183905.865306
2023-11-23 01:51:47,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:48,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:48,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:48,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:49,538:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2023-11-23 01:51:49,538:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:51:49,538:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:51:49,538:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:51:49,539:INFO:[LightGBM] [Info] Start training from score 183786.092063
2023-11-23 01:51:49,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:49,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:49,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:49,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:51,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000529 seconds.
2023-11-23 01:51:51,143:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:51:51,143:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:51:51,143:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:51:51,143:INFO:[LightGBM] [Info] Start training from score 186428.374754
2023-11-23 01:51:51,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:51,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:52,673:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2023-11-23 01:51:52,673:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:51:52,673:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:51:52,673:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:51:52,673:INFO:[LightGBM] [Info] Start training from score 185944.595314
2023-11-23 01:51:53,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:53,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:54,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:54,244:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000462 seconds.
2023-11-23 01:51:54,244:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 01:51:54,244:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 01:51:54,244:INFO:[LightGBM] [Info] Number of data points in the train set: 6615, number of used features: 12
2023-11-23 01:51:54,244:INFO:[LightGBM] [Info] Start training from score 185417.172940
2023-11-23 01:51:54,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:54,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:54,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:54,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:54,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:54,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:55,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 01:51:55,966:INFO:Uploading results into container
2023-11-23 01:51:55,968:INFO:Uploading model into container now
2023-11-23 01:51:55,969:INFO:_master_model_container: 31
2023-11-23 01:51:55,969:INFO:_display_container: 18
2023-11-23 01:51:55,971:INFO:BaggingRegressor(estimator=LGBMRegressor(boosting_type='dart',
                                         colsample_bytree=0.9, max_bin=255,
                                         max_depth=20, n_estimators=200,
                                         n_jobs=-1, num_leaves=75,
                                         random_state=123, reg_alpha=0,
                                         reg_lambda=1),
                 random_state=123)
2023-11-23 01:51:55,971:INFO:create_model() successfully completed......................................
2023-11-23 01:51:56,139:INFO:SubProcess create_model() end ==================================
2023-11-23 01:51:56,149:INFO:_master_model_container: 31
2023-11-23 01:51:56,149:INFO:_display_container: 18
2023-11-23 01:51:56,150:INFO:BaggingRegressor(estimator=LGBMRegressor(boosting_type='dart',
                                         colsample_bytree=0.9, max_bin=255,
                                         max_depth=20, n_estimators=200,
                                         n_jobs=-1, num_leaves=75,
                                         random_state=123, reg_alpha=0,
                                         reg_lambda=1),
                 random_state=123)
2023-11-23 01:51:56,150:INFO:ensemble_model() successfully completed......................................
2023-11-23 01:51:56,204:INFO:Initializing ensemble_model()
2023-11-23 01:51:56,204:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=RandomForestRegressor(max_features='auto', n_estimators=150, n_jobs=-1,
                      random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-11-23 01:51:56,204:INFO:Checking exceptions
2023-11-23 01:51:56,213:INFO:Importing libraries
2023-11-23 01:51:56,213:INFO:Copying training dataset
2023-11-23 01:51:56,213:INFO:Checking base model
2023-11-23 01:51:56,213:INFO:Base model : Random Forest Regressor
2023-11-23 01:51:56,218:INFO:Importing untrained ensembler
2023-11-23 01:51:56,218:INFO:Ensemble method set to Bagging
2023-11-23 01:51:56,218:INFO:SubProcess create_model() called ==================================
2023-11-23 01:51:56,220:INFO:Initializing create_model()
2023-11-23 01:51:56,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=BaggingRegressor(estimator=RandomForestRegressor(max_features='auto',
                                                 n_estimators=150, n_jobs=-1,
                                                 random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1692d9d30>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:51:56,220:INFO:Checking exceptions
2023-11-23 01:51:56,220:INFO:Importing libraries
2023-11-23 01:51:56,220:INFO:Copying training dataset
2023-11-23 01:51:56,224:INFO:Defining folds
2023-11-23 01:51:56,225:INFO:Declaring metric variables
2023-11-23 01:51:56,226:INFO:Importing untrained model
2023-11-23 01:51:56,226:INFO:Declaring custom model
2023-11-23 01:51:56,228:INFO:Bagging Regressor Imported successfully
2023-11-23 01:51:56,233:INFO:Starting cross validation
2023-11-23 01:51:56,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:51:56,285:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:56,288:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:56,296:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:56,297:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:56,357:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:56,419:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:56,477:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:56,507:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:59,544:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:59,610:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:59,651:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:59,652:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:59,884:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:51:59,903:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:00,086:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:00,233:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:02,780:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:02,799:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:02,958:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:03,115:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:03,187:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:03,242:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:03,513:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:03,525:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:06,028:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:06,310:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:06,372:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:06,536:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:06,568:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:06,652:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:06,712:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:06,823:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:09,026:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:09,425:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:09,626:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:09,686:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:09,689:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:09,984:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:10,035:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:10,057:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:12,400:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:12,954:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:13,028:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:13,199:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:13,297:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:13,362:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:13,417:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:13,620:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:15,803:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:16,148:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:16,412:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:16,750:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:16,871:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:16,883:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:16,891:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:17,077:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:19,144:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:19,446:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:19,868:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:20,328:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:20,335:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:20,352:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:20,656:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:20,848:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:22,812:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:23,345:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:23,575:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:23,969:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:24,240:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:24,354:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:24,388:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:24,876:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:26,757:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:26,985:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:27,393:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:27,829:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:27,865:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:27,969:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:28,156:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:28,285:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:31,601:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:32,312:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:32,848:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:33,348:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:33,630:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:34,027:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:34,412:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:34,776:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:35,206:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:35,559:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:35,972:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:36,294:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:36,722:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:37,044:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:37,473:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:37,809:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:38,259:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:38,851:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:39,336:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:39,756:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 01:52:40,334:INFO:Calculating mean and std
2023-11-23 01:52:40,336:INFO:Creating metrics dataframe
2023-11-23 01:52:40,343:INFO:Finalizing model
2023-11-23 01:52:45,079:INFO:Uploading results into container
2023-11-23 01:52:45,079:INFO:Uploading model into container now
2023-11-23 01:52:45,080:INFO:_master_model_container: 32
2023-11-23 01:52:45,080:INFO:_display_container: 19
2023-11-23 01:52:45,081:INFO:BaggingRegressor(estimator=RandomForestRegressor(max_features='auto',
                                                 n_estimators=150, n_jobs=-1,
                                                 random_state=123),
                 random_state=123)
2023-11-23 01:52:45,081:INFO:create_model() successfully completed......................................
2023-11-23 01:52:45,142:INFO:SubProcess create_model() end ==================================
2023-11-23 01:52:45,147:INFO:_master_model_container: 32
2023-11-23 01:52:45,147:INFO:_display_container: 19
2023-11-23 01:52:45,147:INFO:BaggingRegressor(estimator=RandomForestRegressor(max_features='auto',
                                                 n_estimators=150, n_jobs=-1,
                                                 random_state=123),
                 random_state=123)
2023-11-23 01:52:45,147:INFO:ensemble_model() successfully completed......................................
2023-11-23 01:52:45,191:INFO:Initializing ensemble_model()
2023-11-23 01:52:45,191:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-11-23 01:52:45,191:INFO:Checking exceptions
2023-11-23 01:52:45,199:INFO:Importing libraries
2023-11-23 01:52:45,199:INFO:Copying training dataset
2023-11-23 01:52:45,199:INFO:Checking base model
2023-11-23 01:52:45,200:INFO:Base model : Extra Trees Regressor
2023-11-23 01:52:45,203:INFO:Importing untrained ensembler
2023-11-23 01:52:45,203:INFO:Ensemble method set to Bagging
2023-11-23 01:52:45,203:INFO:SubProcess create_model() called ==================================
2023-11-23 01:52:45,204:INFO:Initializing create_model()
2023-11-23 01:52:45,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x166cf4670>, estimator=BaggingRegressor(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1076aefd0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 01:52:45,204:INFO:Checking exceptions
2023-11-23 01:52:45,205:INFO:Importing libraries
2023-11-23 01:52:45,205:INFO:Copying training dataset
2023-11-23 01:52:45,207:INFO:Defining folds
2023-11-23 01:52:45,207:INFO:Declaring metric variables
2023-11-23 01:52:45,208:INFO:Importing untrained model
2023-11-23 01:52:45,208:INFO:Declaring custom model
2023-11-23 01:52:45,210:INFO:Bagging Regressor Imported successfully
2023-11-23 01:52:45,213:INFO:Starting cross validation
2023-11-23 01:52:45,214:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 01:52:59,899:INFO:Calculating mean and std
2023-11-23 01:52:59,903:INFO:Creating metrics dataframe
2023-11-23 01:52:59,912:INFO:Finalizing model
2023-11-23 01:53:01,561:INFO:Uploading results into container
2023-11-23 01:53:01,561:INFO:Uploading model into container now
2023-11-23 01:53:01,562:INFO:_master_model_container: 33
2023-11-23 01:53:01,562:INFO:_display_container: 20
2023-11-23 01:53:01,562:INFO:BaggingRegressor(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-11-23 01:53:01,562:INFO:create_model() successfully completed......................................
2023-11-23 01:53:01,629:INFO:SubProcess create_model() end ==================================
2023-11-23 01:53:01,634:INFO:_master_model_container: 33
2023-11-23 01:53:01,634:INFO:_display_container: 20
2023-11-23 01:53:01,634:INFO:BaggingRegressor(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123),
                 random_state=123)
2023-11-23 01:53:01,634:INFO:ensemble_model() successfully completed......................................
2023-11-23 02:00:41,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 02:00:41,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 02:00:41,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 02:00:41,097:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-23 02:00:41,174:INFO:PyCaret RegressionExperiment
2023-11-23 02:00:41,174:INFO:Logging name: reg-default-name
2023-11-23 02:00:41,174:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-23 02:00:41,174:INFO:version 3.1.0
2023-11-23 02:00:41,174:INFO:Initializing setup()
2023-11-23 02:00:41,174:INFO:self.USI: 8c13
2023-11-23 02:00:41,174:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'fold_shuffle_param', 'USI', 'html_param', '_ml_usecase', 'target_param', 'pipeline', 'n_jobs_param', 'gpu_n_jobs_param', 'transform_target_param', 'exp_name_log', 'X', 'exp_id', 'fold_groups_param', 'gpu_param', 'seed', 'idx', 'X_train', 'y_train', 'data', 'memory', '_available_plots', 'y', 'log_plots_param', 'y_test', 'X_test'}
2023-11-23 02:00:41,174:INFO:Checking environment
2023-11-23 02:00:41,174:INFO:python_version: 3.9.16
2023-11-23 02:00:41,174:INFO:python_build: ('main', 'Nov  2 2023 14:11:49')
2023-11-23 02:00:41,174:INFO:machine: arm64
2023-11-23 02:00:41,174:INFO:platform: macOS-13.4.1-arm64-arm-64bit
2023-11-23 02:00:41,174:INFO:Memory: svmem(total=8589934592, available=2505015296, percent=70.8, used=3735486464, free=61587456, active=2455093248, inactive=2421096448, wired=1280393216)
2023-11-23 02:00:41,174:INFO:Physical Core: 8
2023-11-23 02:00:41,174:INFO:Logical Core: 8
2023-11-23 02:00:41,174:INFO:Checking libraries
2023-11-23 02:00:41,174:INFO:System:
2023-11-23 02:00:41,174:INFO:    python: 3.9.16 (main, Nov  2 2023, 14:11:49)  [Clang 14.0.3 (clang-1403.0.22.14.1)]
2023-11-23 02:00:41,174:INFO:executable: /Users/macOs/.pyenv/versions/3.9.16/bin/python
2023-11-23 02:00:41,174:INFO:   machine: macOS-13.4.1-arm64-arm-64bit
2023-11-23 02:00:41,174:INFO:PyCaret required dependencies:
2023-11-23 02:00:41,189:INFO:                 pip: 22.0.4
2023-11-23 02:00:41,189:INFO:          setuptools: 58.1.0
2023-11-23 02:00:41,189:INFO:             pycaret: 3.1.0
2023-11-23 02:00:41,189:INFO:             IPython: 8.17.2
2023-11-23 02:00:41,189:INFO:          ipywidgets: 8.1.1
2023-11-23 02:00:41,189:INFO:                tqdm: 4.66.1
2023-11-23 02:00:41,190:INFO:               numpy: 1.23.5
2023-11-23 02:00:41,190:INFO:              pandas: 1.5.3
2023-11-23 02:00:41,190:INFO:              jinja2: 3.1.2
2023-11-23 02:00:41,190:INFO:               scipy: 1.10.1
2023-11-23 02:00:41,190:INFO:              joblib: 1.3.2
2023-11-23 02:00:41,190:INFO:             sklearn: 1.2.2
2023-11-23 02:00:41,190:INFO:                pyod: 1.1.1
2023-11-23 02:00:41,190:INFO:            imblearn: 0.11.0
2023-11-23 02:00:41,190:INFO:   category_encoders: 2.6.3
2023-11-23 02:00:41,190:INFO:            lightgbm: 4.1.0
2023-11-23 02:00:41,190:INFO:               numba: 0.58.1
2023-11-23 02:00:41,190:INFO:            requests: 2.31.0
2023-11-23 02:00:41,190:INFO:          matplotlib: 3.8.1
2023-11-23 02:00:41,190:INFO:          scikitplot: 0.3.7
2023-11-23 02:00:41,190:INFO:         yellowbrick: 1.5
2023-11-23 02:00:41,190:INFO:              plotly: 5.18.0
2023-11-23 02:00:41,190:INFO:    plotly-resampler: Not installed
2023-11-23 02:00:41,190:INFO:             kaleido: 0.2.1
2023-11-23 02:00:41,190:INFO:           schemdraw: 0.15
2023-11-23 02:00:41,190:INFO:         statsmodels: 0.14.0
2023-11-23 02:00:41,190:INFO:              sktime: 0.21.1
2023-11-23 02:00:41,190:INFO:               tbats: 1.1.3
2023-11-23 02:00:41,190:INFO:            pmdarima: 2.0.4
2023-11-23 02:00:41,190:INFO:              psutil: 5.9.6
2023-11-23 02:00:41,190:INFO:          markupsafe: 2.1.3
2023-11-23 02:00:41,190:INFO:             pickle5: Not installed
2023-11-23 02:00:41,190:INFO:         cloudpickle: 3.0.0
2023-11-23 02:00:41,190:INFO:         deprecation: 2.1.0
2023-11-23 02:00:41,190:INFO:              xxhash: 3.4.1
2023-11-23 02:00:41,190:INFO:           wurlitzer: 3.0.3
2023-11-23 02:00:41,190:INFO:PyCaret optional dependencies:
2023-11-23 02:00:41,197:INFO:                shap: Not installed
2023-11-23 02:00:41,197:INFO:           interpret: Not installed
2023-11-23 02:00:41,197:INFO:                umap: Not installed
2023-11-23 02:00:41,197:INFO:     ydata_profiling: Not installed
2023-11-23 02:00:41,197:INFO:  explainerdashboard: Not installed
2023-11-23 02:00:41,197:INFO:             autoviz: Not installed
2023-11-23 02:00:41,197:INFO:           fairlearn: Not installed
2023-11-23 02:00:41,197:INFO:          deepchecks: Not installed
2023-11-23 02:00:41,197:INFO:             xgboost: 2.0.2
2023-11-23 02:00:41,197:INFO:            catboost: Not installed
2023-11-23 02:00:41,197:INFO:              kmodes: Not installed
2023-11-23 02:00:41,197:INFO:             mlxtend: Not installed
2023-11-23 02:00:41,197:INFO:       statsforecast: Not installed
2023-11-23 02:00:41,197:INFO:        tune_sklearn: Not installed
2023-11-23 02:00:41,197:INFO:                 ray: Not installed
2023-11-23 02:00:41,197:INFO:            hyperopt: Not installed
2023-11-23 02:00:41,197:INFO:              optuna: Not installed
2023-11-23 02:00:41,197:INFO:               skopt: Not installed
2023-11-23 02:00:41,197:INFO:              mlflow: Not installed
2023-11-23 02:00:41,197:INFO:              gradio: Not installed
2023-11-23 02:00:41,197:INFO:             fastapi: Not installed
2023-11-23 02:00:41,197:INFO:             uvicorn: Not installed
2023-11-23 02:00:41,197:INFO:              m2cgen: Not installed
2023-11-23 02:00:41,197:INFO:           evidently: Not installed
2023-11-23 02:00:41,197:INFO:               fugue: Not installed
2023-11-23 02:00:41,197:INFO:           streamlit: Not installed
2023-11-23 02:00:41,197:INFO:             prophet: Not installed
2023-11-23 02:00:41,197:INFO:None
2023-11-23 02:00:41,197:INFO:Set up data.
2023-11-23 02:00:41,201:INFO:Set up folding strategy.
2023-11-23 02:00:41,201:INFO:Set up train/test split.
2023-11-23 02:00:41,204:INFO:Set up index.
2023-11-23 02:00:41,204:INFO:Assigning column types.
2023-11-23 02:00:41,205:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-23 02:00:41,205:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,208:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,210:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,258:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,259:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,261:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,263:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,290:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,310:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,312:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-23 02:00:41,314:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,316:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,345:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,365:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,365:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,369:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,371:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,397:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,416:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,417:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,418:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-23 02:00:41,422:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,447:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,466:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,466:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,471:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,496:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,516:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,517:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-23 02:00:41,546:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,565:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,614:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,616:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-23 02:00:41,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,663:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,694:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 02:00:41,713:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,715:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-23 02:00:41,762:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,811:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,814:INFO:Set up custom pipeline.
2023-11-23 02:00:41,822:INFO:Finished creating preprocessing pipeline.
2023-11-23 02:00:41,843:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/8h/q7dbs5196q9fcktcxkc2__dh0000gn/T/joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))])))])
2023-11-23 02:00:41,843:INFO:Creating final display dataframe.
2023-11-23 02:00:41,877:INFO:Setup _display_container:                    Description               Value
0                   Session id                 123
1                       Target  median_house_value
2                  Target type          Regression
3          Original data shape          (7560, 10)
4       Transformed data shape          (7560, 13)
5  Transformed train set shape          (5292, 13)
6   Transformed test set shape          (2268, 13)
7             Numeric features                   8
8         Categorical features                   1
2023-11-23 02:00:41,928:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,977:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 02:00:41,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 02:00:41,979:INFO:setup() successfully completed in 0.81s...............
2023-11-23 02:00:41,983:INFO:Initializing compare_models()
2023-11-23 02:00:41,983:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-23 02:00:41,983:INFO:Checking exceptions
2023-11-23 02:00:41,984:INFO:Preparing display monitor
2023-11-23 02:00:42,007:INFO:Initializing Linear Regression
2023-11-23 02:00:42,007:INFO:Total runtime is 3.0835469563802084e-06 minutes
2023-11-23 02:00:42,009:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:42,009:INFO:Initializing create_model()
2023-11-23 02:00:42,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:42,010:INFO:Checking exceptions
2023-11-23 02:00:42,010:INFO:Importing libraries
2023-11-23 02:00:42,010:INFO:Copying training dataset
2023-11-23 02:00:42,014:INFO:Defining folds
2023-11-23 02:00:42,014:INFO:Declaring metric variables
2023-11-23 02:00:42,016:INFO:Importing untrained model
2023-11-23 02:00:42,017:INFO:Linear Regression Imported successfully
2023-11-23 02:00:42,021:INFO:Starting cross validation
2023-11-23 02:00:42,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:43,931:INFO:Calculating mean and std
2023-11-23 02:00:43,940:INFO:Creating metrics dataframe
2023-11-23 02:00:43,951:INFO:Uploading results into container
2023-11-23 02:00:43,952:INFO:Uploading model into container now
2023-11-23 02:00:43,953:INFO:_master_model_container: 1
2023-11-23 02:00:43,953:INFO:_display_container: 2
2023-11-23 02:00:43,954:INFO:LinearRegression(n_jobs=-1)
2023-11-23 02:00:43,954:INFO:create_model() successfully completed......................................
2023-11-23 02:00:44,051:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:44,051:INFO:Creating metrics dataframe
2023-11-23 02:00:44,055:INFO:Initializing Lasso Regression
2023-11-23 02:00:44,055:INFO:Total runtime is 0.034129718939463295 minutes
2023-11-23 02:00:44,056:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:44,056:INFO:Initializing create_model()
2023-11-23 02:00:44,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:44,057:INFO:Checking exceptions
2023-11-23 02:00:44,057:INFO:Importing libraries
2023-11-23 02:00:44,057:INFO:Copying training dataset
2023-11-23 02:00:44,060:INFO:Defining folds
2023-11-23 02:00:44,060:INFO:Declaring metric variables
2023-11-23 02:00:44,061:INFO:Importing untrained model
2023-11-23 02:00:44,063:INFO:Lasso Regression Imported successfully
2023-11-23 02:00:44,065:INFO:Starting cross validation
2023-11-23 02:00:44,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:44,174:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.084e+11, tolerance: 4.143e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 02:00:44,176:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.169e+11, tolerance: 4.122e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 02:00:44,185:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.019e+11, tolerance: 4.116e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 02:00:44,185:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.205e+11, tolerance: 4.189e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 02:00:44,191:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.344e+11, tolerance: 4.125e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 02:00:44,205:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.235e+11, tolerance: 4.117e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 02:00:44,218:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.174e+11, tolerance: 4.140e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 02:00:44,223:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.134e+11, tolerance: 4.121e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 02:00:44,257:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.070e+11, tolerance: 4.120e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 02:00:44,272:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.060e+11, tolerance: 4.135e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 02:00:44,282:INFO:Calculating mean and std
2023-11-23 02:00:44,283:INFO:Creating metrics dataframe
2023-11-23 02:00:44,284:INFO:Uploading results into container
2023-11-23 02:00:44,285:INFO:Uploading model into container now
2023-11-23 02:00:44,285:INFO:_master_model_container: 2
2023-11-23 02:00:44,285:INFO:_display_container: 2
2023-11-23 02:00:44,285:INFO:Lasso(random_state=123)
2023-11-23 02:00:44,285:INFO:create_model() successfully completed......................................
2023-11-23 02:00:44,331:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:44,331:INFO:Creating metrics dataframe
2023-11-23 02:00:44,336:INFO:Initializing Ridge Regression
2023-11-23 02:00:44,336:INFO:Total runtime is 0.03881220022837321 minutes
2023-11-23 02:00:44,337:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:44,337:INFO:Initializing create_model()
2023-11-23 02:00:44,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:44,337:INFO:Checking exceptions
2023-11-23 02:00:44,337:INFO:Importing libraries
2023-11-23 02:00:44,337:INFO:Copying training dataset
2023-11-23 02:00:44,340:INFO:Defining folds
2023-11-23 02:00:44,340:INFO:Declaring metric variables
2023-11-23 02:00:44,341:INFO:Importing untrained model
2023-11-23 02:00:44,343:INFO:Ridge Regression Imported successfully
2023-11-23 02:00:44,346:INFO:Starting cross validation
2023-11-23 02:00:44,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:44,434:INFO:Calculating mean and std
2023-11-23 02:00:44,434:INFO:Creating metrics dataframe
2023-11-23 02:00:44,436:INFO:Uploading results into container
2023-11-23 02:00:44,436:INFO:Uploading model into container now
2023-11-23 02:00:44,436:INFO:_master_model_container: 3
2023-11-23 02:00:44,436:INFO:_display_container: 2
2023-11-23 02:00:44,437:INFO:Ridge(random_state=123)
2023-11-23 02:00:44,437:INFO:create_model() successfully completed......................................
2023-11-23 02:00:44,481:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:44,481:INFO:Creating metrics dataframe
2023-11-23 02:00:44,485:INFO:Initializing Elastic Net
2023-11-23 02:00:44,485:INFO:Total runtime is 0.041302100817362464 minutes
2023-11-23 02:00:44,487:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:44,487:INFO:Initializing create_model()
2023-11-23 02:00:44,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:44,487:INFO:Checking exceptions
2023-11-23 02:00:44,487:INFO:Importing libraries
2023-11-23 02:00:44,487:INFO:Copying training dataset
2023-11-23 02:00:44,489:INFO:Defining folds
2023-11-23 02:00:44,489:INFO:Declaring metric variables
2023-11-23 02:00:44,491:INFO:Importing untrained model
2023-11-23 02:00:44,492:INFO:Elastic Net Imported successfully
2023-11-23 02:00:44,495:INFO:Starting cross validation
2023-11-23 02:00:44,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:44,567:INFO:Calculating mean and std
2023-11-23 02:00:44,567:INFO:Creating metrics dataframe
2023-11-23 02:00:44,569:INFO:Uploading results into container
2023-11-23 02:00:44,569:INFO:Uploading model into container now
2023-11-23 02:00:44,569:INFO:_master_model_container: 4
2023-11-23 02:00:44,569:INFO:_display_container: 2
2023-11-23 02:00:44,569:INFO:ElasticNet(random_state=123)
2023-11-23 02:00:44,569:INFO:create_model() successfully completed......................................
2023-11-23 02:00:44,611:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:44,611:INFO:Creating metrics dataframe
2023-11-23 02:00:44,615:INFO:Initializing Least Angle Regression
2023-11-23 02:00:44,615:INFO:Total runtime is 0.04347088734308878 minutes
2023-11-23 02:00:44,617:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:44,617:INFO:Initializing create_model()
2023-11-23 02:00:44,617:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:44,617:INFO:Checking exceptions
2023-11-23 02:00:44,617:INFO:Importing libraries
2023-11-23 02:00:44,617:INFO:Copying training dataset
2023-11-23 02:00:44,619:INFO:Defining folds
2023-11-23 02:00:44,619:INFO:Declaring metric variables
2023-11-23 02:00:44,621:INFO:Importing untrained model
2023-11-23 02:00:44,622:INFO:Least Angle Regression Imported successfully
2023-11-23 02:00:44,627:INFO:Starting cross validation
2023-11-23 02:00:44,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:44,688:INFO:Calculating mean and std
2023-11-23 02:00:44,689:INFO:Creating metrics dataframe
2023-11-23 02:00:44,690:INFO:Uploading results into container
2023-11-23 02:00:44,690:INFO:Uploading model into container now
2023-11-23 02:00:44,690:INFO:_master_model_container: 5
2023-11-23 02:00:44,690:INFO:_display_container: 2
2023-11-23 02:00:44,691:INFO:Lars(random_state=123)
2023-11-23 02:00:44,691:INFO:create_model() successfully completed......................................
2023-11-23 02:00:44,737:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:44,737:INFO:Creating metrics dataframe
2023-11-23 02:00:44,741:INFO:Initializing Lasso Least Angle Regression
2023-11-23 02:00:44,741:INFO:Total runtime is 0.045570516586303705 minutes
2023-11-23 02:00:44,743:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:44,743:INFO:Initializing create_model()
2023-11-23 02:00:44,743:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:44,743:INFO:Checking exceptions
2023-11-23 02:00:44,743:INFO:Importing libraries
2023-11-23 02:00:44,743:INFO:Copying training dataset
2023-11-23 02:00:44,745:INFO:Defining folds
2023-11-23 02:00:44,745:INFO:Declaring metric variables
2023-11-23 02:00:44,747:INFO:Importing untrained model
2023-11-23 02:00:44,748:INFO:Lasso Least Angle Regression Imported successfully
2023-11-23 02:00:44,750:INFO:Starting cross validation
2023-11-23 02:00:44,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:44,812:INFO:Calculating mean and std
2023-11-23 02:00:44,812:INFO:Creating metrics dataframe
2023-11-23 02:00:44,814:INFO:Uploading results into container
2023-11-23 02:00:44,814:INFO:Uploading model into container now
2023-11-23 02:00:44,814:INFO:_master_model_container: 6
2023-11-23 02:00:44,814:INFO:_display_container: 2
2023-11-23 02:00:44,814:INFO:LassoLars(random_state=123)
2023-11-23 02:00:44,815:INFO:create_model() successfully completed......................................
2023-11-23 02:00:44,856:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:44,856:INFO:Creating metrics dataframe
2023-11-23 02:00:44,861:INFO:Initializing Orthogonal Matching Pursuit
2023-11-23 02:00:44,861:INFO:Total runtime is 0.047558387120564774 minutes
2023-11-23 02:00:44,863:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:44,863:INFO:Initializing create_model()
2023-11-23 02:00:44,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:44,863:INFO:Checking exceptions
2023-11-23 02:00:44,863:INFO:Importing libraries
2023-11-23 02:00:44,863:INFO:Copying training dataset
2023-11-23 02:00:44,865:INFO:Defining folds
2023-11-23 02:00:44,865:INFO:Declaring metric variables
2023-11-23 02:00:44,866:INFO:Importing untrained model
2023-11-23 02:00:44,867:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-23 02:00:44,870:INFO:Starting cross validation
2023-11-23 02:00:44,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:44,930:INFO:Calculating mean and std
2023-11-23 02:00:44,930:INFO:Creating metrics dataframe
2023-11-23 02:00:44,932:INFO:Uploading results into container
2023-11-23 02:00:44,932:INFO:Uploading model into container now
2023-11-23 02:00:44,932:INFO:_master_model_container: 7
2023-11-23 02:00:44,932:INFO:_display_container: 2
2023-11-23 02:00:44,932:INFO:OrthogonalMatchingPursuit()
2023-11-23 02:00:44,932:INFO:create_model() successfully completed......................................
2023-11-23 02:00:44,973:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:44,974:INFO:Creating metrics dataframe
2023-11-23 02:00:44,978:INFO:Initializing Bayesian Ridge
2023-11-23 02:00:44,978:INFO:Total runtime is 0.04951635201772053 minutes
2023-11-23 02:00:44,980:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:44,980:INFO:Initializing create_model()
2023-11-23 02:00:44,980:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:44,980:INFO:Checking exceptions
2023-11-23 02:00:44,980:INFO:Importing libraries
2023-11-23 02:00:44,980:INFO:Copying training dataset
2023-11-23 02:00:44,982:INFO:Defining folds
2023-11-23 02:00:44,982:INFO:Declaring metric variables
2023-11-23 02:00:44,983:INFO:Importing untrained model
2023-11-23 02:00:44,984:INFO:Bayesian Ridge Imported successfully
2023-11-23 02:00:44,987:INFO:Starting cross validation
2023-11-23 02:00:44,988:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:45,048:INFO:Calculating mean and std
2023-11-23 02:00:45,048:INFO:Creating metrics dataframe
2023-11-23 02:00:45,050:INFO:Uploading results into container
2023-11-23 02:00:45,050:INFO:Uploading model into container now
2023-11-23 02:00:45,050:INFO:_master_model_container: 8
2023-11-23 02:00:45,050:INFO:_display_container: 2
2023-11-23 02:00:45,050:INFO:BayesianRidge()
2023-11-23 02:00:45,050:INFO:create_model() successfully completed......................................
2023-11-23 02:00:45,092:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:45,092:INFO:Creating metrics dataframe
2023-11-23 02:00:45,097:INFO:Initializing Passive Aggressive Regressor
2023-11-23 02:00:45,097:INFO:Total runtime is 0.05149490435918171 minutes
2023-11-23 02:00:45,098:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:45,098:INFO:Initializing create_model()
2023-11-23 02:00:45,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:45,098:INFO:Checking exceptions
2023-11-23 02:00:45,098:INFO:Importing libraries
2023-11-23 02:00:45,098:INFO:Copying training dataset
2023-11-23 02:00:45,100:INFO:Defining folds
2023-11-23 02:00:45,101:INFO:Declaring metric variables
2023-11-23 02:00:45,102:INFO:Importing untrained model
2023-11-23 02:00:45,103:INFO:Passive Aggressive Regressor Imported successfully
2023-11-23 02:00:45,106:INFO:Starting cross validation
2023-11-23 02:00:45,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:45,203:INFO:Calculating mean and std
2023-11-23 02:00:45,204:INFO:Creating metrics dataframe
2023-11-23 02:00:45,205:INFO:Uploading results into container
2023-11-23 02:00:45,205:INFO:Uploading model into container now
2023-11-23 02:00:45,205:INFO:_master_model_container: 9
2023-11-23 02:00:45,206:INFO:_display_container: 2
2023-11-23 02:00:45,206:INFO:PassiveAggressiveRegressor(random_state=123)
2023-11-23 02:00:45,206:INFO:create_model() successfully completed......................................
2023-11-23 02:00:45,248:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:45,248:INFO:Creating metrics dataframe
2023-11-23 02:00:45,253:INFO:Initializing Huber Regressor
2023-11-23 02:00:45,253:INFO:Total runtime is 0.05409814914067585 minutes
2023-11-23 02:00:45,255:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:45,255:INFO:Initializing create_model()
2023-11-23 02:00:45,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:45,255:INFO:Checking exceptions
2023-11-23 02:00:45,255:INFO:Importing libraries
2023-11-23 02:00:45,255:INFO:Copying training dataset
2023-11-23 02:00:45,257:INFO:Defining folds
2023-11-23 02:00:45,257:INFO:Declaring metric variables
2023-11-23 02:00:45,258:INFO:Importing untrained model
2023-11-23 02:00:45,260:INFO:Huber Regressor Imported successfully
2023-11-23 02:00:45,262:INFO:Starting cross validation
2023-11-23 02:00:45,263:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:45,351:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 02:00:45,356:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 02:00:45,358:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 02:00:45,361:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 02:00:45,367:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 02:00:45,370:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 02:00:45,375:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 02:00:45,375:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 02:00:45,414:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 02:00:45,418:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 02:00:45,431:INFO:Calculating mean and std
2023-11-23 02:00:45,432:INFO:Creating metrics dataframe
2023-11-23 02:00:45,433:INFO:Uploading results into container
2023-11-23 02:00:45,433:INFO:Uploading model into container now
2023-11-23 02:00:45,434:INFO:_master_model_container: 10
2023-11-23 02:00:45,434:INFO:_display_container: 2
2023-11-23 02:00:45,434:INFO:HuberRegressor()
2023-11-23 02:00:45,434:INFO:create_model() successfully completed......................................
2023-11-23 02:00:45,475:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:45,476:INFO:Creating metrics dataframe
2023-11-23 02:00:45,481:INFO:Initializing K Neighbors Regressor
2023-11-23 02:00:45,481:INFO:Total runtime is 0.0578912854194641 minutes
2023-11-23 02:00:45,482:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:45,482:INFO:Initializing create_model()
2023-11-23 02:00:45,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:45,482:INFO:Checking exceptions
2023-11-23 02:00:45,482:INFO:Importing libraries
2023-11-23 02:00:45,482:INFO:Copying training dataset
2023-11-23 02:00:45,484:INFO:Defining folds
2023-11-23 02:00:45,484:INFO:Declaring metric variables
2023-11-23 02:00:45,485:INFO:Importing untrained model
2023-11-23 02:00:45,487:INFO:K Neighbors Regressor Imported successfully
2023-11-23 02:00:45,489:INFO:Starting cross validation
2023-11-23 02:00:45,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:45,570:INFO:Calculating mean and std
2023-11-23 02:00:45,570:INFO:Creating metrics dataframe
2023-11-23 02:00:45,572:INFO:Uploading results into container
2023-11-23 02:00:45,572:INFO:Uploading model into container now
2023-11-23 02:00:45,575:INFO:_master_model_container: 11
2023-11-23 02:00:45,575:INFO:_display_container: 2
2023-11-23 02:00:45,575:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-23 02:00:45,575:INFO:create_model() successfully completed......................................
2023-11-23 02:00:45,616:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:45,616:INFO:Creating metrics dataframe
2023-11-23 02:00:45,621:INFO:Initializing Decision Tree Regressor
2023-11-23 02:00:45,621:INFO:Total runtime is 0.06023428440093993 minutes
2023-11-23 02:00:45,623:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:45,623:INFO:Initializing create_model()
2023-11-23 02:00:45,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:45,623:INFO:Checking exceptions
2023-11-23 02:00:45,623:INFO:Importing libraries
2023-11-23 02:00:45,623:INFO:Copying training dataset
2023-11-23 02:00:45,625:INFO:Defining folds
2023-11-23 02:00:45,625:INFO:Declaring metric variables
2023-11-23 02:00:45,626:INFO:Importing untrained model
2023-11-23 02:00:45,628:INFO:Decision Tree Regressor Imported successfully
2023-11-23 02:00:45,630:INFO:Starting cross validation
2023-11-23 02:00:45,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:45,746:INFO:Calculating mean and std
2023-11-23 02:00:45,747:INFO:Creating metrics dataframe
2023-11-23 02:00:45,748:INFO:Uploading results into container
2023-11-23 02:00:45,748:INFO:Uploading model into container now
2023-11-23 02:00:45,749:INFO:_master_model_container: 12
2023-11-23 02:00:45,749:INFO:_display_container: 2
2023-11-23 02:00:45,749:INFO:DecisionTreeRegressor(random_state=123)
2023-11-23 02:00:45,749:INFO:create_model() successfully completed......................................
2023-11-23 02:00:45,791:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:45,791:INFO:Creating metrics dataframe
2023-11-23 02:00:45,796:INFO:Initializing Random Forest Regressor
2023-11-23 02:00:45,796:INFO:Total runtime is 0.06314701636632283 minutes
2023-11-23 02:00:45,798:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:45,798:INFO:Initializing create_model()
2023-11-23 02:00:45,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:45,798:INFO:Checking exceptions
2023-11-23 02:00:45,798:INFO:Importing libraries
2023-11-23 02:00:45,798:INFO:Copying training dataset
2023-11-23 02:00:45,800:INFO:Defining folds
2023-11-23 02:00:45,800:INFO:Declaring metric variables
2023-11-23 02:00:45,801:INFO:Importing untrained model
2023-11-23 02:00:45,803:INFO:Random Forest Regressor Imported successfully
2023-11-23 02:00:45,805:INFO:Starting cross validation
2023-11-23 02:00:45,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:49,377:INFO:Calculating mean and std
2023-11-23 02:00:49,378:INFO:Creating metrics dataframe
2023-11-23 02:00:49,380:INFO:Uploading results into container
2023-11-23 02:00:49,381:INFO:Uploading model into container now
2023-11-23 02:00:49,381:INFO:_master_model_container: 13
2023-11-23 02:00:49,381:INFO:_display_container: 2
2023-11-23 02:00:49,381:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 02:00:49,382:INFO:create_model() successfully completed......................................
2023-11-23 02:00:49,430:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:49,430:INFO:Creating metrics dataframe
2023-11-23 02:00:49,435:INFO:Initializing Extra Trees Regressor
2023-11-23 02:00:49,435:INFO:Total runtime is 0.12379423379898072 minutes
2023-11-23 02:00:49,436:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:49,436:INFO:Initializing create_model()
2023-11-23 02:00:49,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:49,436:INFO:Checking exceptions
2023-11-23 02:00:49,436:INFO:Importing libraries
2023-11-23 02:00:49,436:INFO:Copying training dataset
2023-11-23 02:00:49,439:INFO:Defining folds
2023-11-23 02:00:49,439:INFO:Declaring metric variables
2023-11-23 02:00:49,440:INFO:Importing untrained model
2023-11-23 02:00:49,442:INFO:Extra Trees Regressor Imported successfully
2023-11-23 02:00:49,445:INFO:Starting cross validation
2023-11-23 02:00:49,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:51,074:INFO:Calculating mean and std
2023-11-23 02:00:51,076:INFO:Creating metrics dataframe
2023-11-23 02:00:51,081:INFO:Uploading results into container
2023-11-23 02:00:51,082:INFO:Uploading model into container now
2023-11-23 02:00:51,082:INFO:_master_model_container: 14
2023-11-23 02:00:51,082:INFO:_display_container: 2
2023-11-23 02:00:51,083:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 02:00:51,083:INFO:create_model() successfully completed......................................
2023-11-23 02:00:51,148:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:51,149:INFO:Creating metrics dataframe
2023-11-23 02:00:51,155:INFO:Initializing AdaBoost Regressor
2023-11-23 02:00:51,155:INFO:Total runtime is 0.15245898564656576 minutes
2023-11-23 02:00:51,156:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:51,156:INFO:Initializing create_model()
2023-11-23 02:00:51,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:51,157:INFO:Checking exceptions
2023-11-23 02:00:51,157:INFO:Importing libraries
2023-11-23 02:00:51,157:INFO:Copying training dataset
2023-11-23 02:00:51,159:INFO:Defining folds
2023-11-23 02:00:51,159:INFO:Declaring metric variables
2023-11-23 02:00:51,160:INFO:Importing untrained model
2023-11-23 02:00:51,161:INFO:AdaBoost Regressor Imported successfully
2023-11-23 02:00:51,164:INFO:Starting cross validation
2023-11-23 02:00:51,165:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:51,631:INFO:Calculating mean and std
2023-11-23 02:00:51,631:INFO:Creating metrics dataframe
2023-11-23 02:00:51,633:INFO:Uploading results into container
2023-11-23 02:00:51,633:INFO:Uploading model into container now
2023-11-23 02:00:51,633:INFO:_master_model_container: 15
2023-11-23 02:00:51,633:INFO:_display_container: 2
2023-11-23 02:00:51,633:INFO:AdaBoostRegressor(random_state=123)
2023-11-23 02:00:51,633:INFO:create_model() successfully completed......................................
2023-11-23 02:00:51,675:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:51,675:INFO:Creating metrics dataframe
2023-11-23 02:00:51,680:INFO:Initializing Gradient Boosting Regressor
2023-11-23 02:00:51,681:INFO:Total runtime is 0.16122260093688967 minutes
2023-11-23 02:00:51,682:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:51,682:INFO:Initializing create_model()
2023-11-23 02:00:51,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:51,682:INFO:Checking exceptions
2023-11-23 02:00:51,682:INFO:Importing libraries
2023-11-23 02:00:51,682:INFO:Copying training dataset
2023-11-23 02:00:51,684:INFO:Defining folds
2023-11-23 02:00:51,685:INFO:Declaring metric variables
2023-11-23 02:00:51,686:INFO:Importing untrained model
2023-11-23 02:00:51,687:INFO:Gradient Boosting Regressor Imported successfully
2023-11-23 02:00:51,690:INFO:Starting cross validation
2023-11-23 02:00:51,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:53,312:INFO:Calculating mean and std
2023-11-23 02:00:53,313:INFO:Creating metrics dataframe
2023-11-23 02:00:53,314:INFO:Uploading results into container
2023-11-23 02:00:53,315:INFO:Uploading model into container now
2023-11-23 02:00:53,315:INFO:_master_model_container: 16
2023-11-23 02:00:53,315:INFO:_display_container: 2
2023-11-23 02:00:53,315:INFO:GradientBoostingRegressor(random_state=123)
2023-11-23 02:00:53,315:INFO:create_model() successfully completed......................................
2023-11-23 02:00:53,357:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:53,357:INFO:Creating metrics dataframe
2023-11-23 02:00:53,363:INFO:Initializing Extreme Gradient Boosting
2023-11-23 02:00:53,363:INFO:Total runtime is 0.18925775289535524 minutes
2023-11-23 02:00:53,364:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:53,364:INFO:Initializing create_model()
2023-11-23 02:00:53,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:53,364:INFO:Checking exceptions
2023-11-23 02:00:53,364:INFO:Importing libraries
2023-11-23 02:00:53,364:INFO:Copying training dataset
2023-11-23 02:00:53,367:INFO:Defining folds
2023-11-23 02:00:53,367:INFO:Declaring metric variables
2023-11-23 02:00:53,368:INFO:Importing untrained model
2023-11-23 02:00:53,370:INFO:Extreme Gradient Boosting Imported successfully
2023-11-23 02:00:53,372:INFO:Starting cross validation
2023-11-23 02:00:53,373:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:53,457:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-23 02:00:53,458:WARNING:Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


2023-11-23 02:00:53,459:INFO:Initializing create_model()
2023-11-23 02:00:53,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:53,459:INFO:Checking exceptions
2023-11-23 02:00:53,459:INFO:Importing libraries
2023-11-23 02:00:53,459:INFO:Copying training dataset
2023-11-23 02:00:53,461:INFO:Defining folds
2023-11-23 02:00:53,461:INFO:Declaring metric variables
2023-11-23 02:00:53,462:INFO:Importing untrained model
2023-11-23 02:00:53,464:INFO:Extreme Gradient Boosting Imported successfully
2023-11-23 02:00:53,467:INFO:Starting cross validation
2023-11-23 02:00:53,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:53,523:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2023-11-23 02:00:53,523:ERROR:Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


2023-11-23 02:00:53,523:INFO:Initializing Light Gradient Boosting Machine
2023-11-23 02:00:53,523:INFO:Total runtime is 0.19193388223648072 minutes
2023-11-23 02:00:53,525:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:53,525:INFO:Initializing create_model()
2023-11-23 02:00:53,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:53,525:INFO:Checking exceptions
2023-11-23 02:00:53,525:INFO:Importing libraries
2023-11-23 02:00:53,525:INFO:Copying training dataset
2023-11-23 02:00:53,527:INFO:Defining folds
2023-11-23 02:00:53,527:INFO:Declaring metric variables
2023-11-23 02:00:53,528:INFO:Importing untrained model
2023-11-23 02:00:53,530:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 02:00:53,533:INFO:Starting cross validation
2023-11-23 02:00:53,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:56,058:INFO:Calculating mean and std
2023-11-23 02:00:56,058:INFO:Creating metrics dataframe
2023-11-23 02:00:56,060:INFO:Uploading results into container
2023-11-23 02:00:56,060:INFO:Uploading model into container now
2023-11-23 02:00:56,060:INFO:_master_model_container: 17
2023-11-23 02:00:56,060:INFO:_display_container: 2
2023-11-23 02:00:56,061:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 02:00:56,061:INFO:create_model() successfully completed......................................
2023-11-23 02:00:56,102:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:56,102:INFO:Creating metrics dataframe
2023-11-23 02:00:56,108:INFO:Initializing Dummy Regressor
2023-11-23 02:00:56,108:INFO:Total runtime is 0.23501378297805786 minutes
2023-11-23 02:00:56,109:INFO:SubProcess create_model() called ==================================
2023-11-23 02:00:56,110:INFO:Initializing create_model()
2023-11-23 02:00:56,110:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x105b6d400>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:56,110:INFO:Checking exceptions
2023-11-23 02:00:56,110:INFO:Importing libraries
2023-11-23 02:00:56,110:INFO:Copying training dataset
2023-11-23 02:00:56,112:INFO:Defining folds
2023-11-23 02:00:56,112:INFO:Declaring metric variables
2023-11-23 02:00:56,113:INFO:Importing untrained model
2023-11-23 02:00:56,114:INFO:Dummy Regressor Imported successfully
2023-11-23 02:00:56,117:INFO:Starting cross validation
2023-11-23 02:00:56,118:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:56,175:INFO:Calculating mean and std
2023-11-23 02:00:56,175:INFO:Creating metrics dataframe
2023-11-23 02:00:56,177:INFO:Uploading results into container
2023-11-23 02:00:56,177:INFO:Uploading model into container now
2023-11-23 02:00:56,177:INFO:_master_model_container: 18
2023-11-23 02:00:56,177:INFO:_display_container: 2
2023-11-23 02:00:56,177:INFO:DummyRegressor()
2023-11-23 02:00:56,177:INFO:create_model() successfully completed......................................
2023-11-23 02:00:56,219:INFO:SubProcess create_model() end ==================================
2023-11-23 02:00:56,219:INFO:Creating metrics dataframe
2023-11-23 02:00:56,229:INFO:Initializing create_model()
2023-11-23 02:00:56,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:56,229:INFO:Checking exceptions
2023-11-23 02:00:56,230:INFO:Importing libraries
2023-11-23 02:00:56,230:INFO:Copying training dataset
2023-11-23 02:00:56,231:INFO:Defining folds
2023-11-23 02:00:56,231:INFO:Declaring metric variables
2023-11-23 02:00:56,231:INFO:Importing untrained model
2023-11-23 02:00:56,231:INFO:Declaring custom model
2023-11-23 02:00:56,232:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 02:00:56,232:INFO:Cross validation set to False
2023-11-23 02:00:56,232:INFO:Fitting Model
2023-11-23 02:00:56,244:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 02:00:56,245:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000462 seconds.
2023-11-23 02:00:56,245:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 02:00:56,245:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 02:00:56,245:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 02:00:56,245:INFO:[LightGBM] [Info] Start training from score 186277.890967
2023-11-23 02:00:56,485:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 02:00:56,485:INFO:create_model() successfully completed......................................
2023-11-23 02:00:56,531:INFO:Initializing create_model()
2023-11-23 02:00:56,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:56,531:INFO:Checking exceptions
2023-11-23 02:00:56,532:INFO:Importing libraries
2023-11-23 02:00:56,532:INFO:Copying training dataset
2023-11-23 02:00:56,534:INFO:Defining folds
2023-11-23 02:00:56,534:INFO:Declaring metric variables
2023-11-23 02:00:56,534:INFO:Importing untrained model
2023-11-23 02:00:56,534:INFO:Declaring custom model
2023-11-23 02:00:56,534:INFO:Random Forest Regressor Imported successfully
2023-11-23 02:00:56,534:INFO:Cross validation set to False
2023-11-23 02:00:56,534:INFO:Fitting Model
2023-11-23 02:00:56,925:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 02:00:56,925:INFO:create_model() successfully completed......................................
2023-11-23 02:00:56,969:INFO:Initializing create_model()
2023-11-23 02:00:56,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:56,969:INFO:Checking exceptions
2023-11-23 02:00:56,970:INFO:Importing libraries
2023-11-23 02:00:56,970:INFO:Copying training dataset
2023-11-23 02:00:56,971:INFO:Defining folds
2023-11-23 02:00:56,972:INFO:Declaring metric variables
2023-11-23 02:00:56,972:INFO:Importing untrained model
2023-11-23 02:00:56,972:INFO:Declaring custom model
2023-11-23 02:00:56,972:INFO:Extra Trees Regressor Imported successfully
2023-11-23 02:00:56,972:INFO:Cross validation set to False
2023-11-23 02:00:56,972:INFO:Fitting Model
2023-11-23 02:00:57,166:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 02:00:57,166:INFO:create_model() successfully completed......................................
2023-11-23 02:00:57,222:INFO:_master_model_container: 18
2023-11-23 02:00:57,222:INFO:_display_container: 2
2023-11-23 02:00:57,222:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)]
2023-11-23 02:00:57,223:INFO:compare_models() successfully completed......................................
2023-11-23 02:00:57,254:INFO:Initializing create_model()
2023-11-23 02:00:57,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:00:57,254:INFO:Checking exceptions
2023-11-23 02:00:57,260:INFO:Importing libraries
2023-11-23 02:00:57,261:INFO:Copying training dataset
2023-11-23 02:00:57,265:INFO:Defining folds
2023-11-23 02:00:57,266:INFO:Declaring metric variables
2023-11-23 02:00:57,268:INFO:Importing untrained model
2023-11-23 02:00:57,268:INFO:Declaring custom model
2023-11-23 02:00:57,270:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 02:00:57,273:INFO:Starting cross validation
2023-11-23 02:00:57,274:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:00:59,724:INFO:Calculating mean and std
2023-11-23 02:00:59,724:INFO:Creating metrics dataframe
2023-11-23 02:00:59,727:INFO:Finalizing model
2023-11-23 02:00:59,738:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 02:00:59,738:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2023-11-23 02:00:59,738:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 02:00:59,738:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 02:00:59,738:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 02:00:59,739:INFO:[LightGBM] [Info] Start training from score 186277.890967
2023-11-23 02:00:59,976:INFO:Uploading results into container
2023-11-23 02:00:59,976:INFO:Uploading model into container now
2023-11-23 02:00:59,980:INFO:_master_model_container: 19
2023-11-23 02:00:59,980:INFO:_display_container: 3
2023-11-23 02:00:59,981:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 02:00:59,981:INFO:create_model() successfully completed......................................
2023-11-23 02:01:00,024:INFO:Initializing create_model()
2023-11-23 02:01:00,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:01:00,024:INFO:Checking exceptions
2023-11-23 02:01:00,030:INFO:Importing libraries
2023-11-23 02:01:00,030:INFO:Copying training dataset
2023-11-23 02:01:00,035:INFO:Defining folds
2023-11-23 02:01:00,035:INFO:Declaring metric variables
2023-11-23 02:01:00,044:INFO:Importing untrained model
2023-11-23 02:01:00,044:INFO:Declaring custom model
2023-11-23 02:01:00,048:INFO:Random Forest Regressor Imported successfully
2023-11-23 02:01:00,055:INFO:Starting cross validation
2023-11-23 02:01:00,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:01:03,238:INFO:Calculating mean and std
2023-11-23 02:01:03,239:INFO:Creating metrics dataframe
2023-11-23 02:01:03,242:INFO:Finalizing model
2023-11-23 02:01:03,647:INFO:Uploading results into container
2023-11-23 02:01:03,647:INFO:Uploading model into container now
2023-11-23 02:01:03,652:INFO:_master_model_container: 20
2023-11-23 02:01:03,652:INFO:_display_container: 4
2023-11-23 02:01:03,652:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 02:01:03,652:INFO:create_model() successfully completed......................................
2023-11-23 02:01:03,697:INFO:Initializing create_model()
2023-11-23 02:01:03,697:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 02:01:03,698:INFO:Checking exceptions
2023-11-23 02:01:03,703:INFO:Importing libraries
2023-11-23 02:01:03,703:INFO:Copying training dataset
2023-11-23 02:01:03,706:INFO:Defining folds
2023-11-23 02:01:03,706:INFO:Declaring metric variables
2023-11-23 02:01:03,707:INFO:Importing untrained model
2023-11-23 02:01:03,707:INFO:Declaring custom model
2023-11-23 02:01:03,709:INFO:Extra Trees Regressor Imported successfully
2023-11-23 02:01:03,712:INFO:Starting cross validation
2023-11-23 02:01:03,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 02:01:05,257:INFO:Calculating mean and std
2023-11-23 02:01:05,257:INFO:Creating metrics dataframe
2023-11-23 02:01:05,261:INFO:Finalizing model
2023-11-23 02:01:05,459:INFO:Uploading results into container
2023-11-23 02:01:05,459:INFO:Uploading model into container now
2023-11-23 02:01:05,465:INFO:_master_model_container: 21
2023-11-23 02:01:05,465:INFO:_display_container: 5
2023-11-23 02:01:05,465:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 02:01:05,466:INFO:create_model() successfully completed......................................
2023-11-23 02:01:05,551:INFO:Initializing tune_model()
2023-11-23 02:01:05,551:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=100, custom_grid={'num_leaves': [50, 75, 100], 'max_depth': [-1, 10, 20], 'min_child_samples': [10, 20, 30], 'subsample': [0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [50, 100, 200], 'reg_alpha': [0, 0.1, 0.5, 1], 'reg_lambda': [0, 0.1, 0.5, 1], 'max_bin': [255, 355, 455], 'boosting_type': ['gbdt', 'dart']}, optimize=mape, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>)
2023-11-23 02:01:05,551:INFO:Checking exceptions
2023-11-23 02:01:05,560:INFO:Copying training dataset
2023-11-23 02:01:05,563:INFO:Checking base model
2023-11-23 02:01:05,563:INFO:Base model : Light Gradient Boosting Machine
2023-11-23 02:01:05,566:INFO:Declaring metric variables
2023-11-23 02:01:05,567:INFO:Defining Hyperparameters
2023-11-23 02:01:05,616:INFO:custom_grid: {'actual_estimator__num_leaves': [50, 75, 100], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__min_child_samples': [10, 20, 30], 'actual_estimator__subsample': [0.7, 0.8, 0.9, 1.0], 'actual_estimator__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [50, 100, 200], 'actual_estimator__reg_alpha': [0, 0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0, 0.1, 0.5, 1], 'actual_estimator__max_bin': [255, 355, 455], 'actual_estimator__boosting_type': ['gbdt', 'dart']}
2023-11-23 02:01:05,616:INFO:Tuning with n_jobs=-1
2023-11-23 02:01:05,616:INFO:Initializing RandomizedSearchCV
2023-11-23 08:26:01,600:INFO:best_params: {'actual_estimator__subsample': 0.9, 'actual_estimator__reg_lambda': 1, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 75, 'actual_estimator__n_estimators': 200, 'actual_estimator__min_child_samples': 30, 'actual_estimator__max_depth': -1, 'actual_estimator__max_bin': 455, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__colsample_bytree': 0.9, 'actual_estimator__boosting_type': 'dart'}
2023-11-23 08:26:01,608:INFO:Hyperparameter search completed
2023-11-23 08:26:01,608:INFO:SubProcess create_model() called ==================================
2023-11-23 08:26:01,609:INFO:Initializing create_model()
2023-11-23 08:26:01,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x281e25ca0>, model_only=True, return_train_score=True, kwargs={'subsample': 0.9, 'reg_lambda': 1, 'reg_alpha': 1, 'num_leaves': 75, 'n_estimators': 200, 'min_child_samples': 30, 'max_depth': -1, 'max_bin': 455, 'learning_rate': 0.1, 'colsample_bytree': 0.9, 'boosting_type': 'dart'})
2023-11-23 08:26:01,609:INFO:Checking exceptions
2023-11-23 08:26:01,610:INFO:Importing libraries
2023-11-23 08:26:01,611:INFO:Copying training dataset
2023-11-23 08:26:01,616:INFO:Defining folds
2023-11-23 08:26:01,616:INFO:Declaring metric variables
2023-11-23 08:26:01,629:INFO:Importing untrained model
2023-11-23 08:26:01,629:INFO:Declaring custom model
2023-11-23 08:26:01,632:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 08:26:01,636:INFO:Starting cross validation
2023-11-23 08:26:01,638:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:46:46,433:INFO:Calculating mean and std
2023-11-23 08:46:46,439:INFO:Creating metrics dataframe
2023-11-23 08:46:46,448:INFO:Finalizing model
2023-11-23 08:46:46,463:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 08:46:46,463:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2023-11-23 08:46:46,463:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 08:46:46,463:INFO:[LightGBM] [Info] Total Bins 3239
2023-11-23 08:46:46,464:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 08:46:46,464:INFO:[LightGBM] [Info] Start training from score 186277.890967
2023-11-23 08:46:46,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:46,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:46,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:46,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:47,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:47,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:47,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:47,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 08:46:47,995:INFO:Initializing predict_model()
2023-11-23 08:46:47,995:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x17ed891f0>)
2023-11-23 08:46:47,995:INFO:Checking exceptions
2023-11-23 08:46:47,995:INFO:Preloading libraries
2023-11-23 08:46:47,995:INFO:Set up data.
2023-11-23 08:46:48,000:INFO:Set up index.
2023-11-23 08:46:48,117:INFO:Uploading results into container
2023-11-23 08:46:48,117:INFO:Uploading model into container now
2023-11-23 08:46:48,118:INFO:_master_model_container: 22
2023-11-23 08:46:48,118:INFO:_display_container: 6
2023-11-23 08:46:48,119:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9)
2023-11-23 08:46:48,119:INFO:create_model() successfully completed......................................
2023-11-23 08:46:48,183:INFO:SubProcess create_model() end ==================================
2023-11-23 08:46:48,184:INFO:choose_better activated
2023-11-23 08:46:48,191:INFO:SubProcess create_model() called ==================================
2023-11-23 08:46:48,191:INFO:Initializing create_model()
2023-11-23 08:46:48,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:46:48,191:INFO:Checking exceptions
2023-11-23 08:46:48,192:INFO:Importing libraries
2023-11-23 08:46:48,192:INFO:Copying training dataset
2023-11-23 08:46:48,195:INFO:Defining folds
2023-11-23 08:46:48,195:INFO:Declaring metric variables
2023-11-23 08:46:48,195:INFO:Importing untrained model
2023-11-23 08:46:48,195:INFO:Declaring custom model
2023-11-23 08:46:48,195:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 08:46:48,195:INFO:Starting cross validation
2023-11-23 08:46:48,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:46:50,776:INFO:Calculating mean and std
2023-11-23 08:46:50,776:INFO:Creating metrics dataframe
2023-11-23 08:46:50,777:INFO:Finalizing model
2023-11-23 08:46:50,787:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 08:46:50,788:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.
2023-11-23 08:46:50,788:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 08:46:50,788:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 08:46:50,788:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 08:46:50,788:INFO:[LightGBM] [Info] Start training from score 186277.890967
2023-11-23 08:46:51,042:INFO:Uploading results into container
2023-11-23 08:46:51,042:INFO:Uploading model into container now
2023-11-23 08:46:51,043:INFO:_master_model_container: 23
2023-11-23 08:46:51,043:INFO:_display_container: 7
2023-11-23 08:46:51,043:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 08:46:51,043:INFO:create_model() successfully completed......................................
2023-11-23 08:46:51,088:INFO:SubProcess create_model() end ==================================
2023-11-23 08:46:51,088:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.1885
2023-11-23 08:46:51,089:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9) result for MAPE is 0.1789
2023-11-23 08:46:51,089:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9) is best model
2023-11-23 08:46:51,090:INFO:choose_better completed
2023-11-23 08:46:51,097:INFO:_master_model_container: 23
2023-11-23 08:46:51,097:INFO:_display_container: 6
2023-11-23 08:46:51,098:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9)
2023-11-23 08:46:51,098:INFO:tune_model() successfully completed......................................
2023-11-23 08:46:51,145:INFO:Initializing tune_model()
2023-11-23 08:46:51,145:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150], 'max_depth': [None, 3, 5, 7, 9], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2'], 'bootstrap': [True, False]}, optimize=mape, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>)
2023-11-23 08:46:51,145:INFO:Checking exceptions
2023-11-23 08:46:51,151:INFO:Copying training dataset
2023-11-23 08:46:51,153:INFO:Checking base model
2023-11-23 08:46:51,154:INFO:Base model : Random Forest Regressor
2023-11-23 08:46:51,155:INFO:Declaring metric variables
2023-11-23 08:46:51,157:INFO:Defining Hyperparameters
2023-11-23 08:46:51,208:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150], 'actual_estimator__max_depth': [None, 3, 5, 7, 9], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__min_samples_leaf': [1, 2, 4], 'actual_estimator__max_features': ['auto', 'sqrt', 'log2'], 'actual_estimator__bootstrap': [True, False]}
2023-11-23 08:46:51,208:INFO:Tuning with n_jobs=-1
2023-11-23 08:46:51,208:INFO:Initializing RandomizedSearchCV
2023-11-23 08:46:51,231:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:51,231:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:51,241:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:51,254:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:51,315:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:51,373:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:51,426:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:51,459:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:53,588:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:53,622:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:55,072:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:55,166:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:55,602:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:55,705:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:55,775:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:55,945:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:55,951:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:56,053:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:58,829:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:58,935:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:59,489:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:59,505:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:59,674:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:59,686:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:59,687:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:46:59,920:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:00,059:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:00,082:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:00,110:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:00,230:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:01,160:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:01,398:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:01,476:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:01,667:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:01,736:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:01,807:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:01,817:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:01,855:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:01,958:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:01,976:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:06,166:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:06,262:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:06,541:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:06,576:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:06,753:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:06,892:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:06,897:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,101:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,130:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,241:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,303:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,383:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,384:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,394:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,397:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,454:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,487:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:07,487:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:12,842:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:12,978:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:24,278:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:24,391:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:24,489:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:24,506:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:24,521:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:24,561:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:24,593:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:24,639:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:25,690:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:25,707:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:25,760:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:25,882:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:25,883:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:25,886:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:25,912:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:25,916:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:26,182:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:26,197:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:26,203:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:26,220:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:29,299:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:29,314:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:29,405:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:29,556:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:29,950:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:30,090:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:30,164:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:30,332:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:30,466:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:30,543:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:30,582:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:30,729:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:30,906:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:31,032:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:31,327:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:31,355:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:31,503:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:31,590:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:31,669:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:31,677:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:31,936:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:31,993:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,080:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,127:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,308:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,346:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,374:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,382:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,453:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,463:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,816:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,830:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,950:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:32,966:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:33,093:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:33,339:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:33,350:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:33,351:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:33,356:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:33,376:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:35,320:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:35,384:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:35,388:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:35,391:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:35,428:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:35,445:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:35,456:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:35,468:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:35,482:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:35,526:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:36,060:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:36,069:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:36,276:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:36,304:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:36,313:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:36,323:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:36,655:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:36,685:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:37,408:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:37,432:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:37,796:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:37,848:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:37,905:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:37,952:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:38,068:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:38,218:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:38,879:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:38,932:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:40,140:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:40,159:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:40,233:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:40,324:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:40,646:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:40,710:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:41,443:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:41,612:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:41,853:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:41,861:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:42,213:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:42,242:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:44,850:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:44,855:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:44,939:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:44,971:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:44,978:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:44,981:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:45,121:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:45,190:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:45,579:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:45,599:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,527:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,571:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,582:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,644:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,651:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,660:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,662:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,684:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,689:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,740:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,740:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,789:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,812:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,827:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,831:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,835:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,849:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:53,864:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:55,100:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:55,126:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:55,935:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:55,973:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:56,254:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:56,320:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:56,362:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:56,365:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:56,381:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:56,575:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:58,717:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:59,003:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:59,143:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:59,201:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:59,240:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:59,277:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:59,401:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:47:59,628:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:01,138:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:01,186:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:01,255:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:01,297:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,089:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,095:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,261:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,448:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,454:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,457:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,503:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,510:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,639:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,703:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,711:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,719:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,726:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,755:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,862:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,868:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,899:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:03,962:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:04,670:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:04,716:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:08,610:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:08,735:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:08,744:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:08,791:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:08,844:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:08,890:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:08,953:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:10,562:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:10,572:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:10,577:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:10,764:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:11,544:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:11,594:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:11,700:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:12,118:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:12,453:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:13,491:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:13,509:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:13,680:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:13,921:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:15,204:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:15,292:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:15,450:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:15,513:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:15,654:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:15,767:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:15,782:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:15,784:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:17,736:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,002:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,065:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,160:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,235:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,270:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,271:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,339:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,423:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,451:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,475:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,480:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,499:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,515:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,547:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,629:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,636:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:18,659:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:20,267:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:20,440:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:21,089:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:21,175:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:21,254:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:21,327:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:21,397:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:21,491:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:22,909:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:23,385:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:23,838:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:23,946:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:25,000:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:25,026:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:28,822:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:28,835:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:28,848:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:28,943:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:28,969:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:29,055:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:29,066:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:29,071:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:31,195:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:31,418:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:31,857:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:31,874:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:31,903:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:31,924:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:31,975:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:31,986:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:33,481:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:33,639:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:35,428:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:35,665:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:37,774:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': None, 'actual_estimator__bootstrap': False}
2023-11-23 08:48:37,775:INFO:Hyperparameter search completed
2023-11-23 08:48:37,775:INFO:SubProcess create_model() called ==================================
2023-11-23 08:48:37,776:INFO:Initializing create_model()
2023-11-23 08:48:37,776:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17f825f10>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': None, 'bootstrap': False})
2023-11-23 08:48:37,776:INFO:Checking exceptions
2023-11-23 08:48:37,776:INFO:Importing libraries
2023-11-23 08:48:37,776:INFO:Copying training dataset
2023-11-23 08:48:37,780:INFO:Defining folds
2023-11-23 08:48:37,781:INFO:Declaring metric variables
2023-11-23 08:48:37,786:INFO:Importing untrained model
2023-11-23 08:48:37,786:INFO:Declaring custom model
2023-11-23 08:48:37,789:INFO:Random Forest Regressor Imported successfully
2023-11-23 08:48:37,799:INFO:Starting cross validation
2023-11-23 08:48:37,802:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:48:40,075:INFO:Calculating mean and std
2023-11-23 08:48:40,075:INFO:Creating metrics dataframe
2023-11-23 08:48:40,081:INFO:Finalizing model
2023-11-23 08:48:40,370:INFO:Initializing predict_model()
2023-11-23 08:48:40,370:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 RandomForestRegressor(bootstrap=False, max_features='log2',
                                       min_samples_leaf=2, min_samples_split=10,
                                       n_estimators=150, n_jobs=-1,
                                       random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x17ed89280>)
2023-11-23 08:48:40,370:INFO:Checking exceptions
2023-11-23 08:48:40,370:INFO:Preloading libraries
2023-11-23 08:48:40,370:INFO:Set up data.
2023-11-23 08:48:40,373:INFO:Set up index.
2023-11-23 08:48:40,479:INFO:Uploading results into container
2023-11-23 08:48:40,479:INFO:Uploading model into container now
2023-11-23 08:48:40,479:INFO:_master_model_container: 24
2023-11-23 08:48:40,480:INFO:_display_container: 7
2023-11-23 08:48:40,480:INFO:RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,
                      min_samples_split=10, n_estimators=150, n_jobs=-1,
                      random_state=123)
2023-11-23 08:48:40,480:INFO:create_model() successfully completed......................................
2023-11-23 08:48:40,530:INFO:SubProcess create_model() end ==================================
2023-11-23 08:48:40,530:INFO:choose_better activated
2023-11-23 08:48:40,532:INFO:SubProcess create_model() called ==================================
2023-11-23 08:48:40,532:INFO:Initializing create_model()
2023-11-23 08:48:40,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:48:40,532:INFO:Checking exceptions
2023-11-23 08:48:40,533:INFO:Importing libraries
2023-11-23 08:48:40,533:INFO:Copying training dataset
2023-11-23 08:48:40,535:INFO:Defining folds
2023-11-23 08:48:40,535:INFO:Declaring metric variables
2023-11-23 08:48:40,535:INFO:Importing untrained model
2023-11-23 08:48:40,535:INFO:Declaring custom model
2023-11-23 08:48:40,536:INFO:Random Forest Regressor Imported successfully
2023-11-23 08:48:40,536:INFO:Starting cross validation
2023-11-23 08:48:40,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:48:43,935:INFO:Calculating mean and std
2023-11-23 08:48:43,936:INFO:Creating metrics dataframe
2023-11-23 08:48:43,937:INFO:Finalizing model
2023-11-23 08:48:44,384:INFO:Uploading results into container
2023-11-23 08:48:44,385:INFO:Uploading model into container now
2023-11-23 08:48:44,385:INFO:_master_model_container: 25
2023-11-23 08:48:44,385:INFO:_display_container: 8
2023-11-23 08:48:44,385:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 08:48:44,385:INFO:create_model() successfully completed......................................
2023-11-23 08:48:44,433:INFO:SubProcess create_model() end ==================================
2023-11-23 08:48:44,433:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.2047
2023-11-23 08:48:44,433:INFO:RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,
                      min_samples_split=10, n_estimators=150, n_jobs=-1,
                      random_state=123) result for MAPE is 0.2042
2023-11-23 08:48:44,434:INFO:RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,
                      min_samples_split=10, n_estimators=150, n_jobs=-1,
                      random_state=123) is best model
2023-11-23 08:48:44,434:INFO:choose_better completed
2023-11-23 08:48:44,440:INFO:_master_model_container: 25
2023-11-23 08:48:44,440:INFO:_display_container: 7
2023-11-23 08:48:44,440:INFO:RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,
                      min_samples_split=10, n_estimators=150, n_jobs=-1,
                      random_state=123)
2023-11-23 08:48:44,440:INFO:tune_model() successfully completed......................................
2023-11-23 08:48:44,503:INFO:Initializing tune_model()
2023-11-23 08:48:44,503:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150], 'max_depth': [None, 3, 5, 7, 9], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2'], 'bootstrap': [True, False]}, optimize=mape, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>)
2023-11-23 08:48:44,503:INFO:Checking exceptions
2023-11-23 08:48:44,511:INFO:Copying training dataset
2023-11-23 08:48:44,514:INFO:Checking base model
2023-11-23 08:48:44,514:INFO:Base model : Extra Trees Regressor
2023-11-23 08:48:44,521:INFO:Declaring metric variables
2023-11-23 08:48:44,523:INFO:Defining Hyperparameters
2023-11-23 08:48:44,574:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150], 'actual_estimator__max_depth': [None, 3, 5, 7, 9], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__min_samples_leaf': [1, 2, 4], 'actual_estimator__max_features': ['auto', 'sqrt', 'log2'], 'actual_estimator__bootstrap': [True, False]}
2023-11-23 08:48:44,575:INFO:Tuning with n_jobs=-1
2023-11-23 08:48:44,575:INFO:Initializing RandomizedSearchCV
2023-11-23 08:48:44,594:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:44,601:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:44,612:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:44,619:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:44,640:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:44,652:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:44,681:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:44,942:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:45,432:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:45,449:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:46,026:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:46,148:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:46,159:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:46,234:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:46,443:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:46,492:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:46,502:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:46,518:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:47,530:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:47,566:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:47,741:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:47,931:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:47,998:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,155:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,200:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,224:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,225:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,226:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,291:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,295:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,609:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,623:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,682:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,719:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,722:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,726:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,735:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,741:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,753:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:48,755:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,418:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,471:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,633:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,669:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,710:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,801:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,827:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,829:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,870:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,920:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,925:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,927:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,928:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,931:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,957:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,962:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:50,963:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:51,343:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:52,142:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:52,200:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:56,592:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:56,619:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:56,747:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:56,816:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:56,817:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:56,835:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:56,882:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,092:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,095:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,096:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,099:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,114:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,141:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,142:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,179:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,225:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,235:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,271:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,366:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:57,437:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,294:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,313:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,336:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,384:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,410:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,446:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,645:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,748:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,749:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,749:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,751:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,757:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,811:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:58,817:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,068:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,078:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,085:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,149:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,154:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,157:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,238:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,252:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,260:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,277:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,279:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,280:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,290:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,315:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,328:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,407:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,582:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,616:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,647:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,745:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,798:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,817:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,825:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,830:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,933:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:48:59,942:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:00,764:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:00,765:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:00,811:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:00,834:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:00,842:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:00,882:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:00,891:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:00,895:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:00,984:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,002:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,007:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,058:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,125:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,208:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,327:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,372:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,407:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,420:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,422:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,444:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,470:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,498:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,599:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,656:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,665:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,721:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,825:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,841:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,925:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,973:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,987:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:01,991:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:02,017:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:02,076:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:02,164:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:02,201:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:02,249:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:02,263:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:02,464:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:02,528:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:03,265:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:03,310:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:03,375:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:03,426:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:03,467:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:03,471:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:03,475:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:03,623:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:03,626:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:03,712:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:06,876:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:06,883:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:06,901:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:06,912:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:06,986:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:06,988:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:06,989:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:06,993:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,000:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,019:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,045:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,048:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,052:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,121:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,163:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,303:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,446:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,463:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,466:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,485:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,919:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:07,919:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,023:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,035:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,036:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,037:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,280:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,318:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,388:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,494:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,506:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,530:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,596:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,731:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,863:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,885:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:08,911:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,214:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,300:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,391:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,687:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,795:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,815:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,866:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,895:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,961:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,962:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,966:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:09,983:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,000:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,042:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,046:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,057:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,063:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,137:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,168:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,172:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,172:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,195:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:10,303:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:11,745:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:11,772:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:11,780:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,045:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,115:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,117:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,141:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,150:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,435:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,446:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,558:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,719:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,774:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,812:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,829:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:12,833:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,151:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,169:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,178:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,181:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,515:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,521:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,523:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,524:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,604:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,616:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,813:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,814:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,908:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,912:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,962:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,984:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:13,993:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,006:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,062:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,108:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,131:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,160:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,163:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,221:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,344:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,398:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,399:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,412:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,461:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,546:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,587:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,599:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,835:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:14,947:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:15,021:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:15,045:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:15,107:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:15,121:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:15,122:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:15,149:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:15,469:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:15,532:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:16,080:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:16,082:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:16,659:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:16,667:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:16,742:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:16,793:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:16,817:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:16,893:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:16,923:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,023:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,053:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,205:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,210:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,212:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,236:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,370:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,407:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,622:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,769:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,866:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,866:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:17,871:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:18,451:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_features': 'auto', 'actual_estimator__max_depth': None, 'actual_estimator__bootstrap': False}
2023-11-23 08:49:18,453:INFO:Hyperparameter search completed
2023-11-23 08:49:18,453:INFO:SubProcess create_model() called ==================================
2023-11-23 08:49:18,454:INFO:Initializing create_model()
2023-11-23 08:49:18,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2839470d0>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': None, 'bootstrap': False})
2023-11-23 08:49:18,458:INFO:Checking exceptions
2023-11-23 08:49:18,458:INFO:Importing libraries
2023-11-23 08:49:18,458:INFO:Copying training dataset
2023-11-23 08:49:18,465:INFO:Defining folds
2023-11-23 08:49:18,465:INFO:Declaring metric variables
2023-11-23 08:49:18,468:INFO:Importing untrained model
2023-11-23 08:49:18,469:INFO:Declaring custom model
2023-11-23 08:49:18,472:INFO:Extra Trees Regressor Imported successfully
2023-11-23 08:49:18,476:INFO:Starting cross validation
2023-11-23 08:49:18,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:49:18,503:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:18,505:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:18,514:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:18,517:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:18,523:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:18,528:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:18,535:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:18,542:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:19,957:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:19,966:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 08:49:20,415:INFO:Calculating mean and std
2023-11-23 08:49:20,416:INFO:Creating metrics dataframe
2023-11-23 08:49:20,419:INFO:Finalizing model
2023-11-23 08:49:20,662:INFO:Initializing predict_model()
2023-11-23 08:49:20,662:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 ExtraTreesRegressor(max_features='auto', min_samples_leaf=2,
                                     n_estimators=150, n_jobs=-1,
                                     random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x17fc60f70>)
2023-11-23 08:49:20,662:INFO:Checking exceptions
2023-11-23 08:49:20,662:INFO:Preloading libraries
2023-11-23 08:49:20,662:INFO:Set up data.
2023-11-23 08:49:20,665:INFO:Set up index.
2023-11-23 08:49:20,784:INFO:Uploading results into container
2023-11-23 08:49:20,784:INFO:Uploading model into container now
2023-11-23 08:49:20,784:INFO:_master_model_container: 26
2023-11-23 08:49:20,784:INFO:_display_container: 8
2023-11-23 08:49:20,785:INFO:ExtraTreesRegressor(max_features='auto', min_samples_leaf=2, n_estimators=150,
                    n_jobs=-1, random_state=123)
2023-11-23 08:49:20,785:INFO:create_model() successfully completed......................................
2023-11-23 08:49:20,850:INFO:SubProcess create_model() end ==================================
2023-11-23 08:49:20,850:INFO:choose_better activated
2023-11-23 08:49:20,852:INFO:SubProcess create_model() called ==================================
2023-11-23 08:49:20,852:INFO:Initializing create_model()
2023-11-23 08:49:20,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2839eb190>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:49:20,852:INFO:Checking exceptions
2023-11-23 08:49:20,853:INFO:Importing libraries
2023-11-23 08:49:20,853:INFO:Copying training dataset
2023-11-23 08:49:20,855:INFO:Defining folds
2023-11-23 08:49:20,856:INFO:Declaring metric variables
2023-11-23 08:49:20,856:INFO:Importing untrained model
2023-11-23 08:49:20,856:INFO:Declaring custom model
2023-11-23 08:49:20,856:INFO:Extra Trees Regressor Imported successfully
2023-11-23 08:49:20,856:INFO:Starting cross validation
2023-11-23 08:49:20,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:49:22,365:INFO:Calculating mean and std
2023-11-23 08:49:22,365:INFO:Creating metrics dataframe
2023-11-23 08:49:22,366:INFO:Finalizing model
2023-11-23 08:49:22,563:INFO:Uploading results into container
2023-11-23 08:49:22,563:INFO:Uploading model into container now
2023-11-23 08:49:22,563:INFO:_master_model_container: 27
2023-11-23 08:49:22,563:INFO:_display_container: 9
2023-11-23 08:49:22,564:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 08:49:22,564:INFO:create_model() successfully completed......................................
2023-11-23 08:49:22,608:INFO:SubProcess create_model() end ==================================
2023-11-23 08:49:22,608:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.2146
2023-11-23 08:49:22,608:INFO:ExtraTreesRegressor(max_features='auto', min_samples_leaf=2, n_estimators=150,
                    n_jobs=-1, random_state=123) result for MAPE is 0.2142
2023-11-23 08:49:22,609:INFO:ExtraTreesRegressor(max_features='auto', min_samples_leaf=2, n_estimators=150,
                    n_jobs=-1, random_state=123) is best model
2023-11-23 08:49:22,609:INFO:choose_better completed
2023-11-23 08:49:22,615:INFO:_master_model_container: 27
2023-11-23 08:49:22,615:INFO:_display_container: 8
2023-11-23 08:49:22,616:INFO:ExtraTreesRegressor(max_features='auto', min_samples_leaf=2, n_estimators=150,
                    n_jobs=-1, random_state=123)
2023-11-23 08:49:22,616:INFO:tune_model() successfully completed......................................
2023-11-23 08:55:40,963:INFO:PyCaret RegressionExperiment
2023-11-23 08:55:40,963:INFO:Logging name: reg-default-name
2023-11-23 08:55:40,963:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-23 08:55:40,963:INFO:version 3.1.0
2023-11-23 08:55:40,963:INFO:Initializing setup()
2023-11-23 08:55:40,963:INFO:self.USI: 821b
2023-11-23 08:55:40,963:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'fold_shuffle_param', 'USI', 'html_param', '_ml_usecase', 'target_param', 'pipeline', 'n_jobs_param', 'gpu_n_jobs_param', 'transform_target_param', 'exp_name_log', 'X', 'exp_id', 'fold_groups_param', 'gpu_param', 'seed', 'idx', 'X_train', 'y_train', 'data', 'memory', '_available_plots', 'y', 'log_plots_param', 'y_test', 'X_test'}
2023-11-23 08:55:40,963:INFO:Checking environment
2023-11-23 08:55:40,963:INFO:python_version: 3.9.16
2023-11-23 08:55:40,963:INFO:python_build: ('main', 'Nov  2 2023 14:11:49')
2023-11-23 08:55:40,963:INFO:machine: arm64
2023-11-23 08:55:40,963:INFO:platform: macOS-13.4.1-arm64-arm-64bit
2023-11-23 08:55:40,963:INFO:Memory: svmem(total=8589934592, available=2443296768, percent=71.6, used=3255844864, free=512049152, active=1938194432, inactive=1840939008, wired=1317650432)
2023-11-23 08:55:40,963:INFO:Physical Core: 8
2023-11-23 08:55:40,963:INFO:Logical Core: 8
2023-11-23 08:55:40,963:INFO:Checking libraries
2023-11-23 08:55:40,963:INFO:System:
2023-11-23 08:55:40,963:INFO:    python: 3.9.16 (main, Nov  2 2023, 14:11:49)  [Clang 14.0.3 (clang-1403.0.22.14.1)]
2023-11-23 08:55:40,963:INFO:executable: /Users/macOs/.pyenv/versions/3.9.16/bin/python
2023-11-23 08:55:40,963:INFO:   machine: macOS-13.4.1-arm64-arm-64bit
2023-11-23 08:55:40,963:INFO:PyCaret required dependencies:
2023-11-23 08:55:40,964:INFO:                 pip: 22.0.4
2023-11-23 08:55:40,964:INFO:          setuptools: 58.1.0
2023-11-23 08:55:40,964:INFO:             pycaret: 3.1.0
2023-11-23 08:55:40,964:INFO:             IPython: 8.17.2
2023-11-23 08:55:40,964:INFO:          ipywidgets: 8.1.1
2023-11-23 08:55:40,964:INFO:                tqdm: 4.66.1
2023-11-23 08:55:40,964:INFO:               numpy: 1.23.5
2023-11-23 08:55:40,964:INFO:              pandas: 1.5.3
2023-11-23 08:55:40,964:INFO:              jinja2: 3.1.2
2023-11-23 08:55:40,964:INFO:               scipy: 1.10.1
2023-11-23 08:55:40,964:INFO:              joblib: 1.3.2
2023-11-23 08:55:40,964:INFO:             sklearn: 1.2.2
2023-11-23 08:55:40,964:INFO:                pyod: 1.1.1
2023-11-23 08:55:40,964:INFO:            imblearn: 0.11.0
2023-11-23 08:55:40,964:INFO:   category_encoders: 2.6.3
2023-11-23 08:55:40,964:INFO:            lightgbm: 4.1.0
2023-11-23 08:55:40,964:INFO:               numba: 0.58.1
2023-11-23 08:55:40,964:INFO:            requests: 2.31.0
2023-11-23 08:55:40,964:INFO:          matplotlib: 3.8.1
2023-11-23 08:55:40,964:INFO:          scikitplot: 0.3.7
2023-11-23 08:55:40,964:INFO:         yellowbrick: 1.5
2023-11-23 08:55:40,964:INFO:              plotly: 5.18.0
2023-11-23 08:55:40,964:INFO:    plotly-resampler: Not installed
2023-11-23 08:55:40,964:INFO:             kaleido: 0.2.1
2023-11-23 08:55:40,964:INFO:           schemdraw: 0.15
2023-11-23 08:55:40,964:INFO:         statsmodels: 0.14.0
2023-11-23 08:55:40,964:INFO:              sktime: 0.21.1
2023-11-23 08:55:40,964:INFO:               tbats: 1.1.3
2023-11-23 08:55:40,964:INFO:            pmdarima: 2.0.4
2023-11-23 08:55:40,964:INFO:              psutil: 5.9.6
2023-11-23 08:55:40,964:INFO:          markupsafe: 2.1.3
2023-11-23 08:55:40,964:INFO:             pickle5: Not installed
2023-11-23 08:55:40,964:INFO:         cloudpickle: 3.0.0
2023-11-23 08:55:40,964:INFO:         deprecation: 2.1.0
2023-11-23 08:55:40,964:INFO:              xxhash: 3.4.1
2023-11-23 08:55:40,964:INFO:           wurlitzer: 3.0.3
2023-11-23 08:55:40,964:INFO:PyCaret optional dependencies:
2023-11-23 08:55:40,964:INFO:                shap: Not installed
2023-11-23 08:55:40,964:INFO:           interpret: Not installed
2023-11-23 08:55:40,964:INFO:                umap: Not installed
2023-11-23 08:55:40,964:INFO:     ydata_profiling: Not installed
2023-11-23 08:55:40,964:INFO:  explainerdashboard: Not installed
2023-11-23 08:55:40,964:INFO:             autoviz: Not installed
2023-11-23 08:55:40,964:INFO:           fairlearn: Not installed
2023-11-23 08:55:40,964:INFO:          deepchecks: Not installed
2023-11-23 08:55:40,964:INFO:             xgboost: 2.0.2
2023-11-23 08:55:40,964:INFO:            catboost: Not installed
2023-11-23 08:55:40,964:INFO:              kmodes: Not installed
2023-11-23 08:55:40,964:INFO:             mlxtend: Not installed
2023-11-23 08:55:40,964:INFO:       statsforecast: Not installed
2023-11-23 08:55:40,964:INFO:        tune_sklearn: Not installed
2023-11-23 08:55:40,964:INFO:                 ray: Not installed
2023-11-23 08:55:40,964:INFO:            hyperopt: Not installed
2023-11-23 08:55:40,964:INFO:              optuna: Not installed
2023-11-23 08:55:40,965:INFO:               skopt: Not installed
2023-11-23 08:55:40,965:INFO:              mlflow: Not installed
2023-11-23 08:55:40,965:INFO:              gradio: Not installed
2023-11-23 08:55:40,965:INFO:             fastapi: Not installed
2023-11-23 08:55:40,965:INFO:             uvicorn: Not installed
2023-11-23 08:55:40,965:INFO:              m2cgen: Not installed
2023-11-23 08:55:40,965:INFO:           evidently: Not installed
2023-11-23 08:55:40,965:INFO:               fugue: Not installed
2023-11-23 08:55:40,965:INFO:           streamlit: Not installed
2023-11-23 08:55:40,965:INFO:             prophet: Not installed
2023-11-23 08:55:40,965:INFO:None
2023-11-23 08:55:40,965:INFO:Set up data.
2023-11-23 08:55:40,970:INFO:Set up folding strategy.
2023-11-23 08:55:40,970:INFO:Set up train/test split.
2023-11-23 08:55:40,974:INFO:Set up index.
2023-11-23 08:55:40,974:INFO:Assigning column types.
2023-11-23 08:55:40,976:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-23 08:55:40,977:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 08:55:40,979:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 08:55:40,981:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,029:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,030:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,032:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,034:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,036:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,080:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,080:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,081:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-23 08:55:41,083:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,085:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,110:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,130:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,133:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,135:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,161:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,180:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,182:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-23 08:55:41,186:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,230:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,235:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,260:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,279:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,279:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,280:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-23 08:55:41,309:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,329:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,359:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,378:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,378:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,380:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-23 08:55:41,408:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,428:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 08:55:41,477:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,478:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-23 08:55:41,527:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,528:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,576:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,578:INFO:Set up custom pipeline.
2023-11-23 08:55:41,590:INFO:Finished creating preprocessing pipeline.
2023-11-23 08:55:41,613:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/8h/q7dbs5196q9fcktcxkc2__dh0000gn/T/joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))])))])
2023-11-23 08:55:41,613:INFO:Creating final display dataframe.
2023-11-23 08:55:41,653:INFO:Setup _display_container:                    Description               Value
0                   Session id                 123
1                       Target  median_house_value
2                  Target type          Regression
3          Original data shape          (7560, 10)
4       Transformed data shape          (7560, 13)
5  Transformed train set shape          (5292, 13)
6   Transformed test set shape          (2268, 13)
7             Numeric features                   8
8         Categorical features                   1
2023-11-23 08:55:41,708:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,759:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 08:55:41,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 08:55:41,760:INFO:setup() successfully completed in 0.8s...............
2023-11-23 08:55:45,344:INFO:Initializing compare_models()
2023-11-23 08:55:45,344:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-23 08:55:45,344:INFO:Checking exceptions
2023-11-23 08:55:45,345:INFO:Preparing display monitor
2023-11-23 08:55:45,357:INFO:Initializing Linear Regression
2023-11-23 08:55:45,357:INFO:Total runtime is 3.631909688313802e-06 minutes
2023-11-23 08:55:45,358:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:45,358:INFO:Initializing create_model()
2023-11-23 08:55:45,358:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:45,358:INFO:Checking exceptions
2023-11-23 08:55:45,359:INFO:Importing libraries
2023-11-23 08:55:45,359:INFO:Copying training dataset
2023-11-23 08:55:45,361:INFO:Defining folds
2023-11-23 08:55:45,361:INFO:Declaring metric variables
2023-11-23 08:55:45,363:INFO:Importing untrained model
2023-11-23 08:55:45,364:INFO:Linear Regression Imported successfully
2023-11-23 08:55:45,367:INFO:Starting cross validation
2023-11-23 08:55:45,368:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:47,216:INFO:Calculating mean and std
2023-11-23 08:55:47,218:INFO:Creating metrics dataframe
2023-11-23 08:55:47,220:INFO:Uploading results into container
2023-11-23 08:55:47,221:INFO:Uploading model into container now
2023-11-23 08:55:47,221:INFO:_master_model_container: 1
2023-11-23 08:55:47,221:INFO:_display_container: 2
2023-11-23 08:55:47,222:INFO:LinearRegression(n_jobs=-1)
2023-11-23 08:55:47,222:INFO:create_model() successfully completed......................................
2023-11-23 08:55:47,289:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:47,289:INFO:Creating metrics dataframe
2023-11-23 08:55:47,293:INFO:Initializing Lasso Regression
2023-11-23 08:55:47,293:INFO:Total runtime is 0.03227566480636597 minutes
2023-11-23 08:55:47,294:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:47,295:INFO:Initializing create_model()
2023-11-23 08:55:47,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:47,295:INFO:Checking exceptions
2023-11-23 08:55:47,295:INFO:Importing libraries
2023-11-23 08:55:47,295:INFO:Copying training dataset
2023-11-23 08:55:47,297:INFO:Defining folds
2023-11-23 08:55:47,297:INFO:Declaring metric variables
2023-11-23 08:55:47,299:INFO:Importing untrained model
2023-11-23 08:55:47,300:INFO:Lasso Regression Imported successfully
2023-11-23 08:55:47,303:INFO:Starting cross validation
2023-11-23 08:55:47,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:47,422:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.205e+11, tolerance: 4.189e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 08:55:47,422:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.084e+11, tolerance: 4.143e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 08:55:47,425:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.344e+11, tolerance: 4.125e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 08:55:47,426:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.235e+11, tolerance: 4.117e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 08:55:47,433:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.169e+11, tolerance: 4.122e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 08:55:47,442:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.174e+11, tolerance: 4.140e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 08:55:47,445:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.019e+11, tolerance: 4.116e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 08:55:47,456:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.134e+11, tolerance: 4.121e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 08:55:47,502:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.070e+11, tolerance: 4.120e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 08:55:47,503:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.060e+11, tolerance: 4.135e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 08:55:47,514:INFO:Calculating mean and std
2023-11-23 08:55:47,515:INFO:Creating metrics dataframe
2023-11-23 08:55:47,516:INFO:Uploading results into container
2023-11-23 08:55:47,517:INFO:Uploading model into container now
2023-11-23 08:55:47,517:INFO:_master_model_container: 2
2023-11-23 08:55:47,517:INFO:_display_container: 2
2023-11-23 08:55:47,517:INFO:Lasso(random_state=123)
2023-11-23 08:55:47,517:INFO:create_model() successfully completed......................................
2023-11-23 08:55:47,563:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:47,564:INFO:Creating metrics dataframe
2023-11-23 08:55:47,568:INFO:Initializing Ridge Regression
2023-11-23 08:55:47,568:INFO:Total runtime is 0.03685710032780966 minutes
2023-11-23 08:55:47,569:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:47,570:INFO:Initializing create_model()
2023-11-23 08:55:47,570:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:47,570:INFO:Checking exceptions
2023-11-23 08:55:47,570:INFO:Importing libraries
2023-11-23 08:55:47,570:INFO:Copying training dataset
2023-11-23 08:55:47,572:INFO:Defining folds
2023-11-23 08:55:47,572:INFO:Declaring metric variables
2023-11-23 08:55:47,573:INFO:Importing untrained model
2023-11-23 08:55:47,574:INFO:Ridge Regression Imported successfully
2023-11-23 08:55:47,577:INFO:Starting cross validation
2023-11-23 08:55:47,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:47,634:INFO:Calculating mean and std
2023-11-23 08:55:47,635:INFO:Creating metrics dataframe
2023-11-23 08:55:47,636:INFO:Uploading results into container
2023-11-23 08:55:47,636:INFO:Uploading model into container now
2023-11-23 08:55:47,636:INFO:_master_model_container: 3
2023-11-23 08:55:47,636:INFO:_display_container: 2
2023-11-23 08:55:47,637:INFO:Ridge(random_state=123)
2023-11-23 08:55:47,637:INFO:create_model() successfully completed......................................
2023-11-23 08:55:47,680:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:47,680:INFO:Creating metrics dataframe
2023-11-23 08:55:47,684:INFO:Initializing Elastic Net
2023-11-23 08:55:47,684:INFO:Total runtime is 0.03879236777623495 minutes
2023-11-23 08:55:47,686:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:47,686:INFO:Initializing create_model()
2023-11-23 08:55:47,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:47,686:INFO:Checking exceptions
2023-11-23 08:55:47,686:INFO:Importing libraries
2023-11-23 08:55:47,686:INFO:Copying training dataset
2023-11-23 08:55:47,689:INFO:Defining folds
2023-11-23 08:55:47,689:INFO:Declaring metric variables
2023-11-23 08:55:47,690:INFO:Importing untrained model
2023-11-23 08:55:47,692:INFO:Elastic Net Imported successfully
2023-11-23 08:55:47,695:INFO:Starting cross validation
2023-11-23 08:55:47,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:47,768:INFO:Calculating mean and std
2023-11-23 08:55:47,769:INFO:Creating metrics dataframe
2023-11-23 08:55:47,770:INFO:Uploading results into container
2023-11-23 08:55:47,770:INFO:Uploading model into container now
2023-11-23 08:55:47,771:INFO:_master_model_container: 4
2023-11-23 08:55:47,771:INFO:_display_container: 2
2023-11-23 08:55:47,771:INFO:ElasticNet(random_state=123)
2023-11-23 08:55:47,771:INFO:create_model() successfully completed......................................
2023-11-23 08:55:47,813:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:47,813:INFO:Creating metrics dataframe
2023-11-23 08:55:47,818:INFO:Initializing Least Angle Regression
2023-11-23 08:55:47,818:INFO:Total runtime is 0.04102135101954143 minutes
2023-11-23 08:55:47,819:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:47,820:INFO:Initializing create_model()
2023-11-23 08:55:47,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:47,820:INFO:Checking exceptions
2023-11-23 08:55:47,820:INFO:Importing libraries
2023-11-23 08:55:47,820:INFO:Copying training dataset
2023-11-23 08:55:47,823:INFO:Defining folds
2023-11-23 08:55:47,823:INFO:Declaring metric variables
2023-11-23 08:55:47,824:INFO:Importing untrained model
2023-11-23 08:55:47,826:INFO:Least Angle Regression Imported successfully
2023-11-23 08:55:47,828:INFO:Starting cross validation
2023-11-23 08:55:47,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:47,902:INFO:Calculating mean and std
2023-11-23 08:55:47,903:INFO:Creating metrics dataframe
2023-11-23 08:55:47,904:INFO:Uploading results into container
2023-11-23 08:55:47,905:INFO:Uploading model into container now
2023-11-23 08:55:47,905:INFO:_master_model_container: 5
2023-11-23 08:55:47,905:INFO:_display_container: 2
2023-11-23 08:55:47,905:INFO:Lars(random_state=123)
2023-11-23 08:55:47,905:INFO:create_model() successfully completed......................................
2023-11-23 08:55:47,950:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:47,950:INFO:Creating metrics dataframe
2023-11-23 08:55:47,954:INFO:Initializing Lasso Least Angle Regression
2023-11-23 08:55:47,955:INFO:Total runtime is 0.04329977830251058 minutes
2023-11-23 08:55:47,956:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:47,956:INFO:Initializing create_model()
2023-11-23 08:55:47,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:47,956:INFO:Checking exceptions
2023-11-23 08:55:47,956:INFO:Importing libraries
2023-11-23 08:55:47,956:INFO:Copying training dataset
2023-11-23 08:55:47,958:INFO:Defining folds
2023-11-23 08:55:47,958:INFO:Declaring metric variables
2023-11-23 08:55:47,959:INFO:Importing untrained model
2023-11-23 08:55:47,961:INFO:Lasso Least Angle Regression Imported successfully
2023-11-23 08:55:47,964:INFO:Starting cross validation
2023-11-23 08:55:47,964:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:48,052:INFO:Calculating mean and std
2023-11-23 08:55:48,053:INFO:Creating metrics dataframe
2023-11-23 08:55:48,054:INFO:Uploading results into container
2023-11-23 08:55:48,055:INFO:Uploading model into container now
2023-11-23 08:55:48,055:INFO:_master_model_container: 6
2023-11-23 08:55:48,055:INFO:_display_container: 2
2023-11-23 08:55:48,055:INFO:LassoLars(random_state=123)
2023-11-23 08:55:48,055:INFO:create_model() successfully completed......................................
2023-11-23 08:55:48,097:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:48,097:INFO:Creating metrics dataframe
2023-11-23 08:55:48,103:INFO:Initializing Orthogonal Matching Pursuit
2023-11-23 08:55:48,103:INFO:Total runtime is 0.04577218294143677 minutes
2023-11-23 08:55:48,105:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:48,105:INFO:Initializing create_model()
2023-11-23 08:55:48,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:48,105:INFO:Checking exceptions
2023-11-23 08:55:48,105:INFO:Importing libraries
2023-11-23 08:55:48,105:INFO:Copying training dataset
2023-11-23 08:55:48,107:INFO:Defining folds
2023-11-23 08:55:48,107:INFO:Declaring metric variables
2023-11-23 08:55:48,108:INFO:Importing untrained model
2023-11-23 08:55:48,109:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-23 08:55:48,112:INFO:Starting cross validation
2023-11-23 08:55:48,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:48,171:INFO:Calculating mean and std
2023-11-23 08:55:48,172:INFO:Creating metrics dataframe
2023-11-23 08:55:48,174:INFO:Uploading results into container
2023-11-23 08:55:48,174:INFO:Uploading model into container now
2023-11-23 08:55:48,174:INFO:_master_model_container: 7
2023-11-23 08:55:48,174:INFO:_display_container: 2
2023-11-23 08:55:48,174:INFO:OrthogonalMatchingPursuit()
2023-11-23 08:55:48,174:INFO:create_model() successfully completed......................................
2023-11-23 08:55:48,218:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:48,218:INFO:Creating metrics dataframe
2023-11-23 08:55:48,222:INFO:Initializing Bayesian Ridge
2023-11-23 08:55:48,223:INFO:Total runtime is 0.04776648283004761 minutes
2023-11-23 08:55:48,224:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:48,224:INFO:Initializing create_model()
2023-11-23 08:55:48,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:48,224:INFO:Checking exceptions
2023-11-23 08:55:48,224:INFO:Importing libraries
2023-11-23 08:55:48,224:INFO:Copying training dataset
2023-11-23 08:55:48,226:INFO:Defining folds
2023-11-23 08:55:48,226:INFO:Declaring metric variables
2023-11-23 08:55:48,228:INFO:Importing untrained model
2023-11-23 08:55:48,229:INFO:Bayesian Ridge Imported successfully
2023-11-23 08:55:48,232:INFO:Starting cross validation
2023-11-23 08:55:48,232:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:48,301:INFO:Calculating mean and std
2023-11-23 08:55:48,302:INFO:Creating metrics dataframe
2023-11-23 08:55:48,304:INFO:Uploading results into container
2023-11-23 08:55:48,304:INFO:Uploading model into container now
2023-11-23 08:55:48,304:INFO:_master_model_container: 8
2023-11-23 08:55:48,304:INFO:_display_container: 2
2023-11-23 08:55:48,305:INFO:BayesianRidge()
2023-11-23 08:55:48,305:INFO:create_model() successfully completed......................................
2023-11-23 08:55:48,349:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:48,349:INFO:Creating metrics dataframe
2023-11-23 08:55:48,354:INFO:Initializing Passive Aggressive Regressor
2023-11-23 08:55:48,354:INFO:Total runtime is 0.04995838403701783 minutes
2023-11-23 08:55:48,355:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:48,356:INFO:Initializing create_model()
2023-11-23 08:55:48,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:48,356:INFO:Checking exceptions
2023-11-23 08:55:48,356:INFO:Importing libraries
2023-11-23 08:55:48,356:INFO:Copying training dataset
2023-11-23 08:55:48,358:INFO:Defining folds
2023-11-23 08:55:48,358:INFO:Declaring metric variables
2023-11-23 08:55:48,359:INFO:Importing untrained model
2023-11-23 08:55:48,361:INFO:Passive Aggressive Regressor Imported successfully
2023-11-23 08:55:48,363:INFO:Starting cross validation
2023-11-23 08:55:48,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:48,465:INFO:Calculating mean and std
2023-11-23 08:55:48,465:INFO:Creating metrics dataframe
2023-11-23 08:55:48,467:INFO:Uploading results into container
2023-11-23 08:55:48,467:INFO:Uploading model into container now
2023-11-23 08:55:48,467:INFO:_master_model_container: 9
2023-11-23 08:55:48,467:INFO:_display_container: 2
2023-11-23 08:55:48,467:INFO:PassiveAggressiveRegressor(random_state=123)
2023-11-23 08:55:48,467:INFO:create_model() successfully completed......................................
2023-11-23 08:55:48,511:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:48,511:INFO:Creating metrics dataframe
2023-11-23 08:55:48,517:INFO:Initializing Huber Regressor
2023-11-23 08:55:48,517:INFO:Total runtime is 0.052671583493550625 minutes
2023-11-23 08:55:48,518:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:48,518:INFO:Initializing create_model()
2023-11-23 08:55:48,518:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:48,518:INFO:Checking exceptions
2023-11-23 08:55:48,518:INFO:Importing libraries
2023-11-23 08:55:48,518:INFO:Copying training dataset
2023-11-23 08:55:48,521:INFO:Defining folds
2023-11-23 08:55:48,521:INFO:Declaring metric variables
2023-11-23 08:55:48,523:INFO:Importing untrained model
2023-11-23 08:55:48,524:INFO:Huber Regressor Imported successfully
2023-11-23 08:55:48,527:INFO:Starting cross validation
2023-11-23 08:55:48,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:48,608:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 08:55:48,615:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 08:55:48,626:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 08:55:48,626:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 08:55:48,632:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 08:55:48,632:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 08:55:48,644:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 08:55:48,645:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 08:55:48,674:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 08:55:48,678:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 08:55:48,690:INFO:Calculating mean and std
2023-11-23 08:55:48,691:INFO:Creating metrics dataframe
2023-11-23 08:55:48,692:INFO:Uploading results into container
2023-11-23 08:55:48,693:INFO:Uploading model into container now
2023-11-23 08:55:48,693:INFO:_master_model_container: 10
2023-11-23 08:55:48,693:INFO:_display_container: 2
2023-11-23 08:55:48,693:INFO:HuberRegressor()
2023-11-23 08:55:48,693:INFO:create_model() successfully completed......................................
2023-11-23 08:55:48,737:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:48,737:INFO:Creating metrics dataframe
2023-11-23 08:55:48,743:INFO:Initializing K Neighbors Regressor
2023-11-23 08:55:48,743:INFO:Total runtime is 0.056447283426920576 minutes
2023-11-23 08:55:48,745:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:48,745:INFO:Initializing create_model()
2023-11-23 08:55:48,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:48,745:INFO:Checking exceptions
2023-11-23 08:55:48,745:INFO:Importing libraries
2023-11-23 08:55:48,745:INFO:Copying training dataset
2023-11-23 08:55:48,747:INFO:Defining folds
2023-11-23 08:55:48,747:INFO:Declaring metric variables
2023-11-23 08:55:48,749:INFO:Importing untrained model
2023-11-23 08:55:48,751:INFO:K Neighbors Regressor Imported successfully
2023-11-23 08:55:48,753:INFO:Starting cross validation
2023-11-23 08:55:48,754:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:48,873:INFO:Calculating mean and std
2023-11-23 08:55:48,873:INFO:Creating metrics dataframe
2023-11-23 08:55:48,875:INFO:Uploading results into container
2023-11-23 08:55:48,875:INFO:Uploading model into container now
2023-11-23 08:55:48,875:INFO:_master_model_container: 11
2023-11-23 08:55:48,875:INFO:_display_container: 2
2023-11-23 08:55:48,875:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-23 08:55:48,875:INFO:create_model() successfully completed......................................
2023-11-23 08:55:48,919:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:48,919:INFO:Creating metrics dataframe
2023-11-23 08:55:48,924:INFO:Initializing Decision Tree Regressor
2023-11-23 08:55:48,924:INFO:Total runtime is 0.059465531508127854 minutes
2023-11-23 08:55:48,926:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:48,927:INFO:Initializing create_model()
2023-11-23 08:55:48,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:48,927:INFO:Checking exceptions
2023-11-23 08:55:48,927:INFO:Importing libraries
2023-11-23 08:55:48,927:INFO:Copying training dataset
2023-11-23 08:55:48,929:INFO:Defining folds
2023-11-23 08:55:48,929:INFO:Declaring metric variables
2023-11-23 08:55:48,931:INFO:Importing untrained model
2023-11-23 08:55:48,932:INFO:Decision Tree Regressor Imported successfully
2023-11-23 08:55:48,936:INFO:Starting cross validation
2023-11-23 08:55:48,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:49,055:INFO:Calculating mean and std
2023-11-23 08:55:49,056:INFO:Creating metrics dataframe
2023-11-23 08:55:49,057:INFO:Uploading results into container
2023-11-23 08:55:49,057:INFO:Uploading model into container now
2023-11-23 08:55:49,057:INFO:_master_model_container: 12
2023-11-23 08:55:49,057:INFO:_display_container: 2
2023-11-23 08:55:49,057:INFO:DecisionTreeRegressor(random_state=123)
2023-11-23 08:55:49,057:INFO:create_model() successfully completed......................................
2023-11-23 08:55:49,100:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:49,100:INFO:Creating metrics dataframe
2023-11-23 08:55:49,105:INFO:Initializing Random Forest Regressor
2023-11-23 08:55:49,105:INFO:Total runtime is 0.06248120069503785 minutes
2023-11-23 08:55:49,107:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:49,107:INFO:Initializing create_model()
2023-11-23 08:55:49,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:49,107:INFO:Checking exceptions
2023-11-23 08:55:49,107:INFO:Importing libraries
2023-11-23 08:55:49,108:INFO:Copying training dataset
2023-11-23 08:55:49,110:INFO:Defining folds
2023-11-23 08:55:49,110:INFO:Declaring metric variables
2023-11-23 08:55:49,112:INFO:Importing untrained model
2023-11-23 08:55:49,113:INFO:Random Forest Regressor Imported successfully
2023-11-23 08:55:49,117:INFO:Starting cross validation
2023-11-23 08:55:49,118:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:52,346:INFO:Calculating mean and std
2023-11-23 08:55:52,346:INFO:Creating metrics dataframe
2023-11-23 08:55:52,348:INFO:Uploading results into container
2023-11-23 08:55:52,348:INFO:Uploading model into container now
2023-11-23 08:55:52,348:INFO:_master_model_container: 13
2023-11-23 08:55:52,348:INFO:_display_container: 2
2023-11-23 08:55:52,348:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 08:55:52,348:INFO:create_model() successfully completed......................................
2023-11-23 08:55:52,392:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:52,392:INFO:Creating metrics dataframe
2023-11-23 08:55:52,398:INFO:Initializing Extra Trees Regressor
2023-11-23 08:55:52,398:INFO:Total runtime is 0.11735726594924928 minutes
2023-11-23 08:55:52,400:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:52,403:INFO:Initializing create_model()
2023-11-23 08:55:52,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:52,404:INFO:Checking exceptions
2023-11-23 08:55:52,404:INFO:Importing libraries
2023-11-23 08:55:52,404:INFO:Copying training dataset
2023-11-23 08:55:52,406:INFO:Defining folds
2023-11-23 08:55:52,406:INFO:Declaring metric variables
2023-11-23 08:55:52,409:INFO:Importing untrained model
2023-11-23 08:55:52,412:INFO:Extra Trees Regressor Imported successfully
2023-11-23 08:55:52,418:INFO:Starting cross validation
2023-11-23 08:55:52,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:53,971:INFO:Calculating mean and std
2023-11-23 08:55:53,972:INFO:Creating metrics dataframe
2023-11-23 08:55:53,973:INFO:Uploading results into container
2023-11-23 08:55:53,974:INFO:Uploading model into container now
2023-11-23 08:55:53,974:INFO:_master_model_container: 14
2023-11-23 08:55:53,974:INFO:_display_container: 2
2023-11-23 08:55:53,974:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 08:55:53,974:INFO:create_model() successfully completed......................................
2023-11-23 08:55:54,019:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:54,019:INFO:Creating metrics dataframe
2023-11-23 08:55:54,024:INFO:Initializing AdaBoost Regressor
2023-11-23 08:55:54,024:INFO:Total runtime is 0.14445751508076987 minutes
2023-11-23 08:55:54,026:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:54,026:INFO:Initializing create_model()
2023-11-23 08:55:54,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:54,026:INFO:Checking exceptions
2023-11-23 08:55:54,026:INFO:Importing libraries
2023-11-23 08:55:54,026:INFO:Copying training dataset
2023-11-23 08:55:54,030:INFO:Defining folds
2023-11-23 08:55:54,030:INFO:Declaring metric variables
2023-11-23 08:55:54,033:INFO:Importing untrained model
2023-11-23 08:55:54,036:INFO:AdaBoost Regressor Imported successfully
2023-11-23 08:55:54,041:INFO:Starting cross validation
2023-11-23 08:55:54,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:54,520:INFO:Calculating mean and std
2023-11-23 08:55:54,521:INFO:Creating metrics dataframe
2023-11-23 08:55:54,522:INFO:Uploading results into container
2023-11-23 08:55:54,522:INFO:Uploading model into container now
2023-11-23 08:55:54,523:INFO:_master_model_container: 15
2023-11-23 08:55:54,523:INFO:_display_container: 2
2023-11-23 08:55:54,523:INFO:AdaBoostRegressor(random_state=123)
2023-11-23 08:55:54,523:INFO:create_model() successfully completed......................................
2023-11-23 08:55:54,565:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:54,565:INFO:Creating metrics dataframe
2023-11-23 08:55:54,571:INFO:Initializing Gradient Boosting Regressor
2023-11-23 08:55:54,571:INFO:Total runtime is 0.15357901652654013 minutes
2023-11-23 08:55:54,573:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:54,573:INFO:Initializing create_model()
2023-11-23 08:55:54,573:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:54,573:INFO:Checking exceptions
2023-11-23 08:55:54,573:INFO:Importing libraries
2023-11-23 08:55:54,573:INFO:Copying training dataset
2023-11-23 08:55:54,576:INFO:Defining folds
2023-11-23 08:55:54,576:INFO:Declaring metric variables
2023-11-23 08:55:54,577:INFO:Importing untrained model
2023-11-23 08:55:54,579:INFO:Gradient Boosting Regressor Imported successfully
2023-11-23 08:55:54,582:INFO:Starting cross validation
2023-11-23 08:55:54,583:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:56,241:INFO:Calculating mean and std
2023-11-23 08:55:56,241:INFO:Creating metrics dataframe
2023-11-23 08:55:56,243:INFO:Uploading results into container
2023-11-23 08:55:56,243:INFO:Uploading model into container now
2023-11-23 08:55:56,243:INFO:_master_model_container: 16
2023-11-23 08:55:56,243:INFO:_display_container: 2
2023-11-23 08:55:56,243:INFO:GradientBoostingRegressor(random_state=123)
2023-11-23 08:55:56,243:INFO:create_model() successfully completed......................................
2023-11-23 08:55:56,286:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:56,286:INFO:Creating metrics dataframe
2023-11-23 08:55:56,293:INFO:Initializing Extreme Gradient Boosting
2023-11-23 08:55:56,293:INFO:Total runtime is 0.1822690010070801 minutes
2023-11-23 08:55:56,294:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:56,294:INFO:Initializing create_model()
2023-11-23 08:55:56,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:56,294:INFO:Checking exceptions
2023-11-23 08:55:56,294:INFO:Importing libraries
2023-11-23 08:55:56,294:INFO:Copying training dataset
2023-11-23 08:55:56,297:INFO:Defining folds
2023-11-23 08:55:56,297:INFO:Declaring metric variables
2023-11-23 08:55:56,298:INFO:Importing untrained model
2023-11-23 08:55:56,299:INFO:Extreme Gradient Boosting Imported successfully
2023-11-23 08:55:56,303:INFO:Starting cross validation
2023-11-23 08:55:56,304:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:56,385:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-23 08:55:56,385:WARNING:Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


2023-11-23 08:55:56,385:INFO:Initializing create_model()
2023-11-23 08:55:56,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:56,385:INFO:Checking exceptions
2023-11-23 08:55:56,385:INFO:Importing libraries
2023-11-23 08:55:56,385:INFO:Copying training dataset
2023-11-23 08:55:56,387:INFO:Defining folds
2023-11-23 08:55:56,387:INFO:Declaring metric variables
2023-11-23 08:55:56,388:INFO:Importing untrained model
2023-11-23 08:55:56,390:INFO:Extreme Gradient Boosting Imported successfully
2023-11-23 08:55:56,394:INFO:Starting cross validation
2023-11-23 08:55:56,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:56,444:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2023-11-23 08:55:56,445:ERROR:Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


2023-11-23 08:55:56,445:INFO:Initializing Light Gradient Boosting Machine
2023-11-23 08:55:56,445:INFO:Total runtime is 0.18480389912923179 minutes
2023-11-23 08:55:56,446:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:56,446:INFO:Initializing create_model()
2023-11-23 08:55:56,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:56,447:INFO:Checking exceptions
2023-11-23 08:55:56,447:INFO:Importing libraries
2023-11-23 08:55:56,447:INFO:Copying training dataset
2023-11-23 08:55:56,449:INFO:Defining folds
2023-11-23 08:55:56,449:INFO:Declaring metric variables
2023-11-23 08:55:56,450:INFO:Importing untrained model
2023-11-23 08:55:56,452:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 08:55:56,455:INFO:Starting cross validation
2023-11-23 08:55:56,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:58,964:INFO:Calculating mean and std
2023-11-23 08:55:58,965:INFO:Creating metrics dataframe
2023-11-23 08:55:58,966:INFO:Uploading results into container
2023-11-23 08:55:58,967:INFO:Uploading model into container now
2023-11-23 08:55:58,967:INFO:_master_model_container: 17
2023-11-23 08:55:58,967:INFO:_display_container: 2
2023-11-23 08:55:58,967:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 08:55:58,967:INFO:create_model() successfully completed......................................
2023-11-23 08:55:59,011:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:59,011:INFO:Creating metrics dataframe
2023-11-23 08:55:59,017:INFO:Initializing Dummy Regressor
2023-11-23 08:55:59,017:INFO:Total runtime is 0.22767457962036133 minutes
2023-11-23 08:55:59,019:INFO:SubProcess create_model() called ==================================
2023-11-23 08:55:59,019:INFO:Initializing create_model()
2023-11-23 08:55:59,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x288b4d160>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:59,019:INFO:Checking exceptions
2023-11-23 08:55:59,019:INFO:Importing libraries
2023-11-23 08:55:59,019:INFO:Copying training dataset
2023-11-23 08:55:59,021:INFO:Defining folds
2023-11-23 08:55:59,021:INFO:Declaring metric variables
2023-11-23 08:55:59,023:INFO:Importing untrained model
2023-11-23 08:55:59,024:INFO:Dummy Regressor Imported successfully
2023-11-23 08:55:59,027:INFO:Starting cross validation
2023-11-23 08:55:59,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 08:55:59,087:INFO:Calculating mean and std
2023-11-23 08:55:59,087:INFO:Creating metrics dataframe
2023-11-23 08:55:59,089:INFO:Uploading results into container
2023-11-23 08:55:59,089:INFO:Uploading model into container now
2023-11-23 08:55:59,089:INFO:_master_model_container: 18
2023-11-23 08:55:59,089:INFO:_display_container: 2
2023-11-23 08:55:59,089:INFO:DummyRegressor()
2023-11-23 08:55:59,089:INFO:create_model() successfully completed......................................
2023-11-23 08:55:59,132:INFO:SubProcess create_model() end ==================================
2023-11-23 08:55:59,132:INFO:Creating metrics dataframe
2023-11-23 08:55:59,142:INFO:Initializing create_model()
2023-11-23 08:55:59,143:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:59,143:INFO:Checking exceptions
2023-11-23 08:55:59,143:INFO:Importing libraries
2023-11-23 08:55:59,144:INFO:Copying training dataset
2023-11-23 08:55:59,145:INFO:Defining folds
2023-11-23 08:55:59,145:INFO:Declaring metric variables
2023-11-23 08:55:59,146:INFO:Importing untrained model
2023-11-23 08:55:59,146:INFO:Declaring custom model
2023-11-23 08:55:59,146:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 08:55:59,146:INFO:Cross validation set to False
2023-11-23 08:55:59,146:INFO:Fitting Model
2023-11-23 08:55:59,158:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 08:55:59,159:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.
2023-11-23 08:55:59,159:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 08:55:59,159:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 08:55:59,159:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 08:55:59,159:INFO:[LightGBM] [Info] Start training from score 186277.890967
2023-11-23 08:55:59,402:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 08:55:59,402:INFO:create_model() successfully completed......................................
2023-11-23 08:55:59,447:INFO:Initializing create_model()
2023-11-23 08:55:59,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:59,447:INFO:Checking exceptions
2023-11-23 08:55:59,448:INFO:Importing libraries
2023-11-23 08:55:59,448:INFO:Copying training dataset
2023-11-23 08:55:59,451:INFO:Defining folds
2023-11-23 08:55:59,451:INFO:Declaring metric variables
2023-11-23 08:55:59,451:INFO:Importing untrained model
2023-11-23 08:55:59,451:INFO:Declaring custom model
2023-11-23 08:55:59,451:INFO:Random Forest Regressor Imported successfully
2023-11-23 08:55:59,452:INFO:Cross validation set to False
2023-11-23 08:55:59,452:INFO:Fitting Model
2023-11-23 08:55:59,855:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 08:55:59,855:INFO:create_model() successfully completed......................................
2023-11-23 08:55:59,901:INFO:Initializing create_model()
2023-11-23 08:55:59,901:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2894b7790>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 08:55:59,901:INFO:Checking exceptions
2023-11-23 08:55:59,901:INFO:Importing libraries
2023-11-23 08:55:59,901:INFO:Copying training dataset
2023-11-23 08:55:59,903:INFO:Defining folds
2023-11-23 08:55:59,903:INFO:Declaring metric variables
2023-11-23 08:55:59,903:INFO:Importing untrained model
2023-11-23 08:55:59,903:INFO:Declaring custom model
2023-11-23 08:55:59,904:INFO:Extra Trees Regressor Imported successfully
2023-11-23 08:55:59,904:INFO:Cross validation set to False
2023-11-23 08:55:59,904:INFO:Fitting Model
2023-11-23 08:56:00,099:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 08:56:00,099:INFO:create_model() successfully completed......................................
2023-11-23 08:56:00,156:INFO:_master_model_container: 18
2023-11-23 08:56:00,156:INFO:_display_container: 2
2023-11-23 08:56:00,157:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123)]
2023-11-23 08:56:00,157:INFO:compare_models() successfully completed......................................
2023-11-23 12:41:31,040:INFO:PyCaret RegressionExperiment
2023-11-23 12:41:31,040:INFO:Logging name: reg-default-name
2023-11-23 12:41:31,040:INFO:ML Usecase: MLUsecase.REGRESSION
2023-11-23 12:41:31,040:INFO:version 3.1.0
2023-11-23 12:41:31,040:INFO:Initializing setup()
2023-11-23 12:41:31,040:INFO:self.USI: cbb6
2023-11-23 12:41:31,040:INFO:self._variable_keys: {'fold_generator', 'logging_param', 'fold_shuffle_param', 'USI', 'html_param', '_ml_usecase', 'target_param', 'pipeline', 'n_jobs_param', 'gpu_n_jobs_param', 'transform_target_param', 'exp_name_log', 'X', 'exp_id', 'fold_groups_param', 'gpu_param', 'seed', 'idx', 'X_train', 'y_train', 'data', 'memory', '_available_plots', 'y', 'log_plots_param', 'y_test', 'X_test'}
2023-11-23 12:41:31,040:INFO:Checking environment
2023-11-23 12:41:31,040:INFO:python_version: 3.9.16
2023-11-23 12:41:31,040:INFO:python_build: ('main', 'Nov  2 2023 14:11:49')
2023-11-23 12:41:31,040:INFO:machine: arm64
2023-11-23 12:41:31,040:INFO:platform: macOS-13.4.1-arm64-arm-64bit
2023-11-23 12:41:31,041:INFO:Memory: svmem(total=8589934592, available=1583382528, percent=81.6, used=2986770432, free=86212608, active=1507721216, inactive=1493073920, wired=1479049216)
2023-11-23 12:41:31,041:INFO:Physical Core: 8
2023-11-23 12:41:31,041:INFO:Logical Core: 8
2023-11-23 12:41:31,041:INFO:Checking libraries
2023-11-23 12:41:31,041:INFO:System:
2023-11-23 12:41:31,041:INFO:    python: 3.9.16 (main, Nov  2 2023, 14:11:49)  [Clang 14.0.3 (clang-1403.0.22.14.1)]
2023-11-23 12:41:31,041:INFO:executable: /Users/macOs/.pyenv/versions/3.9.16/bin/python
2023-11-23 12:41:31,041:INFO:   machine: macOS-13.4.1-arm64-arm-64bit
2023-11-23 12:41:31,041:INFO:PyCaret required dependencies:
2023-11-23 12:41:31,041:INFO:                 pip: 22.0.4
2023-11-23 12:41:31,041:INFO:          setuptools: 58.1.0
2023-11-23 12:41:31,041:INFO:             pycaret: 3.1.0
2023-11-23 12:41:31,041:INFO:             IPython: 8.17.2
2023-11-23 12:41:31,041:INFO:          ipywidgets: 8.1.1
2023-11-23 12:41:31,041:INFO:                tqdm: 4.66.1
2023-11-23 12:41:31,041:INFO:               numpy: 1.23.5
2023-11-23 12:41:31,041:INFO:              pandas: 1.5.3
2023-11-23 12:41:31,041:INFO:              jinja2: 3.1.2
2023-11-23 12:41:31,041:INFO:               scipy: 1.10.1
2023-11-23 12:41:31,041:INFO:              joblib: 1.3.2
2023-11-23 12:41:31,041:INFO:             sklearn: 1.2.2
2023-11-23 12:41:31,041:INFO:                pyod: 1.1.1
2023-11-23 12:41:31,041:INFO:            imblearn: 0.11.0
2023-11-23 12:41:31,041:INFO:   category_encoders: 2.6.3
2023-11-23 12:41:31,041:INFO:            lightgbm: 4.1.0
2023-11-23 12:41:31,041:INFO:               numba: 0.58.1
2023-11-23 12:41:31,041:INFO:            requests: 2.31.0
2023-11-23 12:41:31,041:INFO:          matplotlib: 3.8.1
2023-11-23 12:41:31,041:INFO:          scikitplot: 0.3.7
2023-11-23 12:41:31,041:INFO:         yellowbrick: 1.5
2023-11-23 12:41:31,041:INFO:              plotly: 5.18.0
2023-11-23 12:41:31,041:INFO:    plotly-resampler: Not installed
2023-11-23 12:41:31,041:INFO:             kaleido: 0.2.1
2023-11-23 12:41:31,041:INFO:           schemdraw: 0.15
2023-11-23 12:41:31,042:INFO:         statsmodels: 0.14.0
2023-11-23 12:41:31,042:INFO:              sktime: 0.21.1
2023-11-23 12:41:31,042:INFO:               tbats: 1.1.3
2023-11-23 12:41:31,042:INFO:            pmdarima: 2.0.4
2023-11-23 12:41:31,042:INFO:              psutil: 5.9.6
2023-11-23 12:41:31,042:INFO:          markupsafe: 2.1.3
2023-11-23 12:41:31,042:INFO:             pickle5: Not installed
2023-11-23 12:41:31,042:INFO:         cloudpickle: 3.0.0
2023-11-23 12:41:31,042:INFO:         deprecation: 2.1.0
2023-11-23 12:41:31,042:INFO:              xxhash: 3.4.1
2023-11-23 12:41:31,042:INFO:           wurlitzer: 3.0.3
2023-11-23 12:41:31,042:INFO:PyCaret optional dependencies:
2023-11-23 12:41:31,042:INFO:                shap: Not installed
2023-11-23 12:41:31,042:INFO:           interpret: Not installed
2023-11-23 12:41:31,042:INFO:                umap: Not installed
2023-11-23 12:41:31,042:INFO:     ydata_profiling: Not installed
2023-11-23 12:41:31,042:INFO:  explainerdashboard: Not installed
2023-11-23 12:41:31,042:INFO:             autoviz: Not installed
2023-11-23 12:41:31,042:INFO:           fairlearn: Not installed
2023-11-23 12:41:31,042:INFO:          deepchecks: Not installed
2023-11-23 12:41:31,042:INFO:             xgboost: 2.0.2
2023-11-23 12:41:31,042:INFO:            catboost: Not installed
2023-11-23 12:41:31,042:INFO:              kmodes: Not installed
2023-11-23 12:41:31,042:INFO:             mlxtend: Not installed
2023-11-23 12:41:31,042:INFO:       statsforecast: Not installed
2023-11-23 12:41:31,042:INFO:        tune_sklearn: Not installed
2023-11-23 12:41:31,042:INFO:                 ray: Not installed
2023-11-23 12:41:31,042:INFO:            hyperopt: Not installed
2023-11-23 12:41:31,042:INFO:              optuna: Not installed
2023-11-23 12:41:31,042:INFO:               skopt: Not installed
2023-11-23 12:41:31,042:INFO:              mlflow: Not installed
2023-11-23 12:41:31,042:INFO:              gradio: Not installed
2023-11-23 12:41:31,042:INFO:             fastapi: Not installed
2023-11-23 12:41:31,042:INFO:             uvicorn: Not installed
2023-11-23 12:41:31,042:INFO:              m2cgen: Not installed
2023-11-23 12:41:31,042:INFO:           evidently: Not installed
2023-11-23 12:41:31,042:INFO:               fugue: Not installed
2023-11-23 12:41:31,042:INFO:           streamlit: Not installed
2023-11-23 12:41:31,042:INFO:             prophet: Not installed
2023-11-23 12:41:31,042:INFO:None
2023-11-23 12:41:31,042:INFO:Set up data.
2023-11-23 12:41:31,046:INFO:Set up folding strategy.
2023-11-23 12:41:31,046:INFO:Set up train/test split.
2023-11-23 12:41:31,049:INFO:Set up index.
2023-11-23 12:41:31,049:INFO:Assigning column types.
2023-11-23 12:41:31,051:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-23 12:41:31,051:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,053:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,055:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,081:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,101:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,103:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,105:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,107:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,131:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,150:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,151:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,152:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-11-23 12:41:31,154:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,180:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,199:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,200:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,203:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,205:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,229:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,248:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,249:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,250:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-11-23 12:41:31,254:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,297:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,298:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,303:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,328:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,347:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,349:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-11-23 12:41:31,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,397:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,427:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,447:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,447:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,448:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-23 12:41:31,476:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,496:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-11-23 12:41:31,544:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,545:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-11-23 12:41:31,594:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,643:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,645:INFO:Set up custom pipeline.
2023-11-23 12:41:31,657:INFO:Finished creating preprocessing pipeline.
2023-11-23 12:41:31,679:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/8h/q7dbs5196q9fcktcxkc2__dh0000gn/T/joblib),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))])))])
2023-11-23 12:41:31,679:INFO:Creating final display dataframe.
2023-11-23 12:41:31,712:INFO:Setup _display_container:                    Description               Value
0                   Session id                 123
1                       Target  median_house_value
2                  Target type          Regression
3          Original data shape          (7560, 10)
4       Transformed data shape          (7560, 13)
5  Transformed train set shape          (5292, 13)
6   Transformed test set shape          (2268, 13)
7             Numeric features                   8
8         Categorical features                   1
2023-11-23 12:41:31,763:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,813:INFO:Soft dependency imported: xgboost: 2.0.2
2023-11-23 12:41:31,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-23 12:41:31,815:INFO:setup() successfully completed in 0.78s...............
2023-11-23 12:41:31,848:INFO:Initializing compare_models()
2023-11-23 12:41:31,848:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=2, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 2, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-11-23 12:41:31,849:INFO:Checking exceptions
2023-11-23 12:41:31,850:INFO:Preparing display monitor
2023-11-23 12:41:31,861:INFO:Initializing Linear Regression
2023-11-23 12:41:31,861:INFO:Total runtime is 1.8636385599772135e-06 minutes
2023-11-23 12:41:31,863:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:31,863:INFO:Initializing create_model()
2023-11-23 12:41:31,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:31,863:INFO:Checking exceptions
2023-11-23 12:41:31,863:INFO:Importing libraries
2023-11-23 12:41:31,863:INFO:Copying training dataset
2023-11-23 12:41:31,865:INFO:Defining folds
2023-11-23 12:41:31,866:INFO:Declaring metric variables
2023-11-23 12:41:31,867:INFO:Importing untrained model
2023-11-23 12:41:31,869:INFO:Linear Regression Imported successfully
2023-11-23 12:41:31,872:INFO:Starting cross validation
2023-11-23 12:41:31,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:33,871:INFO:Calculating mean and std
2023-11-23 12:41:33,875:INFO:Creating metrics dataframe
2023-11-23 12:41:33,879:INFO:Uploading results into container
2023-11-23 12:41:33,880:INFO:Uploading model into container now
2023-11-23 12:41:33,880:INFO:_master_model_container: 1
2023-11-23 12:41:33,880:INFO:_display_container: 2
2023-11-23 12:41:33,881:INFO:LinearRegression(n_jobs=-1)
2023-11-23 12:41:33,881:INFO:create_model() successfully completed......................................
2023-11-23 12:41:34,023:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:34,024:INFO:Creating metrics dataframe
2023-11-23 12:41:34,027:INFO:Initializing Lasso Regression
2023-11-23 12:41:34,028:INFO:Total runtime is 0.036114966869354254 minutes
2023-11-23 12:41:34,029:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:34,029:INFO:Initializing create_model()
2023-11-23 12:41:34,029:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:34,029:INFO:Checking exceptions
2023-11-23 12:41:34,029:INFO:Importing libraries
2023-11-23 12:41:34,029:INFO:Copying training dataset
2023-11-23 12:41:34,033:INFO:Defining folds
2023-11-23 12:41:34,033:INFO:Declaring metric variables
2023-11-23 12:41:34,035:INFO:Importing untrained model
2023-11-23 12:41:34,036:INFO:Lasso Regression Imported successfully
2023-11-23 12:41:34,043:INFO:Starting cross validation
2023-11-23 12:41:34,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:34,167:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.132e+11, tolerance: 4.151e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 12:41:34,167:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.139e+11, tolerance: 4.218e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 12:41:34,173:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.183e+11, tolerance: 4.180e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 12:41:34,203:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.026e+11, tolerance: 4.161e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 12:41:34,203:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.202e+11, tolerance: 4.181e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 12:41:34,210:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.889e+11, tolerance: 4.155e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 12:41:34,211:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.135e+11, tolerance: 4.197e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 12:41:34,222:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.929e+11, tolerance: 4.130e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 12:41:34,254:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.959e+11, tolerance: 4.159e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 12:41:34,262:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.033e+11, tolerance: 4.156e+09
  model = cd_fast.enet_coordinate_descent(

2023-11-23 12:41:34,274:INFO:Calculating mean and std
2023-11-23 12:41:34,274:INFO:Creating metrics dataframe
2023-11-23 12:41:34,275:INFO:Uploading results into container
2023-11-23 12:41:34,276:INFO:Uploading model into container now
2023-11-23 12:41:34,276:INFO:_master_model_container: 2
2023-11-23 12:41:34,276:INFO:_display_container: 2
2023-11-23 12:41:34,276:INFO:Lasso(random_state=123)
2023-11-23 12:41:34,276:INFO:create_model() successfully completed......................................
2023-11-23 12:41:34,330:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:34,330:INFO:Creating metrics dataframe
2023-11-23 12:41:34,335:INFO:Initializing Ridge Regression
2023-11-23 12:41:34,335:INFO:Total runtime is 0.04124728441238404 minutes
2023-11-23 12:41:34,337:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:34,337:INFO:Initializing create_model()
2023-11-23 12:41:34,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:34,337:INFO:Checking exceptions
2023-11-23 12:41:34,337:INFO:Importing libraries
2023-11-23 12:41:34,337:INFO:Copying training dataset
2023-11-23 12:41:34,339:INFO:Defining folds
2023-11-23 12:41:34,339:INFO:Declaring metric variables
2023-11-23 12:41:34,341:INFO:Importing untrained model
2023-11-23 12:41:34,342:INFO:Ridge Regression Imported successfully
2023-11-23 12:41:34,345:INFO:Starting cross validation
2023-11-23 12:41:34,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:34,428:INFO:Calculating mean and std
2023-11-23 12:41:34,429:INFO:Creating metrics dataframe
2023-11-23 12:41:34,430:INFO:Uploading results into container
2023-11-23 12:41:34,430:INFO:Uploading model into container now
2023-11-23 12:41:34,431:INFO:_master_model_container: 3
2023-11-23 12:41:34,431:INFO:_display_container: 2
2023-11-23 12:41:34,431:INFO:Ridge(random_state=123)
2023-11-23 12:41:34,431:INFO:create_model() successfully completed......................................
2023-11-23 12:41:34,478:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:34,478:INFO:Creating metrics dataframe
2023-11-23 12:41:34,483:INFO:Initializing Elastic Net
2023-11-23 12:41:34,483:INFO:Total runtime is 0.04370253086090088 minutes
2023-11-23 12:41:34,484:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:34,485:INFO:Initializing create_model()
2023-11-23 12:41:34,485:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:34,485:INFO:Checking exceptions
2023-11-23 12:41:34,485:INFO:Importing libraries
2023-11-23 12:41:34,485:INFO:Copying training dataset
2023-11-23 12:41:34,487:INFO:Defining folds
2023-11-23 12:41:34,487:INFO:Declaring metric variables
2023-11-23 12:41:34,489:INFO:Importing untrained model
2023-11-23 12:41:34,490:INFO:Elastic Net Imported successfully
2023-11-23 12:41:34,493:INFO:Starting cross validation
2023-11-23 12:41:34,494:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:34,563:INFO:Calculating mean and std
2023-11-23 12:41:34,564:INFO:Creating metrics dataframe
2023-11-23 12:41:34,565:INFO:Uploading results into container
2023-11-23 12:41:34,566:INFO:Uploading model into container now
2023-11-23 12:41:34,566:INFO:_master_model_container: 4
2023-11-23 12:41:34,566:INFO:_display_container: 2
2023-11-23 12:41:34,566:INFO:ElasticNet(random_state=123)
2023-11-23 12:41:34,566:INFO:create_model() successfully completed......................................
2023-11-23 12:41:34,613:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:34,613:INFO:Creating metrics dataframe
2023-11-23 12:41:34,618:INFO:Initializing Least Angle Regression
2023-11-23 12:41:34,618:INFO:Total runtime is 0.04595296382904053 minutes
2023-11-23 12:41:34,620:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:34,620:INFO:Initializing create_model()
2023-11-23 12:41:34,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:34,620:INFO:Checking exceptions
2023-11-23 12:41:34,620:INFO:Importing libraries
2023-11-23 12:41:34,620:INFO:Copying training dataset
2023-11-23 12:41:34,623:INFO:Defining folds
2023-11-23 12:41:34,623:INFO:Declaring metric variables
2023-11-23 12:41:34,624:INFO:Importing untrained model
2023-11-23 12:41:34,625:INFO:Least Angle Regression Imported successfully
2023-11-23 12:41:34,629:INFO:Starting cross validation
2023-11-23 12:41:34,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:34,709:INFO:Calculating mean and std
2023-11-23 12:41:34,710:INFO:Creating metrics dataframe
2023-11-23 12:41:34,713:INFO:Uploading results into container
2023-11-23 12:41:34,714:INFO:Uploading model into container now
2023-11-23 12:41:34,715:INFO:_master_model_container: 5
2023-11-23 12:41:34,715:INFO:_display_container: 2
2023-11-23 12:41:34,715:INFO:Lars(random_state=123)
2023-11-23 12:41:34,716:INFO:create_model() successfully completed......................................
2023-11-23 12:41:34,791:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:34,792:INFO:Creating metrics dataframe
2023-11-23 12:41:34,796:INFO:Initializing Lasso Least Angle Regression
2023-11-23 12:41:34,796:INFO:Total runtime is 0.048924215634663905 minutes
2023-11-23 12:41:34,798:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:34,798:INFO:Initializing create_model()
2023-11-23 12:41:34,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:34,798:INFO:Checking exceptions
2023-11-23 12:41:34,798:INFO:Importing libraries
2023-11-23 12:41:34,798:INFO:Copying training dataset
2023-11-23 12:41:34,802:INFO:Defining folds
2023-11-23 12:41:34,802:INFO:Declaring metric variables
2023-11-23 12:41:34,805:INFO:Importing untrained model
2023-11-23 12:41:34,807:INFO:Lasso Least Angle Regression Imported successfully
2023-11-23 12:41:34,814:INFO:Starting cross validation
2023-11-23 12:41:34,815:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:34,873:INFO:Calculating mean and std
2023-11-23 12:41:34,873:INFO:Creating metrics dataframe
2023-11-23 12:41:34,875:INFO:Uploading results into container
2023-11-23 12:41:34,875:INFO:Uploading model into container now
2023-11-23 12:41:34,875:INFO:_master_model_container: 6
2023-11-23 12:41:34,875:INFO:_display_container: 2
2023-11-23 12:41:34,875:INFO:LassoLars(random_state=123)
2023-11-23 12:41:34,875:INFO:create_model() successfully completed......................................
2023-11-23 12:41:34,927:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:34,928:INFO:Creating metrics dataframe
2023-11-23 12:41:34,933:INFO:Initializing Orthogonal Matching Pursuit
2023-11-23 12:41:34,933:INFO:Total runtime is 0.05120449860890707 minutes
2023-11-23 12:41:34,934:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:34,934:INFO:Initializing create_model()
2023-11-23 12:41:34,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:34,934:INFO:Checking exceptions
2023-11-23 12:41:34,935:INFO:Importing libraries
2023-11-23 12:41:34,935:INFO:Copying training dataset
2023-11-23 12:41:34,937:INFO:Defining folds
2023-11-23 12:41:34,937:INFO:Declaring metric variables
2023-11-23 12:41:34,939:INFO:Importing untrained model
2023-11-23 12:41:34,940:INFO:Orthogonal Matching Pursuit Imported successfully
2023-11-23 12:41:34,943:INFO:Starting cross validation
2023-11-23 12:41:34,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:35,002:INFO:Calculating mean and std
2023-11-23 12:41:35,002:INFO:Creating metrics dataframe
2023-11-23 12:41:35,004:INFO:Uploading results into container
2023-11-23 12:41:35,004:INFO:Uploading model into container now
2023-11-23 12:41:35,004:INFO:_master_model_container: 7
2023-11-23 12:41:35,004:INFO:_display_container: 2
2023-11-23 12:41:35,004:INFO:OrthogonalMatchingPursuit()
2023-11-23 12:41:35,004:INFO:create_model() successfully completed......................................
2023-11-23 12:41:35,058:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:35,058:INFO:Creating metrics dataframe
2023-11-23 12:41:35,063:INFO:Initializing Bayesian Ridge
2023-11-23 12:41:35,063:INFO:Total runtime is 0.05337639649709067 minutes
2023-11-23 12:41:35,065:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:35,065:INFO:Initializing create_model()
2023-11-23 12:41:35,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:35,065:INFO:Checking exceptions
2023-11-23 12:41:35,065:INFO:Importing libraries
2023-11-23 12:41:35,065:INFO:Copying training dataset
2023-11-23 12:41:35,068:INFO:Defining folds
2023-11-23 12:41:35,068:INFO:Declaring metric variables
2023-11-23 12:41:35,072:INFO:Importing untrained model
2023-11-23 12:41:35,078:INFO:Bayesian Ridge Imported successfully
2023-11-23 12:41:35,090:INFO:Starting cross validation
2023-11-23 12:41:35,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:35,163:INFO:Calculating mean and std
2023-11-23 12:41:35,164:INFO:Creating metrics dataframe
2023-11-23 12:41:35,166:INFO:Uploading results into container
2023-11-23 12:41:35,166:INFO:Uploading model into container now
2023-11-23 12:41:35,166:INFO:_master_model_container: 8
2023-11-23 12:41:35,166:INFO:_display_container: 2
2023-11-23 12:41:35,166:INFO:BayesianRidge()
2023-11-23 12:41:35,166:INFO:create_model() successfully completed......................................
2023-11-23 12:41:35,215:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:35,215:INFO:Creating metrics dataframe
2023-11-23 12:41:35,220:INFO:Initializing Passive Aggressive Regressor
2023-11-23 12:41:35,220:INFO:Total runtime is 0.055987962086995455 minutes
2023-11-23 12:41:35,222:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:35,222:INFO:Initializing create_model()
2023-11-23 12:41:35,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:35,222:INFO:Checking exceptions
2023-11-23 12:41:35,222:INFO:Importing libraries
2023-11-23 12:41:35,222:INFO:Copying training dataset
2023-11-23 12:41:35,225:INFO:Defining folds
2023-11-23 12:41:35,225:INFO:Declaring metric variables
2023-11-23 12:41:35,226:INFO:Importing untrained model
2023-11-23 12:41:35,227:INFO:Passive Aggressive Regressor Imported successfully
2023-11-23 12:41:35,230:INFO:Starting cross validation
2023-11-23 12:41:35,231:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:35,321:INFO:Calculating mean and std
2023-11-23 12:41:35,322:INFO:Creating metrics dataframe
2023-11-23 12:41:35,323:INFO:Uploading results into container
2023-11-23 12:41:35,324:INFO:Uploading model into container now
2023-11-23 12:41:35,324:INFO:_master_model_container: 9
2023-11-23 12:41:35,324:INFO:_display_container: 2
2023-11-23 12:41:35,324:INFO:PassiveAggressiveRegressor(random_state=123)
2023-11-23 12:41:35,324:INFO:create_model() successfully completed......................................
2023-11-23 12:41:35,371:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:35,371:INFO:Creating metrics dataframe
2023-11-23 12:41:35,377:INFO:Initializing Huber Regressor
2023-11-23 12:41:35,377:INFO:Total runtime is 0.05860236485799155 minutes
2023-11-23 12:41:35,378:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:35,378:INFO:Initializing create_model()
2023-11-23 12:41:35,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:35,378:INFO:Checking exceptions
2023-11-23 12:41:35,378:INFO:Importing libraries
2023-11-23 12:41:35,378:INFO:Copying training dataset
2023-11-23 12:41:35,381:INFO:Defining folds
2023-11-23 12:41:35,381:INFO:Declaring metric variables
2023-11-23 12:41:35,382:INFO:Importing untrained model
2023-11-23 12:41:35,384:INFO:Huber Regressor Imported successfully
2023-11-23 12:41:35,387:INFO:Starting cross validation
2023-11-23 12:41:35,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:35,470:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 12:41:35,473:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 12:41:35,478:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 12:41:35,478:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 12:41:35,490:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 12:41:35,494:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 12:41:35,509:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 12:41:35,513:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 12:41:35,541:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 12:41:35,542:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-11-23 12:41:35,546:INFO:Calculating mean and std
2023-11-23 12:41:35,546:INFO:Creating metrics dataframe
2023-11-23 12:41:35,548:INFO:Uploading results into container
2023-11-23 12:41:35,548:INFO:Uploading model into container now
2023-11-23 12:41:35,548:INFO:_master_model_container: 10
2023-11-23 12:41:35,548:INFO:_display_container: 2
2023-11-23 12:41:35,548:INFO:HuberRegressor()
2023-11-23 12:41:35,548:INFO:create_model() successfully completed......................................
2023-11-23 12:41:35,595:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:35,595:INFO:Creating metrics dataframe
2023-11-23 12:41:35,600:INFO:Initializing K Neighbors Regressor
2023-11-23 12:41:35,600:INFO:Total runtime is 0.06233073075612387 minutes
2023-11-23 12:41:35,608:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:35,608:INFO:Initializing create_model()
2023-11-23 12:41:35,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:35,608:INFO:Checking exceptions
2023-11-23 12:41:35,608:INFO:Importing libraries
2023-11-23 12:41:35,608:INFO:Copying training dataset
2023-11-23 12:41:35,612:INFO:Defining folds
2023-11-23 12:41:35,612:INFO:Declaring metric variables
2023-11-23 12:41:35,620:INFO:Importing untrained model
2023-11-23 12:41:35,625:INFO:K Neighbors Regressor Imported successfully
2023-11-23 12:41:35,628:INFO:Starting cross validation
2023-11-23 12:41:35,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:35,727:INFO:Calculating mean and std
2023-11-23 12:41:35,728:INFO:Creating metrics dataframe
2023-11-23 12:41:35,729:INFO:Uploading results into container
2023-11-23 12:41:35,730:INFO:Uploading model into container now
2023-11-23 12:41:35,730:INFO:_master_model_container: 11
2023-11-23 12:41:35,730:INFO:_display_container: 2
2023-11-23 12:41:35,730:INFO:KNeighborsRegressor(n_jobs=-1)
2023-11-23 12:41:35,730:INFO:create_model() successfully completed......................................
2023-11-23 12:41:35,778:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:35,778:INFO:Creating metrics dataframe
2023-11-23 12:41:35,783:INFO:Initializing Decision Tree Regressor
2023-11-23 12:41:35,783:INFO:Total runtime is 0.06537301143010459 minutes
2023-11-23 12:41:35,785:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:35,785:INFO:Initializing create_model()
2023-11-23 12:41:35,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:35,785:INFO:Checking exceptions
2023-11-23 12:41:35,786:INFO:Importing libraries
2023-11-23 12:41:35,786:INFO:Copying training dataset
2023-11-23 12:41:35,788:INFO:Defining folds
2023-11-23 12:41:35,788:INFO:Declaring metric variables
2023-11-23 12:41:35,790:INFO:Importing untrained model
2023-11-23 12:41:35,791:INFO:Decision Tree Regressor Imported successfully
2023-11-23 12:41:35,794:INFO:Starting cross validation
2023-11-23 12:41:35,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:35,914:INFO:Calculating mean and std
2023-11-23 12:41:35,914:INFO:Creating metrics dataframe
2023-11-23 12:41:35,916:INFO:Uploading results into container
2023-11-23 12:41:35,916:INFO:Uploading model into container now
2023-11-23 12:41:35,916:INFO:_master_model_container: 12
2023-11-23 12:41:35,916:INFO:_display_container: 2
2023-11-23 12:41:35,916:INFO:DecisionTreeRegressor(random_state=123)
2023-11-23 12:41:35,916:INFO:create_model() successfully completed......................................
2023-11-23 12:41:35,964:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:35,965:INFO:Creating metrics dataframe
2023-11-23 12:41:35,970:INFO:Initializing Random Forest Regressor
2023-11-23 12:41:35,971:INFO:Total runtime is 0.06850088040033978 minutes
2023-11-23 12:41:35,972:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:35,973:INFO:Initializing create_model()
2023-11-23 12:41:35,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:35,973:INFO:Checking exceptions
2023-11-23 12:41:35,973:INFO:Importing libraries
2023-11-23 12:41:35,973:INFO:Copying training dataset
2023-11-23 12:41:35,975:INFO:Defining folds
2023-11-23 12:41:35,975:INFO:Declaring metric variables
2023-11-23 12:41:35,977:INFO:Importing untrained model
2023-11-23 12:41:35,978:INFO:Random Forest Regressor Imported successfully
2023-11-23 12:41:35,981:INFO:Starting cross validation
2023-11-23 12:41:35,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:39,346:INFO:Calculating mean and std
2023-11-23 12:41:39,347:INFO:Creating metrics dataframe
2023-11-23 12:41:39,349:INFO:Uploading results into container
2023-11-23 12:41:39,350:INFO:Uploading model into container now
2023-11-23 12:41:39,350:INFO:_master_model_container: 13
2023-11-23 12:41:39,350:INFO:_display_container: 2
2023-11-23 12:41:39,350:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:41:39,350:INFO:create_model() successfully completed......................................
2023-11-23 12:41:39,402:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:39,402:INFO:Creating metrics dataframe
2023-11-23 12:41:39,407:INFO:Initializing Extra Trees Regressor
2023-11-23 12:41:39,407:INFO:Total runtime is 0.12577064832051596 minutes
2023-11-23 12:41:39,408:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:39,408:INFO:Initializing create_model()
2023-11-23 12:41:39,408:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:39,408:INFO:Checking exceptions
2023-11-23 12:41:39,408:INFO:Importing libraries
2023-11-23 12:41:39,408:INFO:Copying training dataset
2023-11-23 12:41:39,411:INFO:Defining folds
2023-11-23 12:41:39,411:INFO:Declaring metric variables
2023-11-23 12:41:39,413:INFO:Importing untrained model
2023-11-23 12:41:39,414:INFO:Extra Trees Regressor Imported successfully
2023-11-23 12:41:39,417:INFO:Starting cross validation
2023-11-23 12:41:39,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:41,028:INFO:Calculating mean and std
2023-11-23 12:41:41,028:INFO:Creating metrics dataframe
2023-11-23 12:41:41,030:INFO:Uploading results into container
2023-11-23 12:41:41,031:INFO:Uploading model into container now
2023-11-23 12:41:41,031:INFO:_master_model_container: 14
2023-11-23 12:41:41,031:INFO:_display_container: 2
2023-11-23 12:41:41,031:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:41:41,031:INFO:create_model() successfully completed......................................
2023-11-23 12:41:41,092:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:41,092:INFO:Creating metrics dataframe
2023-11-23 12:41:41,099:INFO:Initializing AdaBoost Regressor
2023-11-23 12:41:41,099:INFO:Total runtime is 0.15397168000539144 minutes
2023-11-23 12:41:41,101:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:41,101:INFO:Initializing create_model()
2023-11-23 12:41:41,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:41,101:INFO:Checking exceptions
2023-11-23 12:41:41,101:INFO:Importing libraries
2023-11-23 12:41:41,101:INFO:Copying training dataset
2023-11-23 12:41:41,104:INFO:Defining folds
2023-11-23 12:41:41,105:INFO:Declaring metric variables
2023-11-23 12:41:41,106:INFO:Importing untrained model
2023-11-23 12:41:41,107:INFO:AdaBoost Regressor Imported successfully
2023-11-23 12:41:41,110:INFO:Starting cross validation
2023-11-23 12:41:41,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:41,743:INFO:Calculating mean and std
2023-11-23 12:41:41,743:INFO:Creating metrics dataframe
2023-11-23 12:41:41,745:INFO:Uploading results into container
2023-11-23 12:41:41,745:INFO:Uploading model into container now
2023-11-23 12:41:41,745:INFO:_master_model_container: 15
2023-11-23 12:41:41,745:INFO:_display_container: 2
2023-11-23 12:41:41,745:INFO:AdaBoostRegressor(random_state=123)
2023-11-23 12:41:41,745:INFO:create_model() successfully completed......................................
2023-11-23 12:41:41,794:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:41,794:INFO:Creating metrics dataframe
2023-11-23 12:41:41,799:INFO:Initializing Gradient Boosting Regressor
2023-11-23 12:41:41,800:INFO:Total runtime is 0.1656493663787842 minutes
2023-11-23 12:41:41,801:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:41,802:INFO:Initializing create_model()
2023-11-23 12:41:41,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:41,802:INFO:Checking exceptions
2023-11-23 12:41:41,802:INFO:Importing libraries
2023-11-23 12:41:41,802:INFO:Copying training dataset
2023-11-23 12:41:41,804:INFO:Defining folds
2023-11-23 12:41:41,804:INFO:Declaring metric variables
2023-11-23 12:41:41,806:INFO:Importing untrained model
2023-11-23 12:41:41,807:INFO:Gradient Boosting Regressor Imported successfully
2023-11-23 12:41:41,810:INFO:Starting cross validation
2023-11-23 12:41:41,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:43,537:INFO:Calculating mean and std
2023-11-23 12:41:43,538:INFO:Creating metrics dataframe
2023-11-23 12:41:43,540:INFO:Uploading results into container
2023-11-23 12:41:43,540:INFO:Uploading model into container now
2023-11-23 12:41:43,540:INFO:_master_model_container: 16
2023-11-23 12:41:43,540:INFO:_display_container: 2
2023-11-23 12:41:43,540:INFO:GradientBoostingRegressor(random_state=123)
2023-11-23 12:41:43,540:INFO:create_model() successfully completed......................................
2023-11-23 12:41:43,590:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:43,591:INFO:Creating metrics dataframe
2023-11-23 12:41:43,596:INFO:Initializing Extreme Gradient Boosting
2023-11-23 12:41:43,596:INFO:Total runtime is 0.1955962657928467 minutes
2023-11-23 12:41:43,598:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:43,598:INFO:Initializing create_model()
2023-11-23 12:41:43,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:43,598:INFO:Checking exceptions
2023-11-23 12:41:43,598:INFO:Importing libraries
2023-11-23 12:41:43,598:INFO:Copying training dataset
2023-11-23 12:41:43,601:INFO:Defining folds
2023-11-23 12:41:43,601:INFO:Declaring metric variables
2023-11-23 12:41:43,603:INFO:Importing untrained model
2023-11-23 12:41:43,604:INFO:Extreme Gradient Boosting Imported successfully
2023-11-23 12:41:43,607:INFO:Starting cross validation
2023-11-23 12:41:43,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:43,705:WARNING:create_model() for xgboost raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-23 12:41:43,705:WARNING:Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


2023-11-23 12:41:43,705:INFO:Initializing create_model()
2023-11-23 12:41:43,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:43,705:INFO:Checking exceptions
2023-11-23 12:41:43,705:INFO:Importing libraries
2023-11-23 12:41:43,705:INFO:Copying training dataset
2023-11-23 12:41:43,707:INFO:Defining folds
2023-11-23 12:41:43,707:INFO:Declaring metric variables
2023-11-23 12:41:43,709:INFO:Importing untrained model
2023-11-23 12:41:43,711:INFO:Extreme Gradient Boosting Imported successfully
2023-11-23 12:41:43,715:INFO:Starting cross validation
2023-11-23 12:41:43,715:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:43,764:ERROR:create_model() for xgboost raised an exception or returned all 0.0:
2023-11-23 12:41:43,764:ERROR:Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 796, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 812, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1527, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1121, in _create_model_with_cv
    scores = cross_validate(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 1051, in fit
    train_dmatrix, evals = _wrap_evaluation_matrices(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 534, in _wrap_evaluation_matrices
    train_dmatrix = create_dmatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/sklearn.py", line 954, in _create_dmatrix
    return QuantileDMatrix(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1528, in __init__
    self._init(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1587, in _init
    it.reraise()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 575, in reraise
    raise exc  # pylint: disable=raising-bad-type
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 556, in _handle_exception
    return fn()
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 640, in <lambda>
    return self._handle_exception(lambda: self.next(input_data), 0)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/data.py", line 1280, in next
    input_data(**self.kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 632, in input_data
    self.proxy.set_info(
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 729, in inner_f
    return func(**kwargs)
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 945, in set_info
    self.feature_names = feature_names
  File "/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/xgboost/core.py", line 1321, in feature_names
    raise ValueError(
ValueError: feature_names must be string, and may not contain [, ] or <


2023-11-23 12:41:43,764:INFO:Initializing Light Gradient Boosting Machine
2023-11-23 12:41:43,764:INFO:Total runtime is 0.1983882506688436 minutes
2023-11-23 12:41:43,766:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:43,766:INFO:Initializing create_model()
2023-11-23 12:41:43,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:43,766:INFO:Checking exceptions
2023-11-23 12:41:43,766:INFO:Importing libraries
2023-11-23 12:41:43,766:INFO:Copying training dataset
2023-11-23 12:41:43,768:INFO:Defining folds
2023-11-23 12:41:43,768:INFO:Declaring metric variables
2023-11-23 12:41:43,769:INFO:Importing untrained model
2023-11-23 12:41:43,771:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 12:41:43,774:INFO:Starting cross validation
2023-11-23 12:41:43,774:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:46,381:INFO:Calculating mean and std
2023-11-23 12:41:46,382:INFO:Creating metrics dataframe
2023-11-23 12:41:46,384:INFO:Uploading results into container
2023-11-23 12:41:46,384:INFO:Uploading model into container now
2023-11-23 12:41:46,384:INFO:_master_model_container: 17
2023-11-23 12:41:46,384:INFO:_display_container: 2
2023-11-23 12:41:46,384:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:41:46,384:INFO:create_model() successfully completed......................................
2023-11-23 12:41:46,431:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:46,431:INFO:Creating metrics dataframe
2023-11-23 12:41:46,437:INFO:Initializing Dummy Regressor
2023-11-23 12:41:46,437:INFO:Total runtime is 0.24294580221176149 minutes
2023-11-23 12:41:46,439:INFO:SubProcess create_model() called ==================================
2023-11-23 12:41:46,439:INFO:Initializing create_model()
2023-11-23 12:41:46,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x282b9e370>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:46,439:INFO:Checking exceptions
2023-11-23 12:41:46,439:INFO:Importing libraries
2023-11-23 12:41:46,439:INFO:Copying training dataset
2023-11-23 12:41:46,442:INFO:Defining folds
2023-11-23 12:41:46,442:INFO:Declaring metric variables
2023-11-23 12:41:46,443:INFO:Importing untrained model
2023-11-23 12:41:46,445:INFO:Dummy Regressor Imported successfully
2023-11-23 12:41:46,447:INFO:Starting cross validation
2023-11-23 12:41:46,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:46,508:INFO:Calculating mean and std
2023-11-23 12:41:46,508:INFO:Creating metrics dataframe
2023-11-23 12:41:46,510:INFO:Uploading results into container
2023-11-23 12:41:46,510:INFO:Uploading model into container now
2023-11-23 12:41:46,510:INFO:_master_model_container: 18
2023-11-23 12:41:46,510:INFO:_display_container: 2
2023-11-23 12:41:46,510:INFO:DummyRegressor()
2023-11-23 12:41:46,510:INFO:create_model() successfully completed......................................
2023-11-23 12:41:46,558:INFO:SubProcess create_model() end ==================================
2023-11-23 12:41:46,558:INFO:Creating metrics dataframe
2023-11-23 12:41:46,569:INFO:Initializing create_model()
2023-11-23 12:41:46,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:46,569:INFO:Checking exceptions
2023-11-23 12:41:46,570:INFO:Importing libraries
2023-11-23 12:41:46,570:INFO:Copying training dataset
2023-11-23 12:41:46,572:INFO:Defining folds
2023-11-23 12:41:46,572:INFO:Declaring metric variables
2023-11-23 12:41:46,572:INFO:Importing untrained model
2023-11-23 12:41:46,572:INFO:Declaring custom model
2023-11-23 12:41:46,572:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 12:41:46,573:INFO:Cross validation set to False
2023-11-23 12:41:46,573:INFO:Fitting Model
2023-11-23 12:41:46,583:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 12:41:46,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2023-11-23 12:41:46,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 12:41:46,584:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 12:41:46,584:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 12:41:46,584:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 12:41:46,822:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:41:46,822:INFO:create_model() successfully completed......................................
2023-11-23 12:41:46,871:INFO:Initializing create_model()
2023-11-23 12:41:46,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:46,871:INFO:Checking exceptions
2023-11-23 12:41:46,872:INFO:Importing libraries
2023-11-23 12:41:46,872:INFO:Copying training dataset
2023-11-23 12:41:46,875:INFO:Defining folds
2023-11-23 12:41:46,875:INFO:Declaring metric variables
2023-11-23 12:41:46,875:INFO:Importing untrained model
2023-11-23 12:41:46,875:INFO:Declaring custom model
2023-11-23 12:41:46,875:INFO:Random Forest Regressor Imported successfully
2023-11-23 12:41:46,875:INFO:Cross validation set to False
2023-11-23 12:41:46,875:INFO:Fitting Model
2023-11-23 12:41:47,268:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:41:47,268:INFO:create_model() successfully completed......................................
2023-11-23 12:41:47,346:INFO:_master_model_container: 18
2023-11-23 12:41:47,346:INFO:_display_container: 2
2023-11-23 12:41:47,346:INFO:[LGBMRegressor(n_jobs=-1, random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123)]
2023-11-23 12:41:47,346:INFO:compare_models() successfully completed......................................
2023-11-23 12:41:47,380:INFO:Initializing create_model()
2023-11-23 12:41:47,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:47,380:INFO:Checking exceptions
2023-11-23 12:41:47,387:INFO:Importing libraries
2023-11-23 12:41:47,387:INFO:Copying training dataset
2023-11-23 12:41:47,390:INFO:Defining folds
2023-11-23 12:41:47,391:INFO:Declaring metric variables
2023-11-23 12:41:47,392:INFO:Importing untrained model
2023-11-23 12:41:47,392:INFO:Declaring custom model
2023-11-23 12:41:47,394:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 12:41:47,397:INFO:Starting cross validation
2023-11-23 12:41:47,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:50,033:INFO:Calculating mean and std
2023-11-23 12:41:50,033:INFO:Creating metrics dataframe
2023-11-23 12:41:50,036:INFO:Finalizing model
2023-11-23 12:41:50,048:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 12:41:50,049:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.
2023-11-23 12:41:50,049:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 12:41:50,049:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 12:41:50,049:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 12:41:50,049:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 12:41:50,049:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 12:41:50,334:INFO:Uploading results into container
2023-11-23 12:41:50,334:INFO:Uploading model into container now
2023-11-23 12:41:50,340:INFO:_master_model_container: 19
2023-11-23 12:41:50,340:INFO:_display_container: 3
2023-11-23 12:41:50,340:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:41:50,340:INFO:create_model() successfully completed......................................
2023-11-23 12:41:50,391:INFO:Initializing create_model()
2023-11-23 12:41:50,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:41:50,391:INFO:Checking exceptions
2023-11-23 12:41:50,410:INFO:Importing libraries
2023-11-23 12:41:50,410:INFO:Copying training dataset
2023-11-23 12:41:50,413:INFO:Defining folds
2023-11-23 12:41:50,413:INFO:Declaring metric variables
2023-11-23 12:41:50,425:INFO:Importing untrained model
2023-11-23 12:41:50,426:INFO:Declaring custom model
2023-11-23 12:41:50,428:INFO:Random Forest Regressor Imported successfully
2023-11-23 12:41:50,433:INFO:Starting cross validation
2023-11-23 12:41:50,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:41:53,758:INFO:Calculating mean and std
2023-11-23 12:41:53,760:INFO:Creating metrics dataframe
2023-11-23 12:41:53,764:INFO:Finalizing model
2023-11-23 12:41:54,176:INFO:Uploading results into container
2023-11-23 12:41:54,177:INFO:Uploading model into container now
2023-11-23 12:41:54,183:INFO:_master_model_container: 20
2023-11-23 12:41:54,183:INFO:_display_container: 4
2023-11-23 12:41:54,184:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:41:54,184:INFO:create_model() successfully completed......................................
2023-11-23 12:41:54,264:INFO:Initializing tune_model()
2023-11-23 12:41:54,265:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=100, custom_grid={'num_leaves': [50, 75, 100], 'max_depth': [-1, 10, 20], 'min_child_samples': [10, 20, 30], 'subsample': [0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [50, 100, 200], 'reg_alpha': [0, 0.1, 0.5, 1], 'reg_lambda': [0, 0.1, 0.5, 1], 'max_bin': [255, 355, 455], 'boosting_type': ['gbdt', 'dart']}, optimize=mape, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>)
2023-11-23 12:41:54,265:INFO:Checking exceptions
2023-11-23 12:41:54,273:INFO:Copying training dataset
2023-11-23 12:41:54,275:INFO:Checking base model
2023-11-23 12:41:54,275:INFO:Base model : Light Gradient Boosting Machine
2023-11-23 12:41:54,277:INFO:Declaring metric variables
2023-11-23 12:41:54,278:INFO:Defining Hyperparameters
2023-11-23 12:41:54,365:INFO:custom_grid: {'actual_estimator__num_leaves': [50, 75, 100], 'actual_estimator__max_depth': [-1, 10, 20], 'actual_estimator__min_child_samples': [10, 20, 30], 'actual_estimator__subsample': [0.7, 0.8, 0.9, 1.0], 'actual_estimator__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0], 'actual_estimator__learning_rate': [0.01, 0.05, 0.1], 'actual_estimator__n_estimators': [50, 100, 200], 'actual_estimator__reg_alpha': [0, 0.1, 0.5, 1], 'actual_estimator__reg_lambda': [0, 0.1, 0.5, 1], 'actual_estimator__max_bin': [255, 355, 455], 'actual_estimator__boosting_type': ['gbdt', 'dart']}
2023-11-23 12:41:54,365:INFO:Tuning with n_jobs=-1
2023-11-23 12:41:54,365:INFO:Initializing RandomizedSearchCV
2023-11-23 12:56:52,647:INFO:best_params: {'actual_estimator__subsample': 0.9, 'actual_estimator__reg_lambda': 1, 'actual_estimator__reg_alpha': 1, 'actual_estimator__num_leaves': 75, 'actual_estimator__n_estimators': 200, 'actual_estimator__min_child_samples': 30, 'actual_estimator__max_depth': -1, 'actual_estimator__max_bin': 455, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__colsample_bytree': 0.9, 'actual_estimator__boosting_type': 'dart'}
2023-11-23 12:56:52,654:INFO:Hyperparameter search completed
2023-11-23 12:56:52,654:INFO:SubProcess create_model() called ==================================
2023-11-23 12:56:52,655:INFO:Initializing create_model()
2023-11-23 12:56:52,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17ed27b50>, model_only=True, return_train_score=True, kwargs={'subsample': 0.9, 'reg_lambda': 1, 'reg_alpha': 1, 'num_leaves': 75, 'n_estimators': 200, 'min_child_samples': 30, 'max_depth': -1, 'max_bin': 455, 'learning_rate': 0.1, 'colsample_bytree': 0.9, 'boosting_type': 'dart'})
2023-11-23 12:56:52,655:INFO:Checking exceptions
2023-11-23 12:56:52,655:INFO:Importing libraries
2023-11-23 12:56:52,656:INFO:Copying training dataset
2023-11-23 12:56:52,660:INFO:Defining folds
2023-11-23 12:56:52,660:INFO:Declaring metric variables
2023-11-23 12:56:52,663:INFO:Importing untrained model
2023-11-23 12:56:52,664:INFO:Declaring custom model
2023-11-23 12:56:52,666:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 12:56:52,670:INFO:Starting cross validation
2023-11-23 12:56:52,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:57:05,799:INFO:Calculating mean and std
2023-11-23 12:57:05,800:INFO:Creating metrics dataframe
2023-11-23 12:57:05,807:INFO:Finalizing model
2023-11-23 12:57:05,820:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 12:57:05,822:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000733 seconds.
2023-11-23 12:57:05,822:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 12:57:05,822:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 12:57:05,822:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 12:57:05,822:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 12:57:05,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:06,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:06,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:06,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:06,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:06,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:06,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:06,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:06,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:06,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:07,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 12:57:07,325:INFO:Initializing predict_model()
2023-11-23 12:57:07,325:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x2818044c0>)
2023-11-23 12:57:07,325:INFO:Checking exceptions
2023-11-23 12:57:07,325:INFO:Preloading libraries
2023-11-23 12:57:07,325:INFO:Set up data.
2023-11-23 12:57:07,330:INFO:Set up index.
2023-11-23 12:57:07,462:INFO:Uploading results into container
2023-11-23 12:57:07,463:INFO:Uploading model into container now
2023-11-23 12:57:07,464:INFO:_master_model_container: 21
2023-11-23 12:57:07,464:INFO:_display_container: 5
2023-11-23 12:57:07,465:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9)
2023-11-23 12:57:07,465:INFO:create_model() successfully completed......................................
2023-11-23 12:57:07,526:INFO:SubProcess create_model() end ==================================
2023-11-23 12:57:07,526:INFO:choose_better activated
2023-11-23 12:57:07,528:INFO:SubProcess create_model() called ==================================
2023-11-23 12:57:07,529:INFO:Initializing create_model()
2023-11-23 12:57:07,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:57:07,529:INFO:Checking exceptions
2023-11-23 12:57:07,530:INFO:Importing libraries
2023-11-23 12:57:07,530:INFO:Copying training dataset
2023-11-23 12:57:07,533:INFO:Defining folds
2023-11-23 12:57:07,533:INFO:Declaring metric variables
2023-11-23 12:57:07,533:INFO:Importing untrained model
2023-11-23 12:57:07,533:INFO:Declaring custom model
2023-11-23 12:57:07,533:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 12:57:07,534:INFO:Starting cross validation
2023-11-23 12:57:07,534:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:57:09,986:INFO:Calculating mean and std
2023-11-23 12:57:09,987:INFO:Creating metrics dataframe
2023-11-23 12:57:09,987:INFO:Finalizing model
2023-11-23 12:57:09,998:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 12:57:09,998:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2023-11-23 12:57:09,998:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 12:57:09,998:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 12:57:09,999:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 12:57:09,999:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 12:57:10,238:INFO:Uploading results into container
2023-11-23 12:57:10,238:INFO:Uploading model into container now
2023-11-23 12:57:10,238:INFO:_master_model_container: 22
2023-11-23 12:57:10,238:INFO:_display_container: 6
2023-11-23 12:57:10,239:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:57:10,239:INFO:create_model() successfully completed......................................
2023-11-23 12:57:10,285:INFO:SubProcess create_model() end ==================================
2023-11-23 12:57:10,286:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.1867
2023-11-23 12:57:10,288:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9) result for MAPE is 0.1766
2023-11-23 12:57:10,288:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9) is best model
2023-11-23 12:57:10,288:INFO:choose_better completed
2023-11-23 12:57:10,296:INFO:_master_model_container: 22
2023-11-23 12:57:10,296:INFO:_display_container: 5
2023-11-23 12:57:10,297:INFO:LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9)
2023-11-23 12:57:10,297:INFO:tune_model() successfully completed......................................
2023-11-23 12:57:10,355:INFO:Initializing tune_model()
2023-11-23 12:57:10,355:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=100, custom_grid={'n_estimators': [10, 50, 100, 150], 'max_depth': [None, 3, 5, 7, 9], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['auto', 'sqrt', 'log2'], 'bootstrap': [True, False]}, optimize=mape, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>)
2023-11-23 12:57:10,355:INFO:Checking exceptions
2023-11-23 12:57:10,363:INFO:Copying training dataset
2023-11-23 12:57:10,366:INFO:Checking base model
2023-11-23 12:57:10,366:INFO:Base model : Random Forest Regressor
2023-11-23 12:57:10,368:INFO:Declaring metric variables
2023-11-23 12:57:10,370:INFO:Defining Hyperparameters
2023-11-23 12:57:10,426:INFO:custom_grid: {'actual_estimator__n_estimators': [10, 50, 100, 150], 'actual_estimator__max_depth': [None, 3, 5, 7, 9], 'actual_estimator__min_samples_split': [2, 5, 10], 'actual_estimator__min_samples_leaf': [1, 2, 4], 'actual_estimator__max_features': ['auto', 'sqrt', 'log2'], 'actual_estimator__bootstrap': [True, False]}
2023-11-23 12:57:10,426:INFO:Tuning with n_jobs=-1
2023-11-23 12:57:10,427:INFO:Initializing RandomizedSearchCV
2023-11-23 12:57:10,471:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:10,477:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:10,483:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:10,486:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:10,495:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:10,496:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:10,509:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:10,530:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:12,943:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:13,011:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:14,370:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:14,433:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:14,701:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:14,793:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:14,958:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:14,996:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:15,069:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:15,196:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,230:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,336:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,417:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,424:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,615:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,689:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,778:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,877:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,877:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,926:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,935:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:18,954:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:20,025:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:20,095:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:20,333:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:20,436:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:20,443:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:20,506:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:20,623:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:20,644:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:20,689:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:20,706:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:24,849:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:24,918:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:24,928:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,024:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,215:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,240:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,242:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,416:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,462:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,560:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,572:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,615:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,636:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,728:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,821:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,823:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:25,910:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:26,239:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:30,548:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:30,592:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:41,078:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:41,089:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:41,202:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:41,238:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:41,386:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:41,472:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:41,543:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:41,731:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,134:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,229:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,280:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,357:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,437:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,456:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,660:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,668:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,724:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,808:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,826:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:42,974:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:45,728:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:45,756:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:45,837:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:46,144:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:46,573:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:46,601:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:46,632:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:46,704:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:46,832:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:46,843:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:47,115:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:47,278:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:47,508:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:47,673:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:47,723:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:47,841:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,027:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,102:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,141:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,517:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,628:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,722:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,792:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,804:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,869:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,879:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,917:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,962:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:48,976:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,013:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,397:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,399:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,409:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,586:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,606:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,620:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,704:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,706:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,872:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:49,937:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:51,650:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:51,662:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:51,670:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:51,703:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:51,755:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:51,758:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:51,782:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:51,802:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:51,816:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:51,817:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:52,325:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:52,331:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:52,341:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:52,400:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:52,629:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:52,755:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:52,964:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:53,022:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:53,581:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:53,802:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:53,849:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:54,017:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:54,142:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:54,377:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:54,387:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:54,605:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:54,990:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:55,211:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:56,142:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:56,240:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:56,451:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:56,579:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:56,795:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:57,124:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:57,304:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:57,473:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:58,086:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:58,091:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:58,175:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:57:58,355:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:00,671:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:00,692:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:00,712:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:00,723:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:00,777:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:00,778:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:00,800:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:00,868:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:01,449:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:01,476:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:08,917:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:08,946:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,117:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,169:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,179:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,250:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,290:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,294:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,357:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,359:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,366:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,370:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,371:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,409:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,419:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,421:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,461:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:09,506:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:10,716:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:10,784:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:11,465:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:11,517:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:11,879:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:11,925:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:11,932:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:11,961:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:12,003:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:12,070:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:14,269:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:14,480:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:14,747:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:14,935:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:14,955:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:14,970:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:15,057:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:15,273:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:16,959:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:16,975:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:17,028:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:17,052:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:18,767:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:18,772:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:18,910:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:18,942:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:18,955:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,123:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,181:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,186:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,221:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,232:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,260:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,450:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,460:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,464:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,519:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,523:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,551:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:19,647:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:20,226:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:20,329:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:24,052:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:24,057:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:24,065:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:24,148:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:24,273:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:25,756:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:25,793:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:25,915:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:25,929:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:26,132:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:26,273:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:26,792:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:27,383:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:27,436:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:27,445:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:27,899:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:28,593:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:28,853:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:29,152:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:29,156:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:29,794:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:29,892:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:30,228:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:30,449:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:30,745:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:30,762:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:31,071:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:31,342:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:32,398:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:32,515:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:32,818:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,067:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,172:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,227:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,272:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,350:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,358:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,364:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,480:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,565:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,610:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,624:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,643:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,666:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,666:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:33,865:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:34,810:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:34,980:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:36,037:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:36,052:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:36,065:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:36,073:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:36,251:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:36,459:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:37,483:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:37,736:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:38,466:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:38,625:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:39,616:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:39,690:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:43,288:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:43,299:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:43,304:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:43,310:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:43,315:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:43,376:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:43,376:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:43,387:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:45,496:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:45,624:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:45,983:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:45,988:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:46,013:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:46,025:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:46,031:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:46,060:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:47,637:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:47,817:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:49,254:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:49,527:WARNING:/Users/macOs/.pyenv/versions/3.9.16/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.
  warn(

2023-11-23 12:58:51,433:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': None, 'actual_estimator__bootstrap': False}
2023-11-23 12:58:51,435:INFO:Hyperparameter search completed
2023-11-23 12:58:51,435:INFO:SubProcess create_model() called ==================================
2023-11-23 12:58:51,436:INFO:Initializing create_model()
2023-11-23 12:58:51,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17fb6ba30>, model_only=True, return_train_score=True, kwargs={'n_estimators': 150, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': None, 'bootstrap': False})
2023-11-23 12:58:51,436:INFO:Checking exceptions
2023-11-23 12:58:51,436:INFO:Importing libraries
2023-11-23 12:58:51,436:INFO:Copying training dataset
2023-11-23 12:58:51,440:INFO:Defining folds
2023-11-23 12:58:51,440:INFO:Declaring metric variables
2023-11-23 12:58:51,444:INFO:Importing untrained model
2023-11-23 12:58:51,444:INFO:Declaring custom model
2023-11-23 12:58:51,447:INFO:Random Forest Regressor Imported successfully
2023-11-23 12:58:51,450:INFO:Starting cross validation
2023-11-23 12:58:51,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:58:53,497:INFO:Calculating mean and std
2023-11-23 12:58:53,498:INFO:Creating metrics dataframe
2023-11-23 12:58:53,501:INFO:Finalizing model
2023-11-23 12:58:53,785:INFO:Initializing predict_model()
2023-11-23 12:58:53,785:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 RandomForestRegressor(bootstrap=False, max_features='log2',
                                       min_samples_leaf=2, min_samples_split=10,
                                       n_estimators=150, n_jobs=-1,
                                       random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x289646670>)
2023-11-23 12:58:53,785:INFO:Checking exceptions
2023-11-23 12:58:53,785:INFO:Preloading libraries
2023-11-23 12:58:53,785:INFO:Set up data.
2023-11-23 12:58:53,788:INFO:Set up index.
2023-11-23 12:58:53,903:INFO:Uploading results into container
2023-11-23 12:58:53,903:INFO:Uploading model into container now
2023-11-23 12:58:53,903:INFO:_master_model_container: 23
2023-11-23 12:58:53,903:INFO:_display_container: 6
2023-11-23 12:58:53,904:INFO:RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,
                      min_samples_split=10, n_estimators=150, n_jobs=-1,
                      random_state=123)
2023-11-23 12:58:53,904:INFO:create_model() successfully completed......................................
2023-11-23 12:58:53,956:INFO:SubProcess create_model() end ==================================
2023-11-23 12:58:53,956:INFO:choose_better activated
2023-11-23 12:58:53,958:INFO:SubProcess create_model() called ==================================
2023-11-23 12:58:53,958:INFO:Initializing create_model()
2023-11-23 12:58:53,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:58:53,958:INFO:Checking exceptions
2023-11-23 12:58:53,959:INFO:Importing libraries
2023-11-23 12:58:53,959:INFO:Copying training dataset
2023-11-23 12:58:53,961:INFO:Defining folds
2023-11-23 12:58:53,961:INFO:Declaring metric variables
2023-11-23 12:58:53,961:INFO:Importing untrained model
2023-11-23 12:58:53,962:INFO:Declaring custom model
2023-11-23 12:58:53,962:INFO:Random Forest Regressor Imported successfully
2023-11-23 12:58:53,962:INFO:Starting cross validation
2023-11-23 12:58:53,962:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:58:57,182:INFO:Calculating mean and std
2023-11-23 12:58:57,182:INFO:Creating metrics dataframe
2023-11-23 12:58:57,183:INFO:Finalizing model
2023-11-23 12:58:57,584:INFO:Uploading results into container
2023-11-23 12:58:57,585:INFO:Uploading model into container now
2023-11-23 12:58:57,585:INFO:_master_model_container: 24
2023-11-23 12:58:57,585:INFO:_display_container: 7
2023-11-23 12:58:57,585:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:58:57,585:INFO:create_model() successfully completed......................................
2023-11-23 12:58:57,632:INFO:SubProcess create_model() end ==================================
2023-11-23 12:58:57,632:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for MAPE is 0.2044
2023-11-23 12:58:57,633:INFO:RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,
                      min_samples_split=10, n_estimators=150, n_jobs=-1,
                      random_state=123) result for MAPE is 0.204
2023-11-23 12:58:57,633:INFO:RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,
                      min_samples_split=10, n_estimators=150, n_jobs=-1,
                      random_state=123) is best model
2023-11-23 12:58:57,633:INFO:choose_better completed
2023-11-23 12:58:57,639:INFO:_master_model_container: 24
2023-11-23 12:58:57,640:INFO:_display_container: 6
2023-11-23 12:58:57,640:INFO:RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,
                      min_samples_split=10, n_estimators=150, n_jobs=-1,
                      random_state=123)
2023-11-23 12:58:57,640:INFO:tune_model() successfully completed......................................
2023-11-23 12:58:57,833:INFO:Initializing create_model()
2023-11-23 12:58:57,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=lightgbm, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:58:57,833:INFO:Checking exceptions
2023-11-23 12:58:57,845:INFO:Importing libraries
2023-11-23 12:58:57,846:INFO:Copying training dataset
2023-11-23 12:58:57,848:INFO:Defining folds
2023-11-23 12:58:57,849:INFO:Declaring metric variables
2023-11-23 12:58:57,850:INFO:Importing untrained model
2023-11-23 12:58:57,852:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 12:58:57,854:INFO:Cross validation set to False
2023-11-23 12:58:57,854:INFO:Fitting Model
2023-11-23 12:58:57,871:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 12:58:57,872:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000652 seconds.
2023-11-23 12:58:57,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 12:58:57,872:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 12:58:57,872:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 12:58:57,873:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 12:58:58,147:INFO:Initializing predict_model()
2023-11-23 12:58:58,148:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x17fc60f70>)
2023-11-23 12:58:58,148:INFO:Checking exceptions
2023-11-23 12:58:58,148:INFO:Preloading libraries
2023-11-23 12:58:58,229:INFO:_display_container: 7
2023-11-23 12:58:58,229:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:58:58,230:INFO:create_model() successfully completed......................................
2023-11-23 12:58:58,279:INFO:Initializing create_model()
2023-11-23 12:58:58,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=rf, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:58:58,279:INFO:Checking exceptions
2023-11-23 12:58:58,285:INFO:Importing libraries
2023-11-23 12:58:58,285:INFO:Copying training dataset
2023-11-23 12:58:58,289:INFO:Defining folds
2023-11-23 12:58:58,289:INFO:Declaring metric variables
2023-11-23 12:58:58,291:INFO:Importing untrained model
2023-11-23 12:58:58,293:INFO:Random Forest Regressor Imported successfully
2023-11-23 12:58:58,295:INFO:Cross validation set to False
2023-11-23 12:58:58,295:INFO:Fitting Model
2023-11-23 12:58:58,752:INFO:Initializing predict_model()
2023-11-23 12:58:58,752:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x17fbe9af0>)
2023-11-23 12:58:58,752:INFO:Checking exceptions
2023-11-23 12:58:58,752:INFO:Preloading libraries
2023-11-23 12:58:58,838:INFO:_display_container: 8
2023-11-23 12:58:58,838:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:58:58,838:INFO:create_model() successfully completed......................................
2023-11-23 12:58:58,912:INFO:Initializing create_model()
2023-11-23 12:58:58,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:58:58,912:INFO:Checking exceptions
2023-11-23 12:58:58,934:INFO:Importing libraries
2023-11-23 12:58:58,935:INFO:Copying training dataset
2023-11-23 12:58:58,939:INFO:Defining folds
2023-11-23 12:58:58,939:INFO:Declaring metric variables
2023-11-23 12:58:58,941:INFO:Importing untrained model
2023-11-23 12:58:58,942:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 12:58:58,945:INFO:Starting cross validation
2023-11-23 12:58:58,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:59:01,396:INFO:Calculating mean and std
2023-11-23 12:59:01,396:INFO:Creating metrics dataframe
2023-11-23 12:59:01,399:INFO:Finalizing model
2023-11-23 12:59:01,411:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 12:59:01,412:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000202 seconds.
2023-11-23 12:59:01,412:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 12:59:01,412:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 12:59:01,412:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 12:59:01,412:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 12:59:01,412:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 12:59:01,738:INFO:Uploading results into container
2023-11-23 12:59:01,739:INFO:Uploading model into container now
2023-11-23 12:59:01,744:INFO:_master_model_container: 25
2023-11-23 12:59:01,744:INFO:_display_container: 9
2023-11-23 12:59:01,744:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:59:01,744:INFO:create_model() successfully completed......................................
2023-11-23 12:59:01,797:INFO:Initializing create_model()
2023-11-23 12:59:01,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 12:59:01,797:INFO:Checking exceptions
2023-11-23 12:59:01,803:INFO:Importing libraries
2023-11-23 12:59:01,803:INFO:Copying training dataset
2023-11-23 12:59:01,807:INFO:Defining folds
2023-11-23 12:59:01,807:INFO:Declaring metric variables
2023-11-23 12:59:01,809:INFO:Importing untrained model
2023-11-23 12:59:01,810:INFO:Random Forest Regressor Imported successfully
2023-11-23 12:59:01,826:INFO:Starting cross validation
2023-11-23 12:59:01,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 12:59:05,061:INFO:Calculating mean and std
2023-11-23 12:59:05,062:INFO:Creating metrics dataframe
2023-11-23 12:59:05,065:INFO:Finalizing model
2023-11-23 12:59:05,471:INFO:Uploading results into container
2023-11-23 12:59:05,471:INFO:Uploading model into container now
2023-11-23 12:59:05,478:INFO:_master_model_container: 26
2023-11-23 12:59:05,478:INFO:_display_container: 10
2023-11-23 12:59:05,478:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 12:59:05,478:INFO:create_model() successfully completed......................................
2023-11-23 12:59:05,552:INFO:Initializing predict_model()
2023-11-23 12:59:05,553:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x283d04550>)
2023-11-23 12:59:05,553:INFO:Checking exceptions
2023-11-23 12:59:05,553:INFO:Preloading libraries
2023-11-23 12:59:05,648:INFO:Initializing predict_model()
2023-11-23 12:59:05,648:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,
                      min_samples_split=10, n_estimators=150, n_jobs=-1,
                      random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x281a74ee0>)
2023-11-23 12:59:05,648:INFO:Checking exceptions
2023-11-23 12:59:05,648:INFO:Preloading libraries
2023-11-23 13:18:17,207:INFO:Initializing ensemble_model()
2023-11-23 13:18:17,209:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-11-23 13:18:17,209:INFO:Checking exceptions
2023-11-23 13:18:17,259:INFO:Importing libraries
2023-11-23 13:18:17,259:INFO:Copying training dataset
2023-11-23 13:18:17,259:INFO:Checking base model
2023-11-23 13:18:17,260:INFO:Base model : Light Gradient Boosting Machine
2023-11-23 13:18:17,263:INFO:Importing untrained ensembler
2023-11-23 13:18:17,263:INFO:Ensemble method set to Bagging
2023-11-23 13:18:17,263:INFO:SubProcess create_model() called ==================================
2023-11-23 13:18:17,264:INFO:Initializing create_model()
2023-11-23 13:18:17,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=BaggingRegressor(estimator=LGBMRegressor(boosting_type='dart',
                                         colsample_bytree=0.9, max_bin=455,
                                         min_child_samples=30, n_estimators=200,
                                         n_jobs=-1, num_leaves=75,
                                         random_state=123, reg_alpha=1,
                                         reg_lambda=1, subsample=0.9),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17ee58070>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 13:18:17,264:INFO:Checking exceptions
2023-11-23 13:18:17,264:INFO:Importing libraries
2023-11-23 13:18:17,264:INFO:Copying training dataset
2023-11-23 13:18:17,267:INFO:Defining folds
2023-11-23 13:18:17,267:INFO:Declaring metric variables
2023-11-23 13:18:17,269:INFO:Importing untrained model
2023-11-23 13:18:17,269:INFO:Declaring custom model
2023-11-23 13:18:17,271:INFO:Bagging Regressor Imported successfully
2023-11-23 13:18:17,278:INFO:Starting cross validation
2023-11-23 13:18:17,281:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 13:18:19,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001078 seconds.
2023-11-23 13:18:19,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:19,186:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:18:19,186:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:19,187:INFO:[LightGBM] [Info] Start training from score 186943.732731
2023-11-23 13:18:19,189:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002860 seconds.
2023-11-23 13:18:19,189:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:19,189:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 13:18:19,190:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:18:19,190:INFO:[LightGBM] [Info] Start training from score 188647.354053
2023-11-23 13:18:19,195:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001378 seconds.
2023-11-23 13:18:19,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:19,196:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 13:18:19,196:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:19,197:INFO:[LightGBM] [Info] Start training from score 186542.179299
2023-11-23 13:18:19,209:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003675 seconds.
2023-11-23 13:18:19,209:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:19,209:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:18:19,209:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:19,211:INFO:[LightGBM] [Info] Start training from score 186937.560151
2023-11-23 13:18:19,211:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004454 seconds.
2023-11-23 13:18:19,211:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:19,211:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:18:19,212:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:19,213:INFO:[LightGBM] [Info] Start training from score 186954.755196
2023-11-23 13:18:19,214:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002116 seconds.
2023-11-23 13:18:19,214:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:19,214:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:18:19,215:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001382 seconds.
2023-11-23 13:18:19,215:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:19,216:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:19,216:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:18:19,217:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:19,217:INFO:[LightGBM] [Info] Start training from score 186542.557002
2023-11-23 13:18:19,217:INFO:[LightGBM] [Info] Start training from score 185759.479320
2023-11-23 13:18:19,227:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001556 seconds.
2023-11-23 13:18:19,227:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 13:18:19,227:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 13:18:19,228:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:18:19,228:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:18:19,228:INFO:[LightGBM] [Info] Start training from score 188615.497690
2023-11-23 13:18:19,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:19,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:20,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:21,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:21,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:21,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:22,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:22,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:22,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:22,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:22,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:22,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:22,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:22,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:22,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:23,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:23,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:23,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:23,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:23,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:23,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:23,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:23,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:24,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:25,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:26,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:26,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:26,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:26,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:26,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:26,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:27,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:27,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:27,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:27,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:28,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:28,835:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001307 seconds.
2023-11-23 13:18:28,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:28,836:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 13:18:28,836:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:28,836:INFO:[LightGBM] [Info] Start training from score 188171.341381
2023-11-23 13:18:28,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008370 seconds.
2023-11-23 13:18:28,944:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:28,945:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:18:28,972:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:28,973:INFO:[LightGBM] [Info] Start training from score 187626.327735
2023-11-23 13:18:29,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:29,215:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001168 seconds.
2023-11-23 13:18:29,215:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:29,215:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 13:18:29,215:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:18:29,216:INFO:[LightGBM] [Info] Start training from score 186109.113398
2023-11-23 13:18:29,452:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001265 seconds.
2023-11-23 13:18:29,452:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:29,452:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:18:29,452:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:29,452:INFO:[LightGBM] [Info] Start training from score 187749.422423
2023-11-23 13:18:29,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:29,625:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001208 seconds.
2023-11-23 13:18:29,625:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:29,625:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:18:29,625:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:29,625:INFO:[LightGBM] [Info] Start training from score 187250.556162
2023-11-23 13:18:29,645:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009824 seconds.
2023-11-23 13:18:29,645:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:29,645:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:18:29,645:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:29,649:INFO:[LightGBM] [Info] Start training from score 186602.792148
2023-11-23 13:18:29,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:29,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:29,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:29,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:29,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:30,406:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001323 seconds.
2023-11-23 13:18:30,406:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:30,406:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:18:30,406:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:30,407:INFO:[LightGBM] [Info] Start training from score 187040.394709
2023-11-23 13:18:30,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:30,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:30,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:30,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:31,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:31,287:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001529 seconds.
2023-11-23 13:18:31,287:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:31,287:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:18:31,287:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:18:31,288:INFO:[LightGBM] [Info] Start training from score 186275.892062
2023-11-23 13:18:31,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:31,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:33,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:34,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:34,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:34,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:34,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:34,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:35,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:36,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:37,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:37,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:38,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001351 seconds.
2023-11-23 13:18:38,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:38,853:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:18:38,853:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:38,854:INFO:[LightGBM] [Info] Start training from score 186562.607390
2023-11-23 13:18:39,067:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002388 seconds.
2023-11-23 13:18:39,067:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:39,068:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 13:18:39,069:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:18:39,072:INFO:[LightGBM] [Info] Start training from score 186864.804704
2023-11-23 13:18:39,792:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001449 seconds.
2023-11-23 13:18:39,792:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:39,793:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:18:39,793:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:39,794:INFO:[LightGBM] [Info] Start training from score 188293.386311
2023-11-23 13:18:39,825:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001329 seconds.
2023-11-23 13:18:39,825:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:39,825:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 13:18:39,826:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:39,826:INFO:[LightGBM] [Info] Start training from score 187342.892925
2023-11-23 13:18:40,091:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001016 seconds.
2023-11-23 13:18:40,091:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:40,091:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:18:40,091:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:40,091:INFO:[LightGBM] [Info] Start training from score 187796.661348
2023-11-23 13:18:40,509:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001301 seconds.
2023-11-23 13:18:40,509:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:40,509:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:18:40,509:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:40,510:INFO:[LightGBM] [Info] Start training from score 187667.499265
2023-11-23 13:18:40,619:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001734 seconds.
2023-11-23 13:18:40,619:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:40,619:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:18:40,619:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:40,620:INFO:[LightGBM] [Info] Start training from score 187437.770313
2023-11-23 13:18:41,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003362 seconds.
2023-11-23 13:18:41,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:41,115:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:18:41,116:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:18:41,117:INFO:[LightGBM] [Info] Start training from score 187290.760185
2023-11-23 13:18:41,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:41,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:41,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:41,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:42,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:42,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:42,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:42,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:42,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:42,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:43,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:44,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:45,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:46,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:47,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:47,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:47,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:47,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:47,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:47,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:47,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:48,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:48,140:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012091 seconds.
2023-11-23 13:18:48,141:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:48,141:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 13:18:48,143:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:18:48,146:INFO:[LightGBM] [Info] Start training from score 187090.801764
2023-11-23 13:18:48,287:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000850 seconds.
2023-11-23 13:18:48,287:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:48,288:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:18:48,288:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:48,288:INFO:[LightGBM] [Info] Start training from score 189029.497796
2023-11-23 13:18:48,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:48,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:48,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:48,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:48,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:48,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:48,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:49,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:49,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:49,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:49,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:49,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:49,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000835 seconds.
2023-11-23 13:18:49,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:49,852:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 13:18:49,852:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:49,853:INFO:[LightGBM] [Info] Start training from score 189646.651060
2023-11-23 13:18:49,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:50,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003133 seconds.
2023-11-23 13:18:50,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:50,090:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:18:50,090:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:50,090:INFO:[LightGBM] [Info] Start training from score 189844.551333
2023-11-23 13:18:50,112:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001744 seconds.
2023-11-23 13:18:50,113:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:50,113:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:18:50,113:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:18:50,114:INFO:[LightGBM] [Info] Start training from score 185890.528769
2023-11-23 13:18:50,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:50,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:50,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:50,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:50,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000695 seconds.
2023-11-23 13:18:50,325:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:50,325:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:18:50,325:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:50,325:INFO:[LightGBM] [Info] Start training from score 189705.101407
2023-11-23 13:18:50,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001350 seconds.
2023-11-23 13:18:50,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:50,379:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:18:50,380:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:50,380:INFO:[LightGBM] [Info] Start training from score 189993.973966
2023-11-23 13:18:50,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:50,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2023-11-23 13:18:50,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:50,728:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:18:50,728:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:50,728:INFO:[LightGBM] [Info] Start training from score 190168.066135
2023-11-23 13:18:50,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:50,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:50,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:51,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:51,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:51,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:51,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:51,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:51,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:51,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:51,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:52,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:52,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:52,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:52,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:52,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:52,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:52,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:52,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:52,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:52,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:53,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:53,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:53,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:53,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:53,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:53,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:53,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:53,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:54,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:54,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:54,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:55,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:55,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:55,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:55,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:55,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:55,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:56,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:56,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:56,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:56,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:56,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:56,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:56,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:56,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:57,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:57,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:57,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:57,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:57,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009643 seconds.
2023-11-23 13:18:57,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:57,365:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 13:18:57,366:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:18:57,371:INFO:[LightGBM] [Info] Start training from score 186445.001680
2023-11-23 13:18:57,426:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000781 seconds.
2023-11-23 13:18:57,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:57,426:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:18:57,426:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:57,426:INFO:[LightGBM] [Info] Start training from score 187165.315557
2023-11-23 13:18:57,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:57,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:57,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:57,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:58,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:58,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:58,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:58,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:58,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:58,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:58,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:58,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:59,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:59,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:59,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:59,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:59,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:59,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:18:59,413:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000631 seconds.
2023-11-23 13:18:59,413:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:18:59,413:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:18:59,413:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:18:59,413:INFO:[LightGBM] [Info] Start training from score 187318.790468
2023-11-23 13:18:59,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:00,011:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001316 seconds.
2023-11-23 13:19:00,011:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:00,012:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 13:19:00,012:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:00,012:INFO:[LightGBM] [Info] Start training from score 188483.497586
2023-11-23 13:19:00,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:00,318:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000769 seconds.
2023-11-23 13:19:00,318:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:00,318:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:00,318:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:00,318:INFO:[LightGBM] [Info] Start training from score 188484.379383
2023-11-23 13:19:00,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:00,594:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001976 seconds.
2023-11-23 13:19:00,594:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:00,594:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:00,595:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:00,595:INFO:[LightGBM] [Info] Start training from score 186086.580848
2023-11-23 13:19:00,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001563 seconds.
2023-11-23 13:19:00,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:00,649:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:00,649:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:00,650:INFO:[LightGBM] [Info] Start training from score 187961.914760
2023-11-23 13:19:00,654:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000557 seconds.
2023-11-23 13:19:00,654:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:00,654:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:00,655:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:00,655:INFO:[LightGBM] [Info] Start training from score 189021.414865
2023-11-23 13:19:00,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:00,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:00,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:00,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:00,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:01,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:02,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:02,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:02,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:02,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:02,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:02,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:02,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:03,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:03,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:03,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:03,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:03,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:04,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:04,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:04,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:07,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001978 seconds.
2023-11-23 13:19:07,065:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:07,065:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 13:19:07,065:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:07,066:INFO:[LightGBM] [Info] Start training from score 186411.675346
2023-11-23 13:19:07,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:07,602:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000807 seconds.
2023-11-23 13:19:07,602:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:07,602:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:07,602:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:07,603:INFO:[LightGBM] [Info] Start training from score 185677.681923
2023-11-23 13:19:07,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:08,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:08,424:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000542 seconds.
2023-11-23 13:19:08,424:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:08,424:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:08,424:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:08,425:INFO:[LightGBM] [Info] Start training from score 187462.670166
2023-11-23 13:19:08,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:09,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:09,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:09,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:10,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:10,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:10,154:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000795 seconds.
2023-11-23 13:19:10,155:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:10,155:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 13:19:10,155:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:10,155:INFO:[LightGBM] [Info] Start training from score 187774.301701
2023-11-23 13:19:10,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:10,555:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021772 seconds.
2023-11-23 13:19:10,555:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 13:19:10,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 13:19:10,558:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:10,563:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:10,579:INFO:[LightGBM] [Info] Start training from score 186335.439429
2023-11-23 13:19:10,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:10,740:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004622 seconds.
2023-11-23 13:19:10,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:10,740:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:10,742:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:10,743:INFO:[LightGBM] [Info] Start training from score 186696.409406
2023-11-23 13:19:10,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:10,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:10,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:11,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:11,089:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001330 seconds.
2023-11-23 13:19:11,089:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:11,089:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:11,089:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:11,090:INFO:[LightGBM] [Info] Start training from score 187081.419064
2023-11-23 13:19:11,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:11,203:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001306 seconds.
2023-11-23 13:19:11,203:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:11,203:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:11,203:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:11,204:INFO:[LightGBM] [Info] Start training from score 185682.002940
2023-11-23 13:19:11,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:11,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:11,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:11,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:11,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:11,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:12,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:12,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:12,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:12,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:12,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:12,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:12,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:13,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:13,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:13,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:13,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:13,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:13,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:13,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:14,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:14,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:14,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:14,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:14,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:14,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:14,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:14,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:15,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:15,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:16,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:16,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:16,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:16,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:17,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:17,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:17,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:17,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:17,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:17,786:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001160 seconds.
2023-11-23 13:19:17,786:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:17,786:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 13:19:17,786:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:17,786:INFO:[LightGBM] [Info] Start training from score 182740.023940
2023-11-23 13:19:18,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:18,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.
2023-11-23 13:19:18,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 13:19:18,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 13:19:18,031:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:18,031:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:18,031:INFO:[LightGBM] [Info] Start training from score 186715.305270
2023-11-23 13:19:18,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:18,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:18,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:18,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:18,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:19,138:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001345 seconds.
2023-11-23 13:19:19,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:19,139:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:19,139:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:19,140:INFO:[LightGBM] [Info] Start training from score 186312.638673
2023-11-23 13:19:19,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:19,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:19,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:19,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:19,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:19,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003474 seconds.
2023-11-23 13:19:19,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 13:19:19,980:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 13:19:19,980:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 13:19:19,980:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:19,983:INFO:[LightGBM] [Info] Start training from score 186756.224858
2023-11-23 13:19:20,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:20,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:20,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:20,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:20,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:20,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:20,846:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006885 seconds.
2023-11-23 13:19:20,846:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:20,846:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:20,846:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:20,848:INFO:[LightGBM] [Info] Start training from score 185878.206592
2023-11-23 13:19:20,864:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004577 seconds.
2023-11-23 13:19:20,864:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:20,864:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:20,864:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:20,867:INFO:[LightGBM] [Info] Start training from score 186812.344531
2023-11-23 13:19:20,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:21,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:21,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:21,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:21,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:21,441:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002498 seconds.
2023-11-23 13:19:21,441:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:21,441:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:21,441:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:21,442:INFO:[LightGBM] [Info] Start training from score 183995.609828
2023-11-23 13:19:21,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:21,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:21,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:21,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:22,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:22,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:22,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:22,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:22,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:22,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:22,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:22,620:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002333 seconds.
2023-11-23 13:19:22,621:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:22,621:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:22,621:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:22,623:INFO:[LightGBM] [Info] Start training from score 185975.204073
2023-11-23 13:19:22,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:22,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:22,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:23,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:23,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:23,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:23,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:23,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:23,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:23,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:23,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:23,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:24,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:24,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:24,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:24,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:24,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:24,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:25,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:25,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:25,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:25,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:25,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:25,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:25,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:26,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:26,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:26,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:27,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:27,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:27,521:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000660 seconds.
2023-11-23 13:19:27,521:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:27,521:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 13:19:27,521:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:27,521:INFO:[LightGBM] [Info] Start training from score 186709.743805
2023-11-23 13:19:27,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:27,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:27,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:28,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:28,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:28,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:28,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:28,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:28,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:28,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:28,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:29,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:29,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:29,576:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001099 seconds.
2023-11-23 13:19:29,576:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:29,576:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:29,577:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:29,577:INFO:[LightGBM] [Info] Start training from score 188004.345371
2023-11-23 13:19:29,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:29,710:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000910 seconds.
2023-11-23 13:19:29,710:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:29,710:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:29,710:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:29,711:INFO:[LightGBM] [Info] Start training from score 184171.488348
2023-11-23 13:19:30,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:30,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:30,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:30,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:30,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:30,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:30,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:30,956:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001719 seconds.
2023-11-23 13:19:30,956:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:30,956:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:30,957:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:30,958:INFO:[LightGBM] [Info] Start training from score 186583.788324
2023-11-23 13:19:31,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:31,292:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000753 seconds.
2023-11-23 13:19:31,292:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:31,292:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:31,293:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:31,293:INFO:[LightGBM] [Info] Start training from score 185246.146966
2023-11-23 13:19:31,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:31,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:31,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:31,722:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001546 seconds.
2023-11-23 13:19:31,722:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:31,723:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:31,723:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:31,724:INFO:[LightGBM] [Info] Start training from score 185224.858283
2023-11-23 13:19:31,795:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002085 seconds.
2023-11-23 13:19:31,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:31,795:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 13:19:31,796:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:31,796:INFO:[LightGBM] [Info] Start training from score 186966.680244
2023-11-23 13:19:32,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:32,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:33,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:34,302:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001378 seconds.
2023-11-23 13:19:34,302:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:34,302:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:34,303:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:34,303:INFO:[LightGBM] [Info] Start training from score 185689.921898
2023-11-23 13:19:34,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:34,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:34,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:34,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:34,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:35,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:35,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:35,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:35,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:35,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:35,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:36,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:36,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:36,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:36,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:36,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:37,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:37,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:37,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:37,583:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001106 seconds.
2023-11-23 13:19:37,583:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:37,583:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 13:19:37,583:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:37,584:INFO:[LightGBM] [Info] Start training from score 186095.716086
2023-11-23 13:19:37,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:37,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:38,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:38,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:38,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:38,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:38,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,332:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000677 seconds.
2023-11-23 13:19:39,332:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:39,332:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:39,332:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:39,332:INFO:[LightGBM] [Info] Start training from score 185542.661768
2023-11-23 13:19:39,572:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000667 seconds.
2023-11-23 13:19:39,572:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:39,572:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:39,573:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:39,573:INFO:[LightGBM] [Info] Start training from score 185893.931556
2023-11-23 13:19:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:40,368:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002219 seconds.
2023-11-23 13:19:40,368:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:40,368:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:40,368:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:40,369:INFO:[LightGBM] [Info] Start training from score 186686.245275
2023-11-23 13:19:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:40,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:41,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:41,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:41,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:41,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:41,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:41,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:41,859:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.
2023-11-23 13:19:41,859:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:41,859:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 13:19:41,859:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:41,859:INFO:[LightGBM] [Info] Start training from score 185418.286584
2023-11-23 13:19:41,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:41,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:41,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:42,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:42,046:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001105 seconds.
2023-11-23 13:19:42,046:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:42,046:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:42,046:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:42,047:INFO:[LightGBM] [Info] Start training from score 184998.046819
2023-11-23 13:19:42,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:42,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:42,389:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000970 seconds.
2023-11-23 13:19:42,389:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:42,389:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:42,389:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:42,390:INFO:[LightGBM] [Info] Start training from score 186628.867940
2023-11-23 13:19:42,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:42,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:43,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:44,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:44,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:44,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:44,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000772 seconds.
2023-11-23 13:19:44,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:44,397:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:44,397:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:44,397:INFO:[LightGBM] [Info] Start training from score 185549.547974
2023-11-23 13:19:44,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:44,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:44,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:44,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:45,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:46,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:46,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:46,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:46,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:47,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:47,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:47,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:47,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:47,802:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001185 seconds.
2023-11-23 13:19:47,802:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:47,802:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 13:19:47,803:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:47,803:INFO:[LightGBM] [Info] Start training from score 186764.363293
2023-11-23 13:19:48,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:48,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:48,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:48,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:48,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:48,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:49,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:49,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:49,225:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000957 seconds.
2023-11-23 13:19:49,225:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:49,225:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:49,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:49,351:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:49,352:INFO:[LightGBM] [Info] Start training from score 184617.362587
2023-11-23 13:19:49,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:49,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:49,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:49,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:49,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:49,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:49,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:50,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:50,131:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.
2023-11-23 13:19:50,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:50,131:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:50,131:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 13:19:50,132:INFO:[LightGBM] [Info] Start training from score 187333.976900
2023-11-23 13:19:50,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:50,604:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012819 seconds.
2023-11-23 13:19:50,604:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:50,605:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:50,606:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:50,608:INFO:[LightGBM] [Info] Start training from score 186905.122822
2023-11-23 13:19:50,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:50,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:51,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:51,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:51,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:51,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:51,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:51,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:51,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:52,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:52,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:52,173:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001159 seconds.
2023-11-23 13:19:52,173:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:52,173:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 13:19:52,174:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:52,174:INFO:[LightGBM] [Info] Start training from score 184717.278606
2023-11-23 13:19:52,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:52,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:52,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:52,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001032 seconds.
2023-11-23 13:19:52,491:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:52,491:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 13:19:52,491:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:52,491:INFO:[LightGBM] [Info] Start training from score 185476.401008
2023-11-23 13:19:52,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:52,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:52,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:52,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:52,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:53,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:53,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:53,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:53,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:53,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:53,478:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000610 seconds.
2023-11-23 13:19:53,478:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:53,478:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 13:19:53,478:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:53,479:INFO:[LightGBM] [Info] Start training from score 185493.596473
2023-11-23 13:19:53,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:53,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:54,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:54,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:54,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:54,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:54,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:54,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:54,704:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000529 seconds.
2023-11-23 13:19:54,704:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:54,704:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 13:19:54,704:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:54,704:INFO:[LightGBM] [Info] Start training from score 185525.130800
2023-11-23 13:19:54,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:54,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:55,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:56,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:56,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:56,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:56,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:56,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:56,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:56,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:56,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:56,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:57,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:57,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:57,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:57,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:57,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:57,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:58,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:58,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:58,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:58,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.
2023-11-23 13:19:58,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:19:58,517:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 13:19:58,517:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:19:58,517:INFO:[LightGBM] [Info] Start training from score 186788.032752
2023-11-23 13:19:58,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:59,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:59,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:59,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:59,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:59,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:19:59,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:00,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:00,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:00,876:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023849 seconds.
2023-11-23 13:20:00,876:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:00,876:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 13:20:00,877:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:00,880:INFO:[LightGBM] [Info] Start training from score 186623.157674
2023-11-23 13:20:01,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:01,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:01,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:01,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:02,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:02,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:02,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:02,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:03,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:03,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:03,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:03,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:03,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:03,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:03,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:03,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:03,961:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
2023-11-23 13:20:03,961:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:03,961:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 13:20:03,961:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:03,962:INFO:[LightGBM] [Info] Start training from score 188492.924417
2023-11-23 13:20:03,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:04,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:04,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:04,457:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2023-11-23 13:20:04,458:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:04,458:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 13:20:04,458:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:04,458:INFO:[LightGBM] [Info] Start training from score 188142.955910
2023-11-23 13:20:04,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:04,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:04,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:04,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:05,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:05,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:05,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:05,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:05,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:05,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:05,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:05,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:06,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:06,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:06,195:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2023-11-23 13:20:06,195:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:06,195:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 13:20:06,195:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:06,195:INFO:[LightGBM] [Info] Start training from score 185938.609910
2023-11-23 13:20:06,852:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000587 seconds.
2023-11-23 13:20:06,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:06,853:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 13:20:06,853:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:06,853:INFO:[LightGBM] [Info] Start training from score 186240.058577
2023-11-23 13:20:06,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:06,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:06,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:06,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:07,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:08,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:08,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:08,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:08,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:08,232:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2023-11-23 13:20:08,232:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:08,232:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 13:20:08,232:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:08,232:INFO:[LightGBM] [Info] Start training from score 188506.193156
2023-11-23 13:20:08,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:08,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:08,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:08,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:08,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:08,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000284 seconds.
2023-11-23 13:20:08,808:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:08,808:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 13:20:08,808:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:08,808:INFO:[LightGBM] [Info] Start training from score 187537.601932
2023-11-23 13:20:08,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:09,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:09,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:09,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:09,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:09,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:09,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:09,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:09,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:10,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:10,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:10,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:10,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:10,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:10,462:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000914 seconds.
2023-11-23 13:20:10,462:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:10,462:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 13:20:10,462:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:10,462:INFO:[LightGBM] [Info] Start training from score 187237.559941
2023-11-23 13:20:10,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:10,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:10,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:10,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:10,962:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.
2023-11-23 13:20:10,962:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:10,962:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 13:20:10,962:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:10,962:INFO:[LightGBM] [Info] Start training from score 186947.448667
2023-11-23 13:20:11,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:11,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:11,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:11,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:11,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:11,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:12,790:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
2023-11-23 13:20:12,790:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:12,790:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 13:20:12,790:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:12,790:INFO:[LightGBM] [Info] Start training from score 185794.310099
2023-11-23 13:20:12,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:13,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2023-11-23 13:20:13,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:13,030:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 13:20:13,030:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:13,030:INFO:[LightGBM] [Info] Start training from score 185167.037371
2023-11-23 13:20:13,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:13,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:13,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:13,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:13,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:13,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:13,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:13,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:13,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:13,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:14,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:14,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:14,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:14,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:14,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2023-11-23 13:20:14,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:14,904:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 13:20:14,904:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:14,904:INFO:[LightGBM] [Info] Start training from score 186658.786269
2023-11-23 13:20:15,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,265:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.
2023-11-23 13:20:15,265:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:15,265:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 13:20:15,265:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:15,265:INFO:[LightGBM] [Info] Start training from score 186813.100777
2023-11-23 13:20:15,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:15,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:16,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:16,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:16,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:16,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:16,991:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.
2023-11-23 13:20:16,991:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:16,991:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 13:20:16,991:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:16,991:INFO:[LightGBM] [Info] Start training from score 187728.867730
2023-11-23 13:20:17,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:17,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:17,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:17,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:17,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:17,476:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.
2023-11-23 13:20:17,476:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:17,476:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 13:20:17,477:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:17,477:INFO:[LightGBM] [Info] Start training from score 187418.685072
2023-11-23 13:20:17,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:17,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:17,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:17,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:18,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:18,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:18,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:18,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:18,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:18,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:19,025:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.
2023-11-23 13:20:19,025:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:19,025:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 13:20:19,025:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:19,026:INFO:[LightGBM] [Info] Start training from score 184796.346420
2023-11-23 13:20:19,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:19,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:19,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:19,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:19,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:19,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:19,716:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.
2023-11-23 13:20:19,716:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 13:20:19,716:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 13:20:19,716:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 13:20:19,716:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:19,716:INFO:[LightGBM] [Info] Start training from score 184808.439639
2023-11-23 13:20:19,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:19,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:20,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:20,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:20,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:20,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:21,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:21,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:21,215:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
2023-11-23 13:20:21,215:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:21,215:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 13:20:21,215:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:21,216:INFO:[LightGBM] [Info] Start training from score 184754.146126
2023-11-23 13:20:21,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:21,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:21,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:21,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:21,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:22,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:22,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:22,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:22,162:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.
2023-11-23 13:20:22,162:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:22,162:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 13:20:22,163:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 13:20:22,163:INFO:[LightGBM] [Info] Start training from score 184010.833088
2023-11-23 13:20:22,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:22,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:22,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:22,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:22,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:22,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:22,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:23,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:23,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:23,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:23,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:23,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:24,165:INFO:Calculating mean and std
2023-11-23 13:20:24,167:INFO:Creating metrics dataframe
2023-11-23 13:20:24,172:INFO:Finalizing model
2023-11-23 13:20:24,195:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.
2023-11-23 13:20:24,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:24,196:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 13:20:24,196:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 13:20:24,197:INFO:[LightGBM] [Info] Start training from score 187165.211640
2023-11-23 13:20:24,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:24,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:24,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:24,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:24,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:24,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:25,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:25,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:25,746:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.
2023-11-23 13:20:25,746:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:25,746:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 13:20:25,746:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 13:20:25,747:INFO:[LightGBM] [Info] Start training from score 187540.343726
2023-11-23 13:20:25,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:25,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:26,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:26,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:26,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:26,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:26,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:27,274:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2023-11-23 13:20:27,274:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:27,274:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 13:20:27,274:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 13:20:27,274:INFO:[LightGBM] [Info] Start training from score 186741.647581
2023-11-23 13:20:27,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:27,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:27,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:27,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:27,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:27,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:27,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:28,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:28,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:28,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:28,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:28,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:28,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:28,656:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2023-11-23 13:20:28,656:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:28,656:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 13:20:28,656:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 13:20:28,656:INFO:[LightGBM] [Info] Start training from score 187184.258881
2023-11-23 13:20:28,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:28,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:28,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:29,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:29,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:29,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:29,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:29,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:29,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:30,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2023-11-23 13:20:30,135:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:30,135:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 13:20:30,135:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 13:20:30,135:INFO:[LightGBM] [Info] Start training from score 187453.004157
2023-11-23 13:20:30,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:30,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:30,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:30,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:31,573:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2023-11-23 13:20:31,573:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:31,573:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 13:20:31,573:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 13:20:31,573:INFO:[LightGBM] [Info] Start training from score 185531.915911
2023-11-23 13:20:31,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:31,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:31,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:31,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:32,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:32,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:32,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:32,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:33,077:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2023-11-23 13:20:33,077:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:33,077:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 13:20:33,077:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 13:20:33,077:INFO:[LightGBM] [Info] Start training from score 188230.215231
2023-11-23 13:20:33,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:33,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:33,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:33,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:33,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:33,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:34,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:34,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2023-11-23 13:20:34,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:34,558:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 13:20:34,558:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 13:20:34,558:INFO:[LightGBM] [Info] Start training from score 188013.699358
2023-11-23 13:20:34,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:34,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:35,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:35,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:35,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:35,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:35,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:36,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2023-11-23 13:20:36,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:36,030:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 13:20:36,031:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 13:20:36,031:INFO:[LightGBM] [Info] Start training from score 185829.534769
2023-11-23 13:20:36,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:36,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:36,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:36,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:37,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:37,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:37,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:37,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:37,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2023-11-23 13:20:37,534:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 13:20:37,534:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 13:20:37,534:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 13:20:37,534:INFO:[LightGBM] [Info] Start training from score 184763.775132
2023-11-23 13:20:37,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:37,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:37,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:38,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:38,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:38,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:38,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:38,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 13:20:39,004:INFO:Uploading results into container
2023-11-23 13:20:39,006:INFO:Uploading model into container now
2023-11-23 13:20:39,006:INFO:_master_model_container: 27
2023-11-23 13:20:39,006:INFO:_display_container: 13
2023-11-23 13:20:39,008:INFO:BaggingRegressor(estimator=LGBMRegressor(boosting_type='dart',
                                         colsample_bytree=0.9, max_bin=455,
                                         min_child_samples=30, n_estimators=200,
                                         n_jobs=-1, num_leaves=75,
                                         random_state=123, reg_alpha=1,
                                         reg_lambda=1, subsample=0.9),
                 random_state=123)
2023-11-23 13:20:39,008:INFO:create_model() successfully completed......................................
2023-11-23 13:20:39,100:INFO:SubProcess create_model() end ==================================
2023-11-23 13:20:39,106:INFO:_master_model_container: 27
2023-11-23 13:20:39,106:INFO:_display_container: 13
2023-11-23 13:20:39,107:INFO:BaggingRegressor(estimator=LGBMRegressor(boosting_type='dart',
                                         colsample_bytree=0.9, max_bin=455,
                                         min_child_samples=30, n_estimators=200,
                                         n_jobs=-1, num_leaves=75,
                                         random_state=123, reg_alpha=1,
                                         reg_lambda=1, subsample=0.9),
                 random_state=123)
2023-11-23 13:20:39,108:INFO:ensemble_model() successfully completed......................................
2023-11-23 13:20:39,161:INFO:Initializing ensemble_model()
2023-11-23 13:20:39,162:INFO:ensemble_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=RandomForestRegressor(bootstrap=False, max_features='log2', min_samples_leaf=2,
                      min_samples_split=10, n_estimators=150, n_jobs=-1,
                      random_state=123), method=Bagging, fold=None, n_estimators=10, round=4, choose_better=False, optimize=R2, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-11-23 13:20:39,162:INFO:Checking exceptions
2023-11-23 13:20:39,170:INFO:Importing libraries
2023-11-23 13:20:39,170:INFO:Copying training dataset
2023-11-23 13:20:39,170:INFO:Checking base model
2023-11-23 13:20:39,171:INFO:Base model : Random Forest Regressor
2023-11-23 13:20:39,175:INFO:Importing untrained ensembler
2023-11-23 13:20:39,175:INFO:Ensemble method set to Bagging
2023-11-23 13:20:39,175:INFO:SubProcess create_model() called ==================================
2023-11-23 13:20:39,176:INFO:Initializing create_model()
2023-11-23 13:20:39,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=BaggingRegressor(estimator=RandomForestRegressor(bootstrap=False,
                                                 max_features='log2',
                                                 min_samples_leaf=2,
                                                 min_samples_split=10,
                                                 n_estimators=150, n_jobs=-1,
                                                 random_state=123),
                 random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x2894d13a0>, model_only=True, return_train_score=False, kwargs={})
2023-11-23 13:20:39,177:INFO:Checking exceptions
2023-11-23 13:20:39,177:INFO:Importing libraries
2023-11-23 13:20:39,177:INFO:Copying training dataset
2023-11-23 13:20:39,181:INFO:Defining folds
2023-11-23 13:20:39,181:INFO:Declaring metric variables
2023-11-23 13:20:39,190:INFO:Importing untrained model
2023-11-23 13:20:39,190:INFO:Declaring custom model
2023-11-23 13:20:39,203:INFO:Bagging Regressor Imported successfully
2023-11-23 13:20:39,223:INFO:Starting cross validation
2023-11-23 13:20:39,224:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 13:20:52,304:INFO:Calculating mean and std
2023-11-23 13:20:52,306:INFO:Creating metrics dataframe
2023-11-23 13:20:52,312:INFO:Finalizing model
2023-11-23 13:20:54,148:INFO:Uploading results into container
2023-11-23 13:20:54,149:INFO:Uploading model into container now
2023-11-23 13:20:54,149:INFO:_master_model_container: 28
2023-11-23 13:20:54,149:INFO:_display_container: 14
2023-11-23 13:20:54,151:INFO:BaggingRegressor(estimator=RandomForestRegressor(bootstrap=False,
                                                 max_features='log2',
                                                 min_samples_leaf=2,
                                                 min_samples_split=10,
                                                 n_estimators=150, n_jobs=-1,
                                                 random_state=123),
                 random_state=123)
2023-11-23 13:20:54,151:INFO:create_model() successfully completed......................................
2023-11-23 13:20:54,259:INFO:SubProcess create_model() end ==================================
2023-11-23 13:20:54,264:INFO:_master_model_container: 28
2023-11-23 13:20:54,264:INFO:_display_container: 14
2023-11-23 13:20:54,265:INFO:BaggingRegressor(estimator=RandomForestRegressor(bootstrap=False,
                                                 max_features='log2',
                                                 min_samples_leaf=2,
                                                 min_samples_split=10,
                                                 n_estimators=150, n_jobs=-1,
                                                 random_state=123),
                 random_state=123)
2023-11-23 13:20:54,265:INFO:ensemble_model() successfully completed......................................
2023-11-23 14:14:18,907:INFO:Initializing finalize_model()
2023-11-23 14:14:18,907:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-23 14:14:18,909:INFO:Finalizing LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9)
2023-11-23 14:14:18,927:INFO:Initializing create_model()
2023-11-23 14:14:18,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=LGBMRegressor(boosting_type='dart', colsample_bytree=0.9, max_bin=455,
              min_child_samples=30, n_estimators=200, n_jobs=-1, num_leaves=75,
              random_state=123, reg_alpha=1, reg_lambda=1, subsample=0.9), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-11-23 14:14:18,927:INFO:Checking exceptions
2023-11-23 14:14:18,934:INFO:Importing libraries
2023-11-23 14:14:18,934:INFO:Copying training dataset
2023-11-23 14:14:18,936:INFO:Defining folds
2023-11-23 14:14:18,936:INFO:Declaring metric variables
2023-11-23 14:14:18,936:INFO:Importing untrained model
2023-11-23 14:14:18,936:INFO:Declaring custom model
2023-11-23 14:14:18,937:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 14:14:18,938:INFO:Cross validation set to False
2023-11-23 14:14:18,938:INFO:Fitting Model
2023-11-23 14:14:18,970:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:14:18,982:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001191 seconds.
2023-11-23 14:14:18,982:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:14:18,983:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:14:18,983:INFO:[LightGBM] [Info] Total Bins 3238
2023-11-23 14:14:18,984:INFO:[LightGBM] [Info] Number of data points in the train set: 7560, number of used features: 12
2023-11-23 14:14:18,984:INFO:[LightGBM] [Info] Start training from score 185379.933598
2023-11-23 14:14:19,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:14:19,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:14:19,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:14:19,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:14:19,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:14:19,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:14:19,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:14:19,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:14:20,940:INFO:Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))])
2023-11-23 14:14:20,940:INFO:create_model() successfully completed......................................
2023-11-23 14:14:21,019:INFO:_master_model_container: 28
2023-11-23 14:14:21,019:INFO:_display_container: 14
2023-11-23 14:14:21,042:INFO:Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))])
2023-11-23 14:14:21,042:INFO:finalize_model() successfully completed......................................
2023-11-23 14:15:29,050:INFO:Initializing plot_model()
2023-11-23 14:15:29,052:INFO:plot_model(plot=learning, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))]), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, system=True)
2023-11-23 14:15:29,052:INFO:Checking exceptions
2023-11-23 14:15:29,062:INFO:Preloading libraries
2023-11-23 14:15:29,094:INFO:Copying training dataset
2023-11-23 14:15:29,094:INFO:Plot type: learning
2023-11-23 14:15:29,151:INFO:Fitting Model
2023-11-23 14:15:30,377:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:30,378:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:30,379:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:30,380:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002188 seconds.
2023-11-23 14:15:30,380:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:30,380:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:15:30,380:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001800 seconds.
2023-11-23 14:15:30,380:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:30,380:INFO:[LightGBM] [Info] Number of data points in the train set: 3650, number of used features: 12
2023-11-23 14:15:30,380:INFO:[LightGBM] [Info] Total Bins 3226
2023-11-23 14:15:30,381:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:30,381:INFO:[LightGBM] [Info] Number of data points in the train set: 4021, number of used features: 12
2023-11-23 14:15:30,381:INFO:[LightGBM] [Info] Start training from score 185980.825168
2023-11-23 14:15:30,382:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:30,382:INFO:[LightGBM] [Info] Start training from score 185591.561096
2023-11-23 14:15:30,382:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:30,384:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003080 seconds.
2023-11-23 14:15:30,384:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:30,384:INFO:[LightGBM] [Info] Total Bins 3187
2023-11-23 14:15:30,385:INFO:[LightGBM] [Info] Number of data points in the train set: 2169, number of used features: 12
2023-11-23 14:15:30,385:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001371 seconds.
2023-11-23 14:15:30,385:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:30,385:INFO:[LightGBM] [Info] Total Bins 2988
2023-11-23 14:15:30,385:INFO:[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 12
2023-11-23 14:15:30,385:INFO:[LightGBM] [Info] Start training from score 185263.715537
2023-11-23 14:15:30,385:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002118 seconds.
2023-11-23 14:15:30,385:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:30,385:INFO:[LightGBM] [Info] Total Bins 3180
2023-11-23 14:15:30,386:INFO:[LightGBM] [Info] Number of data points in the train set: 1798, number of used features: 12
2023-11-23 14:15:30,386:INFO:[LightGBM] [Info] Start training from score 184449.018908
2023-11-23 14:15:30,387:INFO:[LightGBM] [Info] Start training from score 183759.565628
2023-11-23 14:15:30,388:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:30,406:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:30,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,481:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013184 seconds.
2023-11-23 14:15:30,481:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:30,481:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093562 seconds.
2023-11-23 14:15:30,481:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:30,482:INFO:[LightGBM] [Info] Total Bins 3206
2023-11-23 14:15:30,482:INFO:[LightGBM] [Info] Total Bins 3209
2023-11-23 14:15:30,482:INFO:[LightGBM] [Info] Number of data points in the train set: 2910, number of used features: 12
2023-11-23 14:15:30,482:INFO:[LightGBM] [Info] Number of data points in the train set: 3280, number of used features: 12
2023-11-23 14:15:30,482:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013858 seconds.
2023-11-23 14:15:30,482:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:30,482:INFO:[LightGBM] [Info] Total Bins 3190
2023-11-23 14:15:30,483:INFO:[LightGBM] [Info] Number of data points in the train set: 2539, number of used features: 12
2023-11-23 14:15:30,483:INFO:[LightGBM] [Info] Start training from score 185354.968902
2023-11-23 14:15:30,483:INFO:[LightGBM] [Info] Start training from score 185374.879038
2023-11-23 14:15:30,484:INFO:[LightGBM] [Info] Start training from score 185312.839307
2023-11-23 14:15:30,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:30,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:31,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,397:INFO:
2023-11-23 14:15:32,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,539:INFO:
2023-11-23 14:15:32,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:32,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:33,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,543:INFO:
2023-11-23 14:15:34,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:34,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,386:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:35,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,387:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.
2023-11-23 14:15:35,387:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:35,388:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:15:35,388:INFO:[LightGBM] [Info] Number of data points in the train set: 4391, number of used features: 12
2023-11-23 14:15:35,388:INFO:[LightGBM] [Info] Start training from score 186203.074015
2023-11-23 14:15:35,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:35,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:36,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,088:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:37,092:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002758 seconds.
2023-11-23 14:15:37,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:37,092:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:15:37,092:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:15:37,093:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:15:37,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,412:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:37,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,413:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.
2023-11-23 14:15:37,414:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:37,414:INFO:[LightGBM] [Info] Total Bins 2869
2023-11-23 14:15:37,415:INFO:[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 12
2023-11-23 14:15:37,417:INFO:[LightGBM] [Info] Start training from score 184380.531513
2023-11-23 14:15:37,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:38,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,760:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:39,761:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000575 seconds.
2023-11-23 14:15:39,761:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:39,762:INFO:[LightGBM] [Info] Total Bins 3178
2023-11-23 14:15:39,762:INFO:[LightGBM] [Info] Number of data points in the train set: 1798, number of used features: 12
2023-11-23 14:15:39,762:INFO:[LightGBM] [Info] Start training from score 183705.171858
2023-11-23 14:15:39,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:39,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,122:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:40,123:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001220 seconds.
2023-11-23 14:15:40,123:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:40,124:INFO:[LightGBM] [Info] Total Bins 3179
2023-11-23 14:15:40,124:INFO:[LightGBM] [Info] Number of data points in the train set: 2169, number of used features: 12
2023-11-23 14:15:40,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,125:INFO:[LightGBM] [Info] Start training from score 185218.625634
2023-11-23 14:15:40,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,785:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:40,790:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002897 seconds.
2023-11-23 14:15:40,790:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:40,790:INFO:[LightGBM] [Info] Total Bins 3187
2023-11-23 14:15:40,791:INFO:[LightGBM] [Info] Number of data points in the train set: 2539, number of used features: 12
2023-11-23 14:15:40,793:INFO:[LightGBM] [Info] Start training from score 185274.320205
2023-11-23 14:15:40,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,891:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009997 seconds.
2023-11-23 14:15:40,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:40,903:INFO:[LightGBM] [Info] Total Bins 3197
2023-11-23 14:15:40,904:INFO:[LightGBM] [Info] Number of data points in the train set: 2910, number of used features: 12
2023-11-23 14:15:40,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,914:INFO:[LightGBM] [Info] Start training from score 185341.270790
2023-11-23 14:15:40,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:40,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,034:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:41,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,041:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003473 seconds.
2023-11-23 14:15:41,041:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:41,041:INFO:[LightGBM] [Info] Total Bins 3198
2023-11-23 14:15:41,042:INFO:[LightGBM] [Info] Number of data points in the train set: 3280, number of used features: 12
2023-11-23 14:15:41,045:INFO:[LightGBM] [Info] Start training from score 185325.151829
2023-11-23 14:15:41,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:41,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,081:INFO:
2023-11-23 14:15:42,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,338:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:42,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000960 seconds.
2023-11-23 14:15:42,339:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:42,339:INFO:[LightGBM] [Info] Total Bins 3209
2023-11-23 14:15:42,340:INFO:[LightGBM] [Info] Number of data points in the train set: 3650, number of used features: 12
2023-11-23 14:15:42,340:INFO:[LightGBM] [Info] Start training from score 185564.766575
2023-11-23 14:15:42,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:42,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:43,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,009:INFO:
2023-11-23 14:15:44,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,140:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:44,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.
2023-11-23 14:15:44,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:44,142:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:15:44,142:INFO:[LightGBM] [Info] Number of data points in the train set: 4021, number of used features: 12
2023-11-23 14:15:44,143:INFO:[LightGBM] [Info] Start training from score 185956.502860
2023-11-23 14:15:44,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:44,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,868:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:45,871:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001496 seconds.
2023-11-23 14:15:45,871:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:45,871:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:15:45,871:INFO:[LightGBM] [Info] Number of data points in the train set: 4391, number of used features: 12
2023-11-23 14:15:45,872:INFO:[LightGBM] [Info] Start training from score 186180.801184
2023-11-23 14:15:45,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:45,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:46,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,266:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:47,268:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001549 seconds.
2023-11-23 14:15:47,268:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:47,268:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:15:47,268:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:15:47,269:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:15:47,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:47,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:48,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,020:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:49,022:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001040 seconds.
2023-11-23 14:15:49,022:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:49,022:INFO:[LightGBM] [Info] Total Bins 2871
2023-11-23 14:15:49,023:INFO:[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 12
2023-11-23 14:15:49,023:INFO:[LightGBM] [Info] Start training from score 186680.811625
2023-11-23 14:15:49,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,763:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:49,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,766:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002670 seconds.
2023-11-23 14:15:49,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:49,766:INFO:[LightGBM] [Info] Total Bins 3180
2023-11-23 14:15:49,766:INFO:[LightGBM] [Info] Number of data points in the train set: 1798, number of used features: 12
2023-11-23 14:15:49,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,767:INFO:[LightGBM] [Info] Start training from score 185473.525584
2023-11-23 14:15:49,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:49,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,359:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:50,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003894 seconds.
2023-11-23 14:15:50,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:50,366:INFO:[LightGBM] [Info] Total Bins 3184
2023-11-23 14:15:50,368:INFO:[LightGBM] [Info] Number of data points in the train set: 2169, number of used features: 12
2023-11-23 14:15:50,369:INFO:[LightGBM] [Info] Start training from score 186580.359152
2023-11-23 14:15:50,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,723:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:50,726:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001916 seconds.
2023-11-23 14:15:50,726:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:50,726:INFO:[LightGBM] [Info] Total Bins 3195
2023-11-23 14:15:50,726:INFO:[LightGBM] [Info] Number of data points in the train set: 2539, number of used features: 12
2023-11-23 14:15:50,727:INFO:[LightGBM] [Info] Start training from score 186512.287909
2023-11-23 14:15:50,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:50,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,820:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:51,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004274 seconds.
2023-11-23 14:15:51,826:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:51,827:INFO:[LightGBM] [Info] Total Bins 3205
2023-11-23 14:15:51,827:INFO:[LightGBM] [Info] Number of data points in the train set: 2910, number of used features: 12
2023-11-23 14:15:51,829:INFO:[LightGBM] [Info] Start training from score 186340.995876
2023-11-23 14:15:51,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:51,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,006:INFO:
2023-11-23 14:15:52,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,435:INFO:
2023-11-23 14:15:52,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:52,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,098:INFO:
2023-11-23 14:15:54,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,360:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004806 seconds.
2023-11-23 14:15:54,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:54,369:INFO:[LightGBM] [Info] Total Bins 3210
2023-11-23 14:15:54,369:INFO:[LightGBM] [Info] Number of data points in the train set: 3280, number of used features: 12
2023-11-23 14:15:54,371:INFO:[LightGBM] [Info] Start training from score 186271.493293
2023-11-23 14:15:54,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,404:INFO:
2023-11-23 14:15:54,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,534:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:54,535:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000943 seconds.
2023-11-23 14:15:54,535:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:54,535:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:15:54,536:INFO:[LightGBM] [Info] Number of data points in the train set: 3650, number of used features: 12
2023-11-23 14:15:54,536:INFO:[LightGBM] [Info] Start training from score 186401.698082
2023-11-23 14:15:54,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:54,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,041:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:55,043:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001282 seconds.
2023-11-23 14:15:55,043:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:55,043:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:15:55,043:INFO:[LightGBM] [Info] Number of data points in the train set: 4021, number of used features: 12
2023-11-23 14:15:55,043:INFO:[LightGBM] [Info] Start training from score 186749.539418
2023-11-23 14:15:55,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,848:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:55,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,915:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055636 seconds.
2023-11-23 14:15:55,915:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:55,923:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:15:55,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:55,980:INFO:[LightGBM] [Info] Number of data points in the train set: 4391, number of used features: 12
2023-11-23 14:15:55,980:INFO:[LightGBM] [Info] Start training from score 186911.796402
2023-11-23 14:15:55,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,554:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:56,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005683 seconds.
2023-11-23 14:15:56,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:56,564:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:15:56,565:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:15:56,568:INFO:[LightGBM] [Info] Start training from score 187041.410752
2023-11-23 14:15:56,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:56,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,247:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:57,248:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.
2023-11-23 14:15:57,248:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:57,248:INFO:[LightGBM] [Info] Total Bins 2878
2023-11-23 14:15:57,248:INFO:[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 12
2023-11-23 14:15:57,249:INFO:[LightGBM] [Info] Start training from score 187066.106443
2023-11-23 14:15:57,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:57,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:58,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,374:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:15:59,377:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001546 seconds.
2023-11-23 14:15:59,377:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:15:59,377:INFO:[LightGBM] [Info] Total Bins 3178
2023-11-23 14:15:59,378:INFO:[LightGBM] [Info] Number of data points in the train set: 1798, number of used features: 12
2023-11-23 14:15:59,379:INFO:[LightGBM] [Info] Start training from score 184856.618465
2023-11-23 14:15:59,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:15:59,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,640:INFO:
2023-11-23 14:16:00,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,733:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:00,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.
2023-11-23 14:16:00,734:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:00,735:INFO:[LightGBM] [Info] Total Bins 3179
2023-11-23 14:16:00,735:INFO:[LightGBM] [Info] Number of data points in the train set: 2169, number of used features: 12
2023-11-23 14:16:00,735:INFO:[LightGBM] [Info] Start training from score 186068.971876
2023-11-23 14:16:00,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:00,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,035:INFO:
2023-11-23 14:16:01,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:01,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,093:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:02,094:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000826 seconds.
2023-11-23 14:16:02,094:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:02,094:INFO:[LightGBM] [Info] Total Bins 3190
2023-11-23 14:16:02,094:INFO:[LightGBM] [Info] Number of data points in the train set: 2539, number of used features: 12
2023-11-23 14:16:02,095:INFO:[LightGBM] [Info] Start training from score 186075.423395
2023-11-23 14:16:02,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,117:INFO:
2023-11-23 14:16:02,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:02,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,694:INFO:
2023-11-23 14:16:03,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,940:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:03,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:03,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001071 seconds.
2023-11-23 14:16:03,981:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:03,981:INFO:[LightGBM] [Info] Total Bins 3203
2023-11-23 14:16:03,981:INFO:[LightGBM] [Info] Number of data points in the train set: 2910, number of used features: 12
2023-11-23 14:16:03,981:INFO:[LightGBM] [Info] Start training from score 185959.827835
2023-11-23 14:16:03,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,174:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:04,178:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002974 seconds.
2023-11-23 14:16:04,179:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:04,179:INFO:[LightGBM] [Info] Total Bins 3210
2023-11-23 14:16:04,179:INFO:[LightGBM] [Info] Number of data points in the train set: 3280, number of used features: 12
2023-11-23 14:16:04,180:INFO:[LightGBM] [Info] Start training from score 185933.322866
2023-11-23 14:16:04,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,378:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:04,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000619 seconds.
2023-11-23 14:16:04,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:04,380:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:16:04,380:INFO:[LightGBM] [Info] Number of data points in the train set: 3650, number of used features: 12
2023-11-23 14:16:04,380:INFO:[LightGBM] [Info] Start training from score 186097.807945
2023-11-23 14:16:04,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:04,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,445:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:05,448:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001579 seconds.
2023-11-23 14:16:05,448:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:05,448:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:16:05,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,448:INFO:[LightGBM] [Info] Number of data points in the train set: 4021, number of used features: 12
2023-11-23 14:16:05,452:INFO:[LightGBM] [Info] Start training from score 186473.687889
2023-11-23 14:16:05,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,566:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:05,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018474 seconds.
2023-11-23 14:16:05,592:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:05,592:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:16:05,594:INFO:[LightGBM] [Info] Number of data points in the train set: 4391, number of used features: 12
2023-11-23 14:16:05,601:INFO:[LightGBM] [Info] Start training from score 186659.189023
2023-11-23 14:16:05,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,424:INFO:
2023-11-23 14:16:06,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,890:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:06,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022901 seconds.
2023-11-23 14:16:06,924:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:06,924:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:16:06,926:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:16:06,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,936:INFO:[LightGBM] [Info] Start training from score 186808.483620
2023-11-23 14:16:06,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:06,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,339:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:07,340:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001197 seconds.
2023-11-23 14:16:07,340:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:07,340:INFO:[LightGBM] [Info] Total Bins 2878
2023-11-23 14:16:07,341:INFO:[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 12
2023-11-23 14:16:07,341:INFO:[LightGBM] [Info] Start training from score 187066.106443
2023-11-23 14:16:07,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:07,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:08,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:09,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,143:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:10,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088687 seconds.
2023-11-23 14:16:10,233:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:10,234:INFO:[LightGBM] [Info] Total Bins 3176
2023-11-23 14:16:10,235:INFO:[LightGBM] [Info] Number of data points in the train set: 1798, number of used features: 12
2023-11-23 14:16:10,236:INFO:[LightGBM] [Info] Start training from score 185496.606785
2023-11-23 14:16:10,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:10,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:11,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,496:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:12,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,510:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004498 seconds.
2023-11-23 14:16:12,510:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:12,512:INFO:[LightGBM] [Info] Total Bins 3170
2023-11-23 14:16:12,514:INFO:[LightGBM] [Info] Number of data points in the train set: 2169, number of used features: 12
2023-11-23 14:16:12,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,518:INFO:[LightGBM] [Info] Start training from score 186008.344398
2023-11-23 14:16:12,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,985:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:12,987:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001219 seconds.
2023-11-23 14:16:12,987:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:12,988:INFO:[LightGBM] [Info] Total Bins 3182
2023-11-23 14:16:12,988:INFO:[LightGBM] [Info] Number of data points in the train set: 2539, number of used features: 12
2023-11-23 14:16:12,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:12,989:INFO:[LightGBM] [Info] Start training from score 186023.630957
2023-11-23 14:16:13,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,552:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:13,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,555:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:13,557:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001431 seconds.
2023-11-23 14:16:13,557:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:13,557:INFO:[LightGBM] [Info] Total Bins 3198
2023-11-23 14:16:13,558:INFO:[LightGBM] [Info] Number of data points in the train set: 3280, number of used features: 12
2023-11-23 14:16:13,558:INFO:[LightGBM] [Info] Start training from score 185893.231098
2023-11-23 14:16:13,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,564:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008630 seconds.
2023-11-23 14:16:13,565:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:13,566:INFO:[LightGBM] [Info] Total Bins 3197
2023-11-23 14:16:13,567:INFO:[LightGBM] [Info] Number of data points in the train set: 2910, number of used features: 12
2023-11-23 14:16:13,571:INFO:[LightGBM] [Info] Start training from score 185914.638488
2023-11-23 14:16:13,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:13,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,973:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:14,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:14,988:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012052 seconds.
2023-11-23 14:16:14,988:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:14,988:INFO:[LightGBM] [Info] Total Bins 3211
2023-11-23 14:16:14,989:INFO:[LightGBM] [Info] Number of data points in the train set: 3650, number of used features: 12
2023-11-23 14:16:14,998:INFO:[LightGBM] [Info] Start training from score 186061.780274
2023-11-23 14:16:15,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,283:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:15,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,291:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006247 seconds.
2023-11-23 14:16:15,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:15,291:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:16:15,292:INFO:[LightGBM] [Info] Number of data points in the train set: 4021, number of used features: 12
2023-11-23 14:16:15,294:INFO:[LightGBM] [Info] Start training from score 186440.984332
2023-11-23 14:16:15,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:15,988:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:15,996:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001215 seconds.
2023-11-23 14:16:15,997:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:15,997:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:16:15,997:INFO:[LightGBM] [Info] Number of data points in the train set: 4391, number of used features: 12
2023-11-23 14:16:15,997:INFO:[LightGBM] [Info] Start training from score 186629.241175
2023-11-23 14:16:16,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:16,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,253:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:17,255:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001759 seconds.
2023-11-23 14:16:17,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:17,256:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:16:17,256:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:16:17,257:INFO:[LightGBM] [Info] Start training from score 186780.868963
2023-11-23 14:16:17,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,830:INFO:
2023-11-23 14:16:17,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:17,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,497:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:18,499:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001099 seconds.
2023-11-23 14:16:18,499:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:18,499:INFO:[LightGBM] [Info] Total Bins 2878
2023-11-23 14:16:18,499:INFO:[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 12
2023-11-23 14:16:18,500:INFO:[LightGBM] [Info] Start training from score 187066.106443
2023-11-23 14:16:18,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:18,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:19,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:20,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,488:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:21,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,491:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001813 seconds.
2023-11-23 14:16:21,491:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:21,491:INFO:[LightGBM] [Info] Total Bins 3176
2023-11-23 14:16:21,492:INFO:[LightGBM] [Info] Number of data points in the train set: 1798, number of used features: 12
2023-11-23 14:16:21,493:INFO:[LightGBM] [Info] Start training from score 185496.606785
2023-11-23 14:16:21,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:21,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,757:INFO:
2023-11-23 14:16:22,787:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:22,792:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003781 seconds.
2023-11-23 14:16:22,792:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:22,792:INFO:[LightGBM] [Info] Total Bins 3169
2023-11-23 14:16:22,793:INFO:[LightGBM] [Info] Number of data points in the train set: 2169, number of used features: 12
2023-11-23 14:16:22,794:INFO:[LightGBM] [Info] Start training from score 185490.317658
2023-11-23 14:16:22,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:22,983:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:22,987:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002045 seconds.
2023-11-23 14:16:22,987:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:22,987:INFO:[LightGBM] [Info] Total Bins 3190
2023-11-23 14:16:22,987:INFO:[LightGBM] [Info] Number of data points in the train set: 2539, number of used features: 12
2023-11-23 14:16:22,988:INFO:[LightGBM] [Info] Start training from score 185130.956676
2023-11-23 14:16:22,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,346:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:23,347:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
2023-11-23 14:16:23,347:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:23,347:INFO:[LightGBM] [Info] Total Bins 3198
2023-11-23 14:16:23,347:INFO:[LightGBM] [Info] Number of data points in the train set: 2910, number of used features: 12
2023-11-23 14:16:23,347:INFO:[LightGBM] [Info] Start training from score 185461.236426
2023-11-23 14:16:23,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,363:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:23,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,482:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113566 seconds.
2023-11-23 14:16:23,482:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:23,482:INFO:[LightGBM] [Info] Total Bins 3205
2023-11-23 14:16:23,482:INFO:[LightGBM] [Info] Number of data points in the train set: 3280, number of used features: 12
2023-11-23 14:16:23,483:INFO:[LightGBM] [Info] Start training from score 185490.975000
2023-11-23 14:16:23,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,758:INFO:
2023-11-23 14:16:23,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:23,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,290:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:24,295:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003577 seconds.
2023-11-23 14:16:24,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:24,295:INFO:[LightGBM] [Info] Total Bins 3212
2023-11-23 14:16:24,296:INFO:[LightGBM] [Info] Number of data points in the train set: 3650, number of used features: 12
2023-11-23 14:16:24,299:INFO:[LightGBM] [Info] Start training from score 185700.300822
2023-11-23 14:16:24,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:24,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:25,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,139:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:26,143:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002067 seconds.
2023-11-23 14:16:26,143:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:26,143:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:16:26,143:INFO:[LightGBM] [Info] Number of data points in the train set: 4021, number of used features: 12
2023-11-23 14:16:26,144:INFO:[LightGBM] [Info] Start training from score 186112.857001
2023-11-23 14:16:26,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,444:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:26,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001232 seconds.
2023-11-23 14:16:26,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:26,446:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:16:26,446:INFO:[LightGBM] [Info] Number of data points in the train set: 4391, number of used features: 12
2023-11-23 14:16:26,447:INFO:[LightGBM] [Info] Start training from score 186328.762924
2023-11-23 14:16:26,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:26,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,256:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:27,275:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015470 seconds.
2023-11-23 14:16:27,275:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:27,275:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:16:27,278:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:16:27,283:INFO:[LightGBM] [Info] Start training from score 186503.800504
2023-11-23 14:16:27,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:27,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:28,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,261:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:29,263:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001000 seconds.
2023-11-23 14:16:29,263:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:29,263:INFO:[LightGBM] [Info] Total Bins 2878
2023-11-23 14:16:29,263:INFO:[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 12
2023-11-23 14:16:29,263:INFO:[LightGBM] [Info] Start training from score 187066.106443
2023-11-23 14:16:29,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,778:INFO:
2023-11-23 14:16:29,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:29,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,908:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:30,910:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001226 seconds.
2023-11-23 14:16:30,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:30,910:INFO:[LightGBM] [Info] Total Bins 3176
2023-11-23 14:16:30,910:INFO:[LightGBM] [Info] Number of data points in the train set: 1798, number of used features: 12
2023-11-23 14:16:30,911:INFO:[LightGBM] [Info] Start training from score 185496.606785
2023-11-23 14:16:30,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:30,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:31,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,070:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:32,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,073:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002334 seconds.
2023-11-23 14:16:32,074:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:32,074:INFO:[LightGBM] [Info] Total Bins 3169
2023-11-23 14:16:32,075:INFO:[LightGBM] [Info] Number of data points in the train set: 2169, number of used features: 12
2023-11-23 14:16:32,076:INFO:[LightGBM] [Info] Start training from score 185490.317658
2023-11-23 14:16:32,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,853:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:32,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,874:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012407 seconds.
2023-11-23 14:16:32,874:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:32,874:INFO:[LightGBM] [Info] Total Bins 3190
2023-11-23 14:16:32,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,876:INFO:[LightGBM] [Info] Number of data points in the train set: 2539, number of used features: 12
2023-11-23 14:16:32,879:INFO:[LightGBM] [Info] Start training from score 185130.956676
2023-11-23 14:16:32,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:32,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,750:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:33,751:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000731 seconds.
2023-11-23 14:16:33,751:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:33,751:INFO:[LightGBM] [Info] Total Bins 3199
2023-11-23 14:16:33,751:INFO:[LightGBM] [Info] Number of data points in the train set: 2910, number of used features: 12
2023-11-23 14:16:33,752:INFO:[LightGBM] [Info] Start training from score 185955.257388
2023-11-23 14:16:33,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:33,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,282:INFO:
2023-11-23 14:16:34,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,361:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:34,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002038 seconds.
2023-11-23 14:16:34,364:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:34,365:INFO:[LightGBM] [Info] Total Bins 3201
2023-11-23 14:16:34,366:INFO:[LightGBM] [Info] Number of data points in the train set: 3280, number of used features: 12
2023-11-23 14:16:34,367:INFO:[LightGBM] [Info] Start training from score 185725.396037
2023-11-23 14:16:34,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:34,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,090:INFO:
2023-11-23 14:16:35,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,874:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:35,877:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001976 seconds.
2023-11-23 14:16:35,877:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:35,877:INFO:[LightGBM] [Info] Total Bins 3211
2023-11-23 14:16:35,878:INFO:[LightGBM] [Info] Number of data points in the train set: 3650, number of used features: 12
2023-11-23 14:16:35,879:INFO:[LightGBM] [Info] Start training from score 185910.958630
2023-11-23 14:16:35,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:35,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,113:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:36,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002619 seconds.
2023-11-23 14:16:36,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:36,199:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:16:36,199:INFO:[LightGBM] [Info] Number of data points in the train set: 4021, number of used features: 12
2023-11-23 14:16:36,200:INFO:[LightGBM] [Info] Start training from score 186304.078339
2023-11-23 14:16:36,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,358:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:36,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004788 seconds.
2023-11-23 14:16:36,364:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:36,364:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:16:36,366:INFO:[LightGBM] [Info] Number of data points in the train set: 4391, number of used features: 12
2023-11-23 14:16:36,368:INFO:[LightGBM] [Info] Start training from score 186503.871328
2023-11-23 14:16:36,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,949:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,949:INFO:
2023-11-23 14:16:36,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:36,982:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014126 seconds.
2023-11-23 14:16:36,982:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:36,982:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:16:36,982:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:16:36,983:INFO:[LightGBM] [Info] Start training from score 186665.266485
2023-11-23 14:16:37,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:37,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,821:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:38,823:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001859 seconds.
2023-11-23 14:16:38,823:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:38,823:INFO:[LightGBM] [Info] Total Bins 2878
2023-11-23 14:16:38,824:INFO:[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 12
2023-11-23 14:16:38,824:INFO:[LightGBM] [Info] Start training from score 187066.106443
2023-11-23 14:16:38,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:38,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:39,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,155:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:40,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,158:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002014 seconds.
2023-11-23 14:16:40,158:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:40,158:INFO:[LightGBM] [Info] Total Bins 3176
2023-11-23 14:16:40,159:INFO:[LightGBM] [Info] Number of data points in the train set: 1798, number of used features: 12
2023-11-23 14:16:40,159:INFO:[LightGBM] [Info] Start training from score 185496.606785
2023-11-23 14:16:40,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:40,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:41,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,419:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:42,423:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002544 seconds.
2023-11-23 14:16:42,423:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:42,423:INFO:[LightGBM] [Info] Total Bins 3169
2023-11-23 14:16:42,423:INFO:[LightGBM] [Info] Number of data points in the train set: 2169, number of used features: 12
2023-11-23 14:16:42,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,425:INFO:[LightGBM] [Info] Start training from score 185490.317658
2023-11-23 14:16:42,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,902:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:42,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,917:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007371 seconds.
2023-11-23 14:16:42,917:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:16:42,917:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:16:42,917:INFO:[LightGBM] [Info] Total Bins 3190
2023-11-23 14:16:42,919:INFO:[LightGBM] [Info] Number of data points in the train set: 2539, number of used features: 12
2023-11-23 14:16:42,920:INFO:[LightGBM] [Info] Start training from score 185130.956676
2023-11-23 14:16:42,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:42,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:43,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,072:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:44,073:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2023-11-23 14:16:44,073:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:16:44,073:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:16:44,073:INFO:[LightGBM] [Info] Total Bins 3199
2023-11-23 14:16:44,074:INFO:[LightGBM] [Info] Number of data points in the train set: 2910, number of used features: 12
2023-11-23 14:16:44,074:INFO:[LightGBM] [Info] Start training from score 185955.257388
2023-11-23 14:16:44,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,196:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:44,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,226:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020440 seconds.
2023-11-23 14:16:44,226:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:44,226:INFO:[LightGBM] [Info] Total Bins 3203
2023-11-23 14:16:44,229:INFO:[LightGBM] [Info] Number of data points in the train set: 3280, number of used features: 12[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,229:INFO:
2023-11-23 14:16:44,233:INFO:[LightGBM] [Info] Start training from score 185871.524085
2023-11-23 14:16:44,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:44,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,466:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:45,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007223 seconds.
2023-11-23 14:16:45,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:45,475:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:16:45,476:INFO:[LightGBM] [Info] Number of data points in the train set: 3650, number of used features: 12
2023-11-23 14:16:45,478:INFO:[LightGBM] [Info] Start training from score 185294.081644
2023-11-23 14:16:45,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,502:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:45,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,607:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102449 seconds.
2023-11-23 14:16:45,607:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:45,607:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:16:45,607:INFO:[LightGBM] [Info] Number of data points in the train set: 4021, number of used features: 12
2023-11-23 14:16:45,608:INFO:[LightGBM] [Info] Start training from score 186117.234021
2023-11-23 14:16:45,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:45,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,642:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:46,643:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000963 seconds.
2023-11-23 14:16:46,643:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:46,643:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:16:46,643:INFO:[LightGBM] [Info] Number of data points in the train set: 4391, number of used features: 12
2023-11-23 14:16:46,643:INFO:[LightGBM] [Info] Start training from score 186332.771123
2023-11-23 14:16:46,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,759:INFO:
2023-11-23 14:16:46,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:46,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,437:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:47,451:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010234 seconds.
2023-11-23 14:16:47,452:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:47,452:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:16:47,454:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:16:47,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,459:INFO:[LightGBM] [Info] Start training from score 186507.496430
2023-11-23 14:16:47,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:47,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:48,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,430:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:49,431:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001135 seconds.
2023-11-23 14:16:49,431:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:49,431:INFO:[LightGBM] [Info] Total Bins 2878
2023-11-23 14:16:49,432:INFO:[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 12
2023-11-23 14:16:49,432:INFO:[LightGBM] [Info] Start training from score 187066.106443
2023-11-23 14:16:49,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:49,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:50,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:51,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:52,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,176:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:53,178:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001669 seconds.
2023-11-23 14:16:53,178:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:53,178:INFO:[LightGBM] [Info] Total Bins 3176
2023-11-23 14:16:53,178:INFO:[LightGBM] [Info] Number of data points in the train set: 1798, number of used features: 12
2023-11-23 14:16:53,179:INFO:[LightGBM] [Info] Start training from score 185496.606785
2023-11-23 14:16:53,207:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:53,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,217:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007774 seconds.
2023-11-23 14:16:53,217:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:53,217:INFO:[LightGBM] [Info] Total Bins 3169
2023-11-23 14:16:53,219:INFO:[LightGBM] [Info] Number of data points in the train set: 2169, number of used features: 12
2023-11-23 14:16:53,222:INFO:[LightGBM] [Info] Start training from score 185490.317658
2023-11-23 14:16:53,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:53,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,067:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:54,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001836 seconds.
2023-11-23 14:16:54,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:54,070:INFO:[LightGBM] [Info] Total Bins 3190
2023-11-23 14:16:54,070:INFO:[LightGBM] [Info] Number of data points in the train set: 2539, number of used features: 12
2023-11-23 14:16:54,071:INFO:[LightGBM] [Info] Start training from score 185130.956676
2023-11-23 14:16:54,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,566:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:54,569:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001484 seconds.
2023-11-23 14:16:54,569:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:54,569:INFO:[LightGBM] [Info] Total Bins 3199
2023-11-23 14:16:54,569:INFO:[LightGBM] [Info] Number of data points in the train set: 2910, number of used features: 12
2023-11-23 14:16:54,570:INFO:[LightGBM] [Info] Start training from score 185955.257388
2023-11-23 14:16:54,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,985:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:54,986:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000980 seconds.
2023-11-23 14:16:54,986:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:54,986:INFO:[LightGBM] [Info] Total Bins 3203
2023-11-23 14:16:54,986:INFO:[LightGBM] [Info] Number of data points in the train set: 3280, number of used features: 12
2023-11-23 14:16:54,987:INFO:[LightGBM] [Info] Start training from score 185871.524085
2023-11-23 14:16:54,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:54,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,149:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:55,152:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001833 seconds.
2023-11-23 14:16:55,152:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:55,152:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:16:55,152:INFO:[LightGBM] [Info] Number of data points in the train set: 3650, number of used features: 12
2023-11-23 14:16:55,153:INFO:[LightGBM] [Info] Start training from score 185294.081644
2023-11-23 14:16:55,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,689:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:55,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,731:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027744 seconds.
2023-11-23 14:16:55,731:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:55,731:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:16:55,733:INFO:[LightGBM] [Info] Number of data points in the train set: 4021, number of used features: 12
2023-11-23 14:16:55,735:INFO:[LightGBM] [Info] Start training from score 185785.450883
2023-11-23 14:16:55,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:55,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,348:INFO:
2023-11-23 14:16:56,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:56,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,734:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:57,735:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000569 seconds.
2023-11-23 14:16:57,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:57,735:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:16:57,736:INFO:[LightGBM] [Info] Number of data points in the train set: 4391, number of used features: 12
2023-11-23 14:16:57,736:INFO:[LightGBM] [Info] Start training from score 186124.299248
2023-11-23 14:16:57,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:57,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,649:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:16:58,651:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001117 seconds.
2023-11-23 14:16:58,651:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:16:58,651:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:16:58,651:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:16:58,652:INFO:[LightGBM] [Info] Start training from score 186315.266275
2023-11-23 14:16:58,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:58,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:16:59,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,578:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:17:00,580:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001172 seconds.
2023-11-23 14:17:00,580:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:17:00,580:INFO:[LightGBM] [Info] Total Bins 2878
2023-11-23 14:17:00,580:INFO:[LightGBM] [Info] Number of data points in the train set: 1428, number of used features: 12
2023-11-23 14:17:00,581:INFO:[LightGBM] [Info] Start training from score 187066.106443
2023-11-23 14:17:00,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:00,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:01,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,044:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:17:02,046:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000995 seconds.
2023-11-23 14:17:02,046:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:17:02,046:INFO:[LightGBM] [Info] Total Bins 3176
2023-11-23 14:17:02,046:INFO:[LightGBM] [Info] Number of data points in the train set: 1798, number of used features: 12
2023-11-23 14:17:02,047:INFO:[LightGBM] [Info] Start training from score 185496.606785
2023-11-23 14:17:02,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:02,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,864:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:17:03,865:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000942 seconds.
2023-11-23 14:17:03,865:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:17:03,867:INFO:[LightGBM] [Info] Total Bins 3169
2023-11-23 14:17:03,868:INFO:[LightGBM] [Info] Number of data points in the train set: 2169, number of used features: 12
2023-11-23 14:17:03,869:INFO:[LightGBM] [Info] Start training from score 185490.317658
2023-11-23 14:17:03,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:03,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,086:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:17:04,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,089:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:17:04,093:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005522 seconds.
2023-11-23 14:17:04,093:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:17:04,094:INFO:[LightGBM] [Info] Total Bins 3199
2023-11-23 14:17:04,094:INFO:[LightGBM] [Info] Number of data points in the train set: 2910, number of used features: 12
2023-11-23 14:17:04,095:INFO:[LightGBM] [Info] Start training from score 185955.257388
2023-11-23 14:17:04,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,109:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001815 seconds.
2023-11-23 14:17:04,109:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:17:04,109:INFO:[LightGBM] [Info] Total Bins 3190
2023-11-23 14:17:04,110:INFO:[LightGBM] [Info] Number of data points in the train set: 2539, number of used features: 12
2023-11-23 14:17:04,111:INFO:[LightGBM] [Info] Start training from score 185130.956676
2023-11-23 14:17:04,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,192:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:17:04,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,202:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007825 seconds.
2023-11-23 14:17:04,202:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:17:04,202:INFO:[LightGBM] [Info] Total Bins 3203
2023-11-23 14:17:04,203:INFO:[LightGBM] [Info] Number of data points in the train set: 3280, number of used features: 12
2023-11-23 14:17:04,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,205:INFO:[LightGBM] [Info] Start training from score 185871.524085
2023-11-23 14:17:04,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,219:INFO:
2023-11-23 14:17:04,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,328:INFO:
2023-11-23 14:17:04,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:04,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,012:INFO:
2023-11-23 14:17:05,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,226:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:17:05,226:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.
2023-11-23 14:17:05,226:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:17:05,226:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:17:05,226:INFO:[LightGBM] [Info] Number of data points in the train set: 3650, number of used features: 12
2023-11-23 14:17:05,226:INFO:[LightGBM] [Info] Start training from score 185294.081644
2023-11-23 14:17:05,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:05,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,609:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:17:06,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,610:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000902 seconds.
2023-11-23 14:17:06,610:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:17:06,610:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:17:06,610:INFO:[LightGBM] [Info] Number of data points in the train set: 4021, number of used features: 12
2023-11-23 14:17:06,611:INFO:[LightGBM] [Info] Start training from score 185785.450883
2023-11-23 14:17:06,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:06,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,470:INFO:
2023-11-23 14:17:07,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:07,965:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:17:07,966:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001038 seconds.
2023-11-23 14:17:07,967:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:17:07,967:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:17:07,967:INFO:[LightGBM] [Info] Number of data points in the train set: 4391, number of used features: 12
2023-11-23 14:17:07,969:INFO:[LightGBM] [Info] Start training from score 185874.014575
2023-11-23 14:17:07,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,246:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 14:17:08,248:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001370 seconds.
2023-11-23 14:17:08,248:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:17:08,248:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:17:08,248:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:17:08,249:INFO:[LightGBM] [Info] Start training from score 186114.027299
2023-11-23 14:17:08,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:08,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:09,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,342:INFO:
2023-11-23 14:17:10,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:10,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:11,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:12,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:13,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:13,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:13,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:13,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:13,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:13,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:13,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:13,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:14,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:14,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:14,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:14,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:17:15,105:INFO:Visual Rendered Successfully
2023-11-23 14:17:15,230:INFO:plot_model() successfully completed......................................
2023-11-23 14:19:37,873:INFO:Initializing plot_model()
2023-11-23 14:19:37,874:INFO:plot_model(plot=residuals, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))]), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, system=True)
2023-11-23 14:19:37,874:INFO:Checking exceptions
2023-11-23 14:19:37,904:INFO:Preloading libraries
2023-11-23 14:19:37,936:INFO:Copying training dataset
2023-11-23 14:19:37,936:INFO:Plot type: residuals
2023-11-23 14:19:38,003:INFO:Fitting Model
2023-11-23 14:19:38,063:INFO:Scoring test/hold-out set
2023-11-23 14:19:38,380:INFO:Visual Rendered Successfully
2023-11-23 14:19:38,504:INFO:plot_model() successfully completed......................................
2023-11-23 14:19:42,631:INFO:Initializing plot_model()
2023-11-23 14:19:42,631:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))]), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, system=True)
2023-11-23 14:19:42,631:INFO:Checking exceptions
2023-11-23 14:19:42,633:INFO:Preloading libraries
2023-11-23 14:19:42,654:INFO:Copying training dataset
2023-11-23 14:19:42,654:INFO:Plot type: feature
2023-11-23 14:19:42,654:WARNING:No coef_ found. Trying feature_importances_
2023-11-23 14:19:42,773:INFO:Visual Rendered Successfully
2023-11-23 14:19:42,826:INFO:plot_model() successfully completed......................................
2023-11-23 14:19:47,215:INFO:Initializing plot_model()
2023-11-23 14:19:47,216:INFO:plot_model(plot=rfe, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))]), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, system=True)
2023-11-23 14:19:47,216:INFO:Checking exceptions
2023-11-23 14:19:47,218:INFO:Preloading libraries
2023-11-23 14:19:47,235:INFO:Copying training dataset
2023-11-23 14:19:47,235:INFO:Plot type: rfe
2023-11-23 14:19:47,271:INFO:Fitting Model
2023-11-23 14:19:47,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2023-11-23 14:19:47,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:19:47,284:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:19:47,284:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:19:47,284:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:19:47,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:47,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:47,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:47,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:47,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:47,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:47,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:47,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:47,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:48,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:48,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:48,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.
2023-11-23 14:19:48,789:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:19:48,789:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:19:48,789:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:19:48,790:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:19:48,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:49,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:49,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:49,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:49,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:49,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:49,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:49,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:49,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:49,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2023-11-23 14:19:50,277:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:19:50,277:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:19:50,278:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:19:50,278:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:19:50,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:50,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:51,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:51,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:51,759:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2023-11-23 14:19:51,759:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:19:51,759:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:19:51,759:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:19:51,759:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:19:51,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:52,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:52,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:52,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:52,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:52,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:52,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:52,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:52,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:52,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:52,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2023-11-23 14:19:53,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:19:53,205:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:19:53,205:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:19:53,205:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:19:53,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:53,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:54,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:54,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:54,667:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
2023-11-23 14:19:54,668:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:19:54,668:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:19:54,668:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:19:54,668:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:19:54,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:54,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:54,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:54,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:55,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:55,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:55,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:55,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:55,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:55,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2023-11-23 14:19:56,096:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:19:56,096:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:19:56,097:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:19:56,097:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:19:56,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:56,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:57,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:57,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:57,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2023-11-23 14:19:57,469:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:19:57,469:INFO:[LightGBM] [Info] Total Bins 2260
2023-11-23 14:19:57,469:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 5
2023-11-23 14:19:57,469:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:19:57,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:57,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:57,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:57,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:57,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:57,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:58,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:58,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:58,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:58,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:58,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:58,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:58,923:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-11-23 14:19:58,923:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:19:58,924:INFO:[LightGBM] [Info] Total Bins 1805
2023-11-23 14:19:58,924:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 4
2023-11-23 14:19:58,924:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:19:58,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:59,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:59,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:59,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:59,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:59,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:59,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:59,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:59,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:59,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:19:59,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,285:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.
2023-11-23 14:20:00,285:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:00,285:INFO:[LightGBM] [Info] Total Bins 1350
2023-11-23 14:20:00,286:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 3
2023-11-23 14:20:00,286:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:20:00,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:00,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:01,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:01,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:01,630:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2023-11-23 14:20:01,630:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:01,630:INFO:[LightGBM] [Info] Total Bins 895
2023-11-23 14:20:01,630:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 2
2023-11-23 14:20:01,631:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:20:01,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:01,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:01,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:01,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:01,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:01,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:02,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:02,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:02,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:02,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:02,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:02,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:02,912:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.
2023-11-23 14:20:02,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:02,912:INFO:[LightGBM] [Info] Total Bins 452
2023-11-23 14:20:02,913:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 1
2023-11-23 14:20:02,913:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:20:02,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:02,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:02,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:03,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,087:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2023-11-23 14:20:04,087:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:04,087:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:20:04,087:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:20:04,087:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:04,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:04,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:05,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:05,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:05,521:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
2023-11-23 14:20:05,521:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:05,521:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:20:05,521:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:20:05,521:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:05,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:05,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:05,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:05,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:05,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:05,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:06,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:06,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:06,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:06,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:06,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:06,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:06,933:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000499 seconds.
2023-11-23 14:20:06,934:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:06,934:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:20:06,934:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:20:06,934:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:06,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:07,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:07,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:07,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:07,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:07,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:07,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:07,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:07,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:07,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:07,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:08,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:08,344:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2023-11-23 14:20:08,344:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:08,344:INFO:[LightGBM] [Info] Total Bins 3213
2023-11-23 14:20:08,344:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:20:08,345:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:08,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:08,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:08,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:08,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:08,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:08,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:08,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:08,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:08,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:09,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:09,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:09,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:09,739:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2023-11-23 14:20:09,739:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:09,739:INFO:[LightGBM] [Info] Total Bins 3211
2023-11-23 14:20:09,739:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:20:09,739:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:09,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:10,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:10,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:10,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:10,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:10,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:10,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:10,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:10,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:10,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:10,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,143:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
2023-11-23 14:20:11,143:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:11,143:INFO:[LightGBM] [Info] Total Bins 2756
2023-11-23 14:20:11,144:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:20:11,144:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:11,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:11,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:12,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:12,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:12,546:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.
2023-11-23 14:20:12,546:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:20:12,546:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:20:12,546:INFO:[LightGBM] [Info] Total Bins 2705
2023-11-23 14:20:12,546:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:20:12,547:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:12,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:12,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:12,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:12,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:12,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:12,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:13,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:13,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:13,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:13,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:13,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,100:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2023-11-23 14:20:14,100:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:14,100:INFO:[LightGBM] [Info] Total Bins 2250
2023-11-23 14:20:14,100:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 5
2023-11-23 14:20:14,100:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:14,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:14,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:15,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:15,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:15,441:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
2023-11-23 14:20:15,441:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:15,441:INFO:[LightGBM] [Info] Total Bins 1795
2023-11-23 14:20:15,441:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 4
2023-11-23 14:20:15,441:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:15,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:15,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:15,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:15,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:15,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:15,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:15,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:15,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:16,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:16,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:16,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:16,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:16,784:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.
2023-11-23 14:20:16,784:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:16,784:INFO:[LightGBM] [Info] Total Bins 1340
2023-11-23 14:20:16,784:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 3
2023-11-23 14:20:16,784:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:16,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:17,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:17,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:17,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:17,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:17,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:17,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:17,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:17,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:17,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:17,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,082:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2023-11-23 14:20:18,082:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:18,082:INFO:[LightGBM] [Info] Total Bins 885
2023-11-23 14:20:18,082:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 2
2023-11-23 14:20:18,082:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:18,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:18,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,354:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.
2023-11-23 14:20:19,354:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:19,354:INFO:[LightGBM] [Info] Total Bins 443
2023-11-23 14:20:19,354:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 1
2023-11-23 14:20:19,354:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:20:19,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:19,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2023-11-23 14:20:20,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:20,494:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:20:20,494:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:20:20,494:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:20,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:20,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:21,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:21,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:21,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:21,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:21,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:21,906:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2023-11-23 14:20:21,906:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:21,906:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:20:21,906:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:20:21,906:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:21,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:22,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:22,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:22,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:22,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:22,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:22,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:22,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:22,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:22,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,314:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2023-11-23 14:20:23,314:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:23,314:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:20:23,314:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:20:23,314:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:23,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:23,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:24,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:24,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:24,713:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2023-11-23 14:20:24,713:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:24,714:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:20:24,714:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:20:24,714:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:24,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:24,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:25,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:25,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:25,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:25,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:25,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:25,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:25,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:25,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:25,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,129:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2023-11-23 14:20:26,129:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:26,129:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:20:26,129:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:20:26,129:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:26,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:26,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:27,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:27,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:27,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2023-11-23 14:20:27,568:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:27,568:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:20:27,568:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:20:27,568:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:27,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:27,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:27,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:27,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:27,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:27,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:28,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:28,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:28,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:28,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:28,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:28,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:28,974:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2023-11-23 14:20:28,974:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:28,974:INFO:[LightGBM] [Info] Total Bins 2710
2023-11-23 14:20:28,974:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:20:28,974:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:29,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:29,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:29,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:29,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:29,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:29,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:29,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:29,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:29,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:29,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2023-11-23 14:20:30,342:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:30,342:INFO:[LightGBM] [Info] Total Bins 2255
2023-11-23 14:20:30,342:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:20:30,342:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:30,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:30,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:31,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:31,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:31,742:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.
2023-11-23 14:20:31,742:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:31,742:INFO:[LightGBM] [Info] Total Bins 1800
2023-11-23 14:20:31,742:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:20:31,742:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:31,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:31,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:32,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:32,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:32,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:32,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:32,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:32,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:32,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:32,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:32,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:33,055:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.
2023-11-23 14:20:33,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:33,055:INFO:[LightGBM] [Info] Total Bins 1345
2023-11-23 14:20:33,055:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:20:33,056:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:33,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:33,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:33,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:33,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:33,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:33,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:33,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:33,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:33,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:33,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2023-11-23 14:20:34,342:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:34,342:INFO:[LightGBM] [Info] Total Bins 890
2023-11-23 14:20:34,343:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:20:34,343:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:34,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:34,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,594:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2023-11-23 14:20:35,594:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:35,594:INFO:[LightGBM] [Info] Total Bins 447
2023-11-23 14:20:35,594:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 1
2023-11-23 14:20:35,594:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:20:35,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:35,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:36,766:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
2023-11-23 14:20:36,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:36,766:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:20:36,766:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:20:36,767:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:36,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:37,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:37,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:37,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:37,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:37,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:37,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:37,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:37,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:37,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:37,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,173:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.
2023-11-23 14:20:38,173:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:38,173:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:20:38,173:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:20:38,173:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:38,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:38,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:39,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:39,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:39,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
2023-11-23 14:20:39,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:39,563:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:20:39,563:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:20:39,563:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:39,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:39,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:39,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:39,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:39,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:39,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:40,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:40,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:40,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:40,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:40,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:40,987:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2023-11-23 14:20:40,987:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:40,987:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:20:40,987:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:20:40,987:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:41,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:41,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:41,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:41,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:41,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:41,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:41,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:41,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:41,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:41,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:42,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:42,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:42,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2023-11-23 14:20:42,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:42,392:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:20:42,393:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:20:42,393:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:42,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:42,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:42,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:42,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:42,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:42,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:42,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:42,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:43,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:43,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:43,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:43,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:43,797:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2023-11-23 14:20:43,797:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:43,797:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:20:43,797:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:20:43,797:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:43,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:44,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:44,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:44,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:44,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:44,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:44,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:44,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:44,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:44,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:44,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,164:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000416 seconds.
2023-11-23 14:20:45,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:45,164:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:20:45,164:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:20:45,165:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:45,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:45,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:46,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:46,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:46,524:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.
2023-11-23 14:20:46,524:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:46,524:INFO:[LightGBM] [Info] Total Bins 2254
2023-11-23 14:20:46,524:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:20:46,524:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:46,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:46,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:46,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:46,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:46,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:46,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:47,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:47,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:47,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:47,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:47,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:47,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:47,867:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2023-11-23 14:20:47,868:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:47,868:INFO:[LightGBM] [Info] Total Bins 1799
2023-11-23 14:20:47,868:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:20:47,868:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:47,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:48,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:48,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:48,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:48,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:48,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:48,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:48,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:48,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:48,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:48,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,196:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.
2023-11-23 14:20:49,196:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:49,196:INFO:[LightGBM] [Info] Total Bins 1344
2023-11-23 14:20:49,196:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:20:49,196:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:49,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:49,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:50,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:50,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:50,498:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
2023-11-23 14:20:50,498:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:50,498:INFO:[LightGBM] [Info] Total Bins 889
2023-11-23 14:20:50,498:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:20:50,498:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:50,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:50,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:50,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:50,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:50,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:50,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:50,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:50,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:51,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:51,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:51,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:51,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:51,764:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2023-11-23 14:20:51,764:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:51,764:INFO:[LightGBM] [Info] Total Bins 442
2023-11-23 14:20:51,764:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 1
2023-11-23 14:20:51,764:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:20:51,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:51,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:51,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:51,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:52,973:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.
2023-11-23 14:20:52,974:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:52,974:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:20:52,974:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:20:52,974:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:20:53,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:53,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:53,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:53,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:53,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:53,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:53,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:53,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:53,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:53,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:54,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:54,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:54,411:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2023-11-23 14:20:54,411:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:54,411:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:20:54,411:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:20:54,411:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:20:54,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:54,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:54,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:54,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:54,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:54,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:54,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:54,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:55,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:55,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:55,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:55,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:55,819:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-23 14:20:55,820:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:55,820:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:20:55,820:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:20:55,820:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:20:55,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:56,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:56,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:56,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:56,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:56,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:56,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:56,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:56,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:56,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,224:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
2023-11-23 14:20:57,224:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:57,224:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:20:57,225:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:20:57,225:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:20:57,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:57,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:58,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:58,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:58,612:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-11-23 14:20:58,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:20:58,612:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:20:58,613:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:20:58,613:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:20:58,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:58,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:58,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:58,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:58,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:58,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:59,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:59,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:59,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:59,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:59,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:20:59,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:00,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2023-11-23 14:21:00,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:00,030:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:21:00,030:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:21:00,031:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:21:00,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:00,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:00,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:00,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:00,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:00,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:00,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:00,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:00,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:00,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:01,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:01,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:01,422:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
2023-11-23 14:21:01,422:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:01,422:INFO:[LightGBM] [Info] Total Bins 2306
2023-11-23 14:21:01,422:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:21:01,422:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:21:01,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:01,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:01,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:01,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:01,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:01,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:01,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:01,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:02,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:02,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:02,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:02,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:02,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2023-11-23 14:21:02,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:02,777:INFO:[LightGBM] [Info] Total Bins 2255
2023-11-23 14:21:02,777:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:21:02,777:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:21:02,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:03,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:03,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:03,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:03,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:03,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:03,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:03,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:03,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:03,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:03,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,140:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.
2023-11-23 14:21:04,140:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:04,140:INFO:[LightGBM] [Info] Total Bins 1800
2023-11-23 14:21:04,140:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:21:04,140:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:21:04,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:04,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:05,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:05,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:05,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.
2023-11-23 14:21:05,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:05,475:INFO:[LightGBM] [Info] Total Bins 1345
2023-11-23 14:21:05,475:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:21:05,475:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:21:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:05,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:05,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:05,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:05,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:05,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:05,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:05,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:06,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:06,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:06,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:06,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:06,783:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000302 seconds.
2023-11-23 14:21:06,783:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:06,783:INFO:[LightGBM] [Info] Total Bins 890
2023-11-23 14:21:06,783:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:21:06,783:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:21:06,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:07,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,052:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2023-11-23 14:21:08,052:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:08,052:INFO:[LightGBM] [Info] Total Bins 445
2023-11-23 14:21:08,052:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 1
2023-11-23 14:21:08,053:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:21:08,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:08,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
2023-11-23 14:21:09,244:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:09,244:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:21:09,244:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:21:09,244:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:09,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:09,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:10,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:10,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:10,658:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2023-11-23 14:21:10,658:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:10,658:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:21:10,658:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:21:10,658:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:10,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:10,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:10,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:10,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:11,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:11,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:11,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:11,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:11,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:11,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:11,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:11,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:12,060:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2023-11-23 14:21:12,060:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:12,060:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:21:12,060:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:21:12,060:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:12,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:12,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:12,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:12,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:12,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:12,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:12,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:12,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:12,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:12,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:13,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:13,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:13,500:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2023-11-23 14:21:13,500:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:13,500:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:21:13,500:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:21:13,500:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:13,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:13,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:13,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:13,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:13,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:13,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:14,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:14,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:14,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:14,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:14,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:14,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:14,917:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2023-11-23 14:21:14,917:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:14,917:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:21:14,917:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:21:14,918:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:14,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:15,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:15,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:15,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:15,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:15,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:15,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:15,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:15,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:15,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:15,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,327:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
2023-11-23 14:21:16,327:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:16,328:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:21:16,328:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:21:16,328:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:16,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:16,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:17,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:17,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:17,715:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.
2023-11-23 14:21:17,715:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:17,715:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:21:17,715:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:21:17,715:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:17,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:17,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:18,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:18,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:18,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:18,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:18,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:18,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:18,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:18,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:18,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:18,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:19,079:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000302 seconds.
2023-11-23 14:21:19,079:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:19,079:INFO:[LightGBM] [Info] Total Bins 2260
2023-11-23 14:21:19,079:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:21:19,080:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:19,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:19,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:19,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:19,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:19,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:19,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:19,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:19,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:19,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:19,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:20,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:20,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:20,438:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2023-11-23 14:21:20,438:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:20,438:INFO:[LightGBM] [Info] Total Bins 1805
2023-11-23 14:21:20,438:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:21:20,438:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:20,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:20,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:20,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:20,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:20,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:20,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:20,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:20,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:21,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:21,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:21,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:21,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:21,771:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.
2023-11-23 14:21:21,771:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:21,771:INFO:[LightGBM] [Info] Total Bins 1350
2023-11-23 14:21:21,771:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:21:21,772:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:21,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:22,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:23,072:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2023-11-23 14:21:23,072:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:23,072:INFO:[LightGBM] [Info] Total Bins 895
2023-11-23 14:21:23,072:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:21:23,073:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:23,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:23,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:23,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:23,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:23,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:23,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:23,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:23,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:23,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:23,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000263 seconds.
2023-11-23 14:21:24,350:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:24,350:INFO:[LightGBM] [Info] Total Bins 452
2023-11-23 14:21:24,350:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 1
2023-11-23 14:21:24,350:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:21:24,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:24,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,633:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2023-11-23 14:21:25,633:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:25,633:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:21:25,633:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:21:25,633:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:25,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:25,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:26,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:26,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:26,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:26,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:26,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:26,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:27,082:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2023-11-23 14:21:27,082:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:27,082:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:21:27,082:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:21:27,082:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:27,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:27,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:27,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:27,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:27,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:27,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:27,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:27,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:27,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:27,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:28,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:28,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:28,502:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.
2023-11-23 14:21:28,502:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:28,502:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:21:28,502:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:21:28,502:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:28,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:28,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:28,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:28,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:28,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:28,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:29,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:29,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:29,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:29,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:29,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:29,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:29,904:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
2023-11-23 14:21:29,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:29,904:INFO:[LightGBM] [Info] Total Bins 3214
2023-11-23 14:21:29,904:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:21:29,904:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:29,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:30,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:30,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:30,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:30,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:30,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:30,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:30,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:30,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:30,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:30,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,324:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.
2023-11-23 14:21:31,324:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:31,324:INFO:[LightGBM] [Info] Total Bins 3212
2023-11-23 14:21:31,324:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:21:31,324:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:31,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:31,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:32,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:32,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:32,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.
2023-11-23 14:21:32,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:32,728:INFO:[LightGBM] [Info] Total Bins 2757
2023-11-23 14:21:32,728:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:21:32,728:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:32,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:32,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:33,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:33,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:33,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:33,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:33,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:33,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:33,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:33,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:33,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,111:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
2023-11-23 14:21:34,111:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:34,111:INFO:[LightGBM] [Info] Total Bins 2302
2023-11-23 14:21:34,111:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:21:34,112:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:34,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:34,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:35,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:35,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:35,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2023-11-23 14:21:35,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:35,467:INFO:[LightGBM] [Info] Total Bins 2251
2023-11-23 14:21:35,467:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:21:35,467:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:35,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:35,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:35,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:35,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:35,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:35,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:35,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:35,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:36,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:36,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:36,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:36,844:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2023-11-23 14:21:36,844:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:36,844:INFO:[LightGBM] [Info] Total Bins 1796
2023-11-23 14:21:36,844:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:21:36,844:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:36,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:37,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:37,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:37,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:37,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:37,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:37,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:37,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:37,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:37,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,194:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2023-11-23 14:21:38,194:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:38,194:INFO:[LightGBM] [Info] Total Bins 1341
2023-11-23 14:21:38,195:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:21:38,195:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:38,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:38,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:39,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:39,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:39,573:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000462 seconds.
2023-11-23 14:21:39,573:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:39,573:INFO:[LightGBM] [Info] Total Bins 886
2023-11-23 14:21:39,573:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:21:39,573:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:39,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:39,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:39,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:39,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:39,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:39,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,927:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000286 seconds.
2023-11-23 14:21:40,927:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:40,927:INFO:[LightGBM] [Info] Total Bins 445
2023-11-23 14:21:40,927:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 1
2023-11-23 14:21:40,927:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:21:40,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:40,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:41,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,164:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000795 seconds.
2023-11-23 14:21:42,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:42,164:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:21:42,164:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:21:42,164:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:42,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:42,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:43,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:43,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:43,747:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2023-11-23 14:21:43,747:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:43,747:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:21:43,747:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:21:43,747:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:43,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:44,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:44,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:44,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:44,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:44,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:44,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:44,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:44,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:44,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:44,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:45,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:45,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000239 seconds.
2023-11-23 14:21:45,209:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:21:45,209:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:21:45,209:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:21:45,209:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:21:45,209:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:45,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:45,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:45,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:45,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:45,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:45,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:45,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:45,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:46,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:46,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:46,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:46,918:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000531 seconds.
2023-11-23 14:21:46,918:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:46,918:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:21:46,919:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:21:46,919:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:46,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:47,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:47,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:47,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:47,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:47,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:47,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:47,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:47,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:47,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:47,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:48,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:48,358:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000191 seconds.
2023-11-23 14:21:48,358:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:21:48,358:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:21:48,358:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:21:48,358:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:21:48,358:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:48,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:48,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:48,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:48,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:48,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:48,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:48,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:48,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:49,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:49,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:49,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:49,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:50,069:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
2023-11-23 14:21:50,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:50,069:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:21:50,069:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:21:50,069:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:50,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:50,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:50,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:50,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:50,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:50,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:50,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:50,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:50,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:50,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:51,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:51,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:51,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2023-11-23 14:21:51,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:51,536:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:21:51,536:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:21:51,536:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:51,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:51,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:51,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:51,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:51,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:51,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:52,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:52,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:52,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:52,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:52,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:52,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:52,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2023-11-23 14:21:52,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:52,943:INFO:[LightGBM] [Info] Total Bins 2254
2023-11-23 14:21:52,943:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:21:52,944:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:52,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:53,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:53,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:53,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:53,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:53,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:53,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:53,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:53,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:53,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:53,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:54,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:54,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2023-11-23 14:21:54,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:54,356:INFO:[LightGBM] [Info] Total Bins 1799
2023-11-23 14:21:54,356:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:21:54,356:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:54,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:54,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:54,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:54,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:54,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:54,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:54,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:54,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:54,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:55,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:55,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:55,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:55,727:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2023-11-23 14:21:55,727:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:55,727:INFO:[LightGBM] [Info] Total Bins 1344
2023-11-23 14:21:55,728:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:21:55,728:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:55,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:55,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:56,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:56,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:56,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:56,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:56,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:56,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:56,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:56,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:56,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:56,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,050:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000245 seconds.
2023-11-23 14:21:57,050:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:57,050:INFO:[LightGBM] [Info] Total Bins 889
2023-11-23 14:21:57,050:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:21:57,050:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:57,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:57,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,304:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.
2023-11-23 14:21:58,304:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:58,304:INFO:[LightGBM] [Info] Total Bins 442
2023-11-23 14:21:58,304:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 1
2023-11-23 14:21:58,304:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:21:58,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:58,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
2023-11-23 14:21:59,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:21:59,515:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:21:59,515:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:21:59,516:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:21:59,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:21:59,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:00,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:00,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:00,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:00,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:00,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:00,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:00,932:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
2023-11-23 14:22:00,932:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:00,932:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:22:00,932:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:22:00,932:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:00,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:01,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:01,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:01,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:01,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:01,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:01,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:01,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:01,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:01,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:01,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:02,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:02,347:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000515 seconds.
2023-11-23 14:22:02,348:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:02,348:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:22:02,348:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:22:02,348:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:02,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:02,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:02,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:02,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:02,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:02,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:02,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:02,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:02,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:03,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:03,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:03,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:03,759:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2023-11-23 14:22:03,759:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:03,759:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:22:03,759:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:22:03,759:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:03,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:04,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:04,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:04,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:04,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:04,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:04,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:04,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:04,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:04,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:04,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-11-23 14:22:05,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:05,177:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:22:05,177:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:22:05,177:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:05,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:05,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:06,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:06,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:06,581:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
2023-11-23 14:22:06,581:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:06,581:INFO:[LightGBM] [Info] Total Bins 2762
2023-11-23 14:22:06,581:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:22:06,581:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:06,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:06,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:06,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:06,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:06,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:07,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:07,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:07,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:07,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:07,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:07,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:07,979:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2023-11-23 14:22:07,979:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:07,979:INFO:[LightGBM] [Info] Total Bins 2307
2023-11-23 14:22:07,979:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:22:07,979:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:08,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:08,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:08,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:08,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:08,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:08,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:08,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:08,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:08,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:08,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:08,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:09,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:09,346:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.
2023-11-23 14:22:09,346:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:09,346:INFO:[LightGBM] [Info] Total Bins 2256
2023-11-23 14:22:09,346:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:22:09,346:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:09,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:09,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:09,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:09,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:09,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:09,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:09,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:09,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:09,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:10,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:10,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:10,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:10,727:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000280 seconds.
2023-11-23 14:22:10,727:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:10,727:INFO:[LightGBM] [Info] Total Bins 1801
2023-11-23 14:22:10,727:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:22:10,727:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:10,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:10,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:11,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:11,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:11,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:11,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:11,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:11,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:11,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:11,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:11,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:11,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:12,064:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000328 seconds.
2023-11-23 14:22:12,064:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:12,064:INFO:[LightGBM] [Info] Total Bins 1346
2023-11-23 14:22:12,064:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:22:12,064:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:12,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:12,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:12,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:12,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:12,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:12,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:12,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:12,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:12,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:12,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,387:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
2023-11-23 14:22:13,387:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:13,387:INFO:[LightGBM] [Info] Total Bins 891
2023-11-23 14:22:13,388:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:22:13,388:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:13,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:13,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,667:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2023-11-23 14:22:14,667:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:14,667:INFO:[LightGBM] [Info] Total Bins 445
2023-11-23 14:22:14,667:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 1
2023-11-23 14:22:14,667:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:22:14,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:14,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:15,822:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000533 seconds.
2023-11-23 14:22:15,822:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:15,822:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:22:15,822:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:22:15,822:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:15,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:16,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:16,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:16,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:16,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:16,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:16,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:16,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:16,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:16,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:16,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,216:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2023-11-23 14:22:17,216:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:17,217:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:22:17,217:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:22:17,217:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:17,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:17,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:18,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:18,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:18,621:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
2023-11-23 14:22:18,621:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:18,621:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:22:18,621:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:22:18,621:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:18,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:18,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:18,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:18,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:18,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:18,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:19,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:19,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:19,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:19,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:19,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:19,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:20,017:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2023-11-23 14:22:20,017:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:20,017:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:22:20,017:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:22:20,017:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:20,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:20,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:20,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:20,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:20,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:20,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:20,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:20,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:20,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:20,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:21,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:21,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:21,401:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000506 seconds.
2023-11-23 14:22:21,401:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:21,401:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:22:21,401:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:22:21,401:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:21,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:21,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:21,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:21,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:21,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:21,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:21,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:21,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:22,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:22,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:22,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:22,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:22,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000273 seconds.
2023-11-23 14:22:22,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:22:22,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:22:22,782:INFO:[LightGBM] [Info] Total Bins 2764
2023-11-23 14:22:22,782:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:22:22,782:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:22,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:23,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:23,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:23,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:23,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:23,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:23,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:23,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:23,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:23,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:23,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,342:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2023-11-23 14:22:24,342:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:24,342:INFO:[LightGBM] [Info] Total Bins 2309
2023-11-23 14:22:24,342:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:22:24,342:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:24,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:24,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:25,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:25,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:25,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2023-11-23 14:22:25,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:25,737:INFO:[LightGBM] [Info] Total Bins 2258
2023-11-23 14:22:25,737:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:22:25,737:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:25,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:25,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:26,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:26,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:26,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:26,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:26,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:26,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:26,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:26,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:26,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,108:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000440 seconds.
2023-11-23 14:22:27,108:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:27,108:INFO:[LightGBM] [Info] Total Bins 1803
2023-11-23 14:22:27,108:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:22:27,109:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:27,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:28,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:28,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:28,477:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2023-11-23 14:22:28,478:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:28,478:INFO:[LightGBM] [Info] Total Bins 1348
2023-11-23 14:22:28,478:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:22:28,478:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:28,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:28,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:28,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:28,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:28,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:28,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:28,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:28,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:29,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:29,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:29,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:29,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:29,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2023-11-23 14:22:29,796:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:29,796:INFO:[LightGBM] [Info] Total Bins 893
2023-11-23 14:22:29,796:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:22:29,797:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:29,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:30,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:30,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:30,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:30,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:30,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:30,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:30,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:30,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:30,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:30,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,124:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.
2023-11-23 14:22:31,124:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:31,124:INFO:[LightGBM] [Info] Total Bins 446
2023-11-23 14:22:31,124:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 1
2023-11-23 14:22:31,125:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:22:31,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:31,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,333:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
2023-11-23 14:22:32,333:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:32,334:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:22:32,334:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:22:32,334:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:32,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:32,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:33,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:33,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:33,718:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
2023-11-23 14:22:33,718:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:33,718:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:22:33,718:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:22:33,719:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:33,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:33,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:34,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:34,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:34,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:34,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:34,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:34,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:34,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:34,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:34,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,096:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.
2023-11-23 14:22:35,097:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:35,097:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:22:35,097:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:22:35,097:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:35,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:35,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:36,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:36,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:36,486:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2023-11-23 14:22:36,486:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:36,486:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:22:36,486:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:22:36,486:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:36,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:36,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:36,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:36,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:36,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:36,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:37,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:37,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:37,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:37,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:37,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:37,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:37,997:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000587 seconds.
2023-11-23 14:22:37,997:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:37,997:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:22:37,997:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:22:37,998:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:38,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:38,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:38,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:38,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:38,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:38,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:38,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:38,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:38,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:38,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:39,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:39,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:39,484:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.
2023-11-23 14:22:39,484:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:39,484:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:22:39,484:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:22:39,484:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:39,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:39,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:39,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:39,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:40,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:40,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:40,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:40,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:40,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2023-11-23 14:22:40,936:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:40,936:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:22:40,937:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:22:40,937:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:40,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:41,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:41,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:41,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:41,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:41,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:41,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:41,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:41,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:41,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:41,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,332:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2023-11-23 14:22:42,332:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:42,332:INFO:[LightGBM] [Info] Total Bins 2260
2023-11-23 14:22:42,332:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 5
2023-11-23 14:22:42,332:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:42,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:42,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:43,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:43,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:43,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2023-11-23 14:22:43,789:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:43,789:INFO:[LightGBM] [Info] Total Bins 1805
2023-11-23 14:22:43,789:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 4
2023-11-23 14:22:43,790:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:43,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:44,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:44,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:44,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:44,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:44,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:44,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:44,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:44,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:44,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:44,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:45,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:45,354:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2023-11-23 14:22:45,354:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:45,354:INFO:[LightGBM] [Info] Total Bins 1350
2023-11-23 14:22:45,354:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 3
2023-11-23 14:22:45,354:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:45,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:45,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:45,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:45,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:45,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:45,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:46,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:46,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:46,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:46,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2023-11-23 14:22:46,854:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:46,854:INFO:[LightGBM] [Info] Total Bins 895
2023-11-23 14:22:46,854:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 2
2023-11-23 14:22:46,854:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:22:46,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:47,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:47,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:47,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:47,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:47,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:47,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:47,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:47,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:47,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:47,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,178:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.
2023-11-23 14:22:48,178:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:48,178:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:22:48,178:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:22:48,178:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:22:48,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:48,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:49,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:49,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:49,671:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2023-11-23 14:22:49,672:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:49,672:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:22:49,672:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:22:49,672:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:22:49,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:49,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:49,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:49,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:50,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:50,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:50,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:50,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:50,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:50,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,115:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000462 seconds.
2023-11-23 14:22:51,115:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:51,115:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:22:51,115:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:22:51,115:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:22:51,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:51,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:52,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:52,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:52,571:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000730 seconds.
2023-11-23 14:22:52,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:52,571:INFO:[LightGBM] [Info] Total Bins 3213
2023-11-23 14:22:52,571:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:22:52,571:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:22:52,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:52,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:52,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:52,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:52,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:52,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:53,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:53,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:53,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:53,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:53,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,147:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
2023-11-23 14:22:54,147:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:54,147:INFO:[LightGBM] [Info] Total Bins 3211
2023-11-23 14:22:54,147:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:22:54,147:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:22:54,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:54,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:55,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:55,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:55,626:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2023-11-23 14:22:55,626:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:55,626:INFO:[LightGBM] [Info] Total Bins 2756
2023-11-23 14:22:55,626:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:22:55,626:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:22:55,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:55,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:55,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:55,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:55,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:55,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:56,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:56,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:56,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:56,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:56,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:56,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:57,032:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2023-11-23 14:22:57,032:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:57,032:INFO:[LightGBM] [Info] Total Bins 2705
2023-11-23 14:22:57,032:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:22:57,032:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:22:57,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:57,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:57,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:57,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:57,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:57,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:57,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:57,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:57,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:58,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:58,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:58,439:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.
2023-11-23 14:22:58,439:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:58,439:INFO:[LightGBM] [Info] Total Bins 2250
2023-11-23 14:22:58,439:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 5
2023-11-23 14:22:58,439:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:22:58,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:58,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:58,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:58,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:58,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:58,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:58,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:58,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:59,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:59,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:59,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:59,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:22:59,880:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2023-11-23 14:22:59,880:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:22:59,880:INFO:[LightGBM] [Info] Total Bins 1795
2023-11-23 14:22:59,880:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 4
2023-11-23 14:22:59,880:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:22:59,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:00,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:00,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:00,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:00,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:00,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:00,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:00,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:00,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:00,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:00,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,331:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
2023-11-23 14:23:01,331:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:01,331:INFO:[LightGBM] [Info] Total Bins 1340
2023-11-23 14:23:01,331:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 3
2023-11-23 14:23:01,331:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:23:01,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:01,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:02,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:02,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:02,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2023-11-23 14:23:02,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:02,729:INFO:[LightGBM] [Info] Total Bins 885
2023-11-23 14:23:02,729:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 2
2023-11-23 14:23:02,729:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:23:02,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:02,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:03,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:03,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:03,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:03,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:03,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:03,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:03,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:03,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:03,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2023-11-23 14:23:04,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:04,157:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:23:04,157:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:23:04,157:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:04,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:04,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:05,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:05,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:05,639:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2023-11-23 14:23:05,639:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:05,639:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:23:05,639:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:23:05,639:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:05,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:05,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:05,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:05,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:06,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:06,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:06,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:06,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:06,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:06,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:06,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.
2023-11-23 14:23:07,233:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:07,233:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:23:07,233:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:23:07,233:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:07,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:07,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:08,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:08,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:08,701:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2023-11-23 14:23:08,701:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:08,701:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:23:08,701:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:23:08,701:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:08,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:09,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:09,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:09,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:09,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:09,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:09,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:09,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:09,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:09,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:09,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:10,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:10,183:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000702 seconds.
2023-11-23 14:23:10,183:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:10,183:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:23:10,184:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:23:10,184:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:10,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:10,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:10,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:10,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:10,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:10,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:10,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:10,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:10,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:11,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:11,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:11,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:11,833:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000717 seconds.
2023-11-23 14:23:11,833:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:11,833:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:23:11,833:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:23:11,833:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:11,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:12,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:12,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:12,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:12,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:12,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:12,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:12,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:12,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:12,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:12,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,301:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2023-11-23 14:23:13,301:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:13,301:INFO:[LightGBM] [Info] Total Bins 2710
2023-11-23 14:23:13,301:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:23:13,302:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:13,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:13,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:14,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:14,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:14,715:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-11-23 14:23:14,715:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:14,715:INFO:[LightGBM] [Info] Total Bins 2255
2023-11-23 14:23:14,716:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:23:14,716:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:14,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:15,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:15,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:15,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:15,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:15,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:15,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:15,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:15,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:15,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:15,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,164:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.
2023-11-23 14:23:16,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:16,165:INFO:[LightGBM] [Info] Total Bins 1800
2023-11-23 14:23:16,165:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:23:16,165:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:16,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:16,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:17,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:17,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:17,557:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.
2023-11-23 14:23:17,557:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:17,557:INFO:[LightGBM] [Info] Total Bins 1345
2023-11-23 14:23:17,557:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:23:17,557:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:17,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:17,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:17,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:17,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:17,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:17,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:18,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:18,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:18,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:18,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:18,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:18,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:18,906:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2023-11-23 14:23:18,907:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:18,907:INFO:[LightGBM] [Info] Total Bins 890
2023-11-23 14:23:18,907:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:23:18,907:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:23:18,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:19,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:19,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:19,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:19,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:19,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:19,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:19,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:19,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:19,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:19,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:20,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:20,318:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2023-11-23 14:23:20,318:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:20,318:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:23:20,318:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:23:20,318:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:20,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:20,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:20,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:20,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:20,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:20,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:20,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:20,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:20,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:21,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:21,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:21,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:21,843:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2023-11-23 14:23:21,843:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:21,843:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:23:21,843:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:23:21,843:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:21,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:22,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:22,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:22,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:22,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:22,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:22,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:22,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:22,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:22,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:22,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:23,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:23,325:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000497 seconds.
2023-11-23 14:23:23,325:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:23,325:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:23:23,326:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:23:23,326:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:23,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:23,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:23,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:23,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:23,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:23,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:23,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:23,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:23,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:24,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:24,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:24,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:24,772:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2023-11-23 14:23:24,772:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:24,772:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:23:24,772:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:23:24,772:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:24,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:25,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:25,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:25,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:25,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:25,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:25,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:25,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:25,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:25,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:25,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,206:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
2023-11-23 14:23:26,206:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:26,206:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:23:26,206:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:23:26,206:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:26,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:26,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:27,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:27,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:27,639:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
2023-11-23 14:23:27,639:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:27,639:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:23:27,640:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:23:27,640:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:27,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:27,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:27,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:27,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:27,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:27,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:28,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:28,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:28,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:28,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:28,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:28,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:29,045:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2023-11-23 14:23:29,045:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:29,045:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:23:29,045:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:23:29,046:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:29,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:29,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:29,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:29,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:29,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:29,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:29,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:29,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:29,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:29,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:30,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:30,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:30,430:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.
2023-11-23 14:23:30,430:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:30,431:INFO:[LightGBM] [Info] Total Bins 2254
2023-11-23 14:23:30,431:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:23:30,431:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:30,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:30,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:30,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:30,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:30,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:30,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:30,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:30,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:31,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:31,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:31,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:31,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:31,825:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.
2023-11-23 14:23:31,825:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:31,825:INFO:[LightGBM] [Info] Total Bins 1799
2023-11-23 14:23:31,825:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:23:31,826:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:31,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:32,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:32,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:32,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:32,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:32,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:32,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:32,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:32,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:32,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:32,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,217:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2023-11-23 14:23:33,217:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:33,217:INFO:[LightGBM] [Info] Total Bins 1344
2023-11-23 14:23:33,218:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:23:33,218:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:33,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:33,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:34,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:34,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:34,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2023-11-23 14:23:34,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:34,528:INFO:[LightGBM] [Info] Total Bins 889
2023-11-23 14:23:34,528:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:23:34,528:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:23:34,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:34,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:34,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:34,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:34,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:34,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:34,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:34,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:35,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:35,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:35,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:35,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:35,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.
2023-11-23 14:23:35,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:35,805:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:23:35,805:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:23:35,805:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:35,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:36,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:36,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:36,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:36,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:36,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:36,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:36,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:36,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:36,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:36,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,229:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
2023-11-23 14:23:37,229:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:37,230:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:23:37,230:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:23:37,230:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:37,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:37,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:38,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:38,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:38,656:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2023-11-23 14:23:38,656:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:38,656:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:23:38,656:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:23:38,656:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:38,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:38,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:38,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:38,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:39,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:39,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:39,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:39,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:39,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:39,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,088:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2023-11-23 14:23:40,088:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:40,088:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:23:40,088:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:23:40,088:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:40,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:41,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:41,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:41,520:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2023-11-23 14:23:41,520:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:41,520:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:23:41,520:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:23:41,520:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:41,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:41,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:41,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:41,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:41,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:41,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:42,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:42,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:42,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:42,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:42,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:42,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:42,945:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
2023-11-23 14:23:42,946:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:42,946:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:23:42,946:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:23:42,946:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:42,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:43,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:43,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:43,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:43,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:43,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:43,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:43,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:43,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:43,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,373:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.
2023-11-23 14:23:44,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:44,373:INFO:[LightGBM] [Info] Total Bins 2306
2023-11-23 14:23:44,373:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:23:44,374:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:44,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:44,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:45,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:45,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:45,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:45,762:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2023-11-23 14:23:45,762:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:45,762:INFO:[LightGBM] [Info] Total Bins 2255
2023-11-23 14:23:45,763:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:23:45,763:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:45,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:46,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:46,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:46,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:46,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:46,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:46,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:46,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:46,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:46,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:46,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
2023-11-23 14:23:47,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:47,177:INFO:[LightGBM] [Info] Total Bins 1800
2023-11-23 14:23:47,177:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:23:47,177:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:47,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:47,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:48,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:48,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:48,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2023-11-23 14:23:48,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:48,584:INFO:[LightGBM] [Info] Total Bins 1345
2023-11-23 14:23:48,584:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:23:48,584:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:48,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:48,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:48,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:48,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:48,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:48,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:49,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:49,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:49,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:49,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:49,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:49,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:50,037:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2023-11-23 14:23:50,037:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:50,037:INFO:[LightGBM] [Info] Total Bins 890
2023-11-23 14:23:50,037:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:23:50,038:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:23:50,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:50,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:50,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:50,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:50,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:50,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:50,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:50,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:50,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:50,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,370:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2023-11-23 14:23:51,370:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:51,370:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:23:51,370:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:23:51,370:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:23:51,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:51,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:52,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:52,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:52,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:52,836:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000542 seconds.
2023-11-23 14:23:52,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:52,836:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:23:52,836:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:23:52,836:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:23:52,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:53,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:53,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:53,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:53,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:53,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:53,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:53,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:53,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:53,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:53,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:54,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:54,321:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2023-11-23 14:23:54,321:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:54,321:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:23:54,321:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:23:54,321:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:23:54,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:54,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:54,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:54,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:54,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:54,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:54,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:54,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:54,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:55,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:55,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:55,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:55,774:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2023-11-23 14:23:55,774:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:55,774:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:23:55,774:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:23:55,774:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:23:55,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:56,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:56,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:56,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:56,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:56,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:56,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:56,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:56,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:56,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:56,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.
2023-11-23 14:23:57,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:57,206:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:23:57,206:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:23:57,206:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:23:57,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:57,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:58,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:58,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:58,614:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2023-11-23 14:23:58,614:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:23:58,614:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:23:58,615:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:23:58,615:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:23:58,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:58,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:58,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:58,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:58,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:58,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:59,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:59,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:59,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:59,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:59,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:23:59,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:00,011:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
2023-11-23 14:24:00,011:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:00,011:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:24:00,011:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:24:00,012:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:24:00,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:00,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:00,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:00,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:00,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:00,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:00,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:00,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:00,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:00,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,386:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2023-11-23 14:24:01,386:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:01,386:INFO:[LightGBM] [Info] Total Bins 2260
2023-11-23 14:24:01,386:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:24:01,386:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:24:01,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:01,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:02,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:02,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:02,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:02,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2023-11-23 14:24:02,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:02,805:INFO:[LightGBM] [Info] Total Bins 1805
2023-11-23 14:24:02,805:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:24:02,805:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:24:02,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:03,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:03,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:03,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:03,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:03,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:03,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:03,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:03,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:03,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:03,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,142:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2023-11-23 14:24:04,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:04,142:INFO:[LightGBM] [Info] Total Bins 1350
2023-11-23 14:24:04,142:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:24:04,143:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:24:04,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:04,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2023-11-23 14:24:05,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:05,450:INFO:[LightGBM] [Info] Total Bins 895
2023-11-23 14:24:05,451:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:24:05,451:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:24:05,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:05,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:06,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:06,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:06,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:06,721:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.
2023-11-23 14:24:06,721:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:06,721:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:24:06,721:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:24:06,722:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:06,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:06,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:07,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:07,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:07,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:07,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:07,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:07,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:07,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:07,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:07,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,128:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
2023-11-23 14:24:08,128:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:08,128:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:24:08,129:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:24:08,129:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:08,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:08,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:09,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:09,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:09,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2023-11-23 14:24:09,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:09,536:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:24:09,536:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:24:09,537:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:09,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:09,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:09,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:09,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:09,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:10,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:10,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:10,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:10,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:10,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:10,934:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
2023-11-23 14:24:10,934:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:10,934:INFO:[LightGBM] [Info] Total Bins 3214
2023-11-23 14:24:10,934:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:24:10,934:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:10,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:11,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:11,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:11,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:11,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:11,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:11,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:11,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:11,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:11,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:11,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,323:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2023-11-23 14:24:12,323:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:12,323:INFO:[LightGBM] [Info] Total Bins 3212
2023-11-23 14:24:12,323:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:24:12,323:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:12,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:12,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:13,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:13,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:13,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2023-11-23 14:24:13,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:13,724:INFO:[LightGBM] [Info] Total Bins 2757
2023-11-23 14:24:13,725:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:24:13,725:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:13,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:13,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:14,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:14,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:14,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:14,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:14,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:14,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:14,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:14,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:14,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,138:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.
2023-11-23 14:24:15,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:15,139:INFO:[LightGBM] [Info] Total Bins 2302
2023-11-23 14:24:15,139:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:24:15,139:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:15,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:15,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:16,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:16,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:16,514:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2023-11-23 14:24:16,514:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:16,514:INFO:[LightGBM] [Info] Total Bins 2251
2023-11-23 14:24:16,514:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:24:16,514:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:16,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:16,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:16,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:16,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:16,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:16,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:17,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:17,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:17,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:17,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:17,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:17,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:17,912:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2023-11-23 14:24:17,912:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:17,912:INFO:[LightGBM] [Info] Total Bins 1796
2023-11-23 14:24:17,912:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:24:17,912:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:17,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:18,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:18,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:18,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:18,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:18,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:18,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:18,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:18,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:18,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:18,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,259:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2023-11-23 14:24:19,260:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:19,260:INFO:[LightGBM] [Info] Total Bins 1341
2023-11-23 14:24:19,260:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:24:19,260:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:19,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:19,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:20,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:20,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:20,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2023-11-23 14:24:20,652:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:20,653:INFO:[LightGBM] [Info] Total Bins 886
2023-11-23 14:24:20,653:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:24:20,653:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:24:20,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:20,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:20,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:20,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:20,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:20,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:21,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:21,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:21,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:21,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:21,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,102:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000591 seconds.
2023-11-23 14:24:22,102:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:22,102:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:24:22,102:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:24:22,103:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:22,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:22,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:23,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:23,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:23,644:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000631 seconds.
2023-11-23 14:24:23,644:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:23,644:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:24:23,644:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:24:23,644:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:23,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:23,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:23,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:23,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:24,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:24,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:24,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:24,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:24,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:24,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:24,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,137:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000490 seconds.
2023-11-23 14:24:25,138:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:25,138:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:24:25,138:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:24:25,138:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:25,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:25,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:26,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:26,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:26,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000558 seconds.
2023-11-23 14:24:26,653:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:26,653:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:24:26,653:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:24:26,653:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:26,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:26,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:26,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:26,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:27,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:27,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:27,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:27,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:27,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:27,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:27,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,132:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.
2023-11-23 14:24:28,132:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:28,132:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:24:28,132:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:24:28,133:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:28,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:28,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:29,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:29,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:29,610:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2023-11-23 14:24:29,610:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:29,610:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:24:29,610:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:24:29,610:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:29,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:29,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:29,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:29,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:29,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:30,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:30,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:30,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:30,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:30,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:30,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:31,003:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2023-11-23 14:24:31,003:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:31,003:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:24:31,003:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:24:31,004:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:31,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:31,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:31,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:31,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:31,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:31,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:31,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:31,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:31,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:31,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:32,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:32,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:32,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.
2023-11-23 14:24:32,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:32,392:INFO:[LightGBM] [Info] Total Bins 2254
2023-11-23 14:24:32,392:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:24:32,392:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:32,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:32,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:32,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:32,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:32,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:32,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:32,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:33,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:33,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:33,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:33,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:33,801:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000739 seconds.
2023-11-23 14:24:33,801:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:33,802:INFO:[LightGBM] [Info] Total Bins 1799
2023-11-23 14:24:33,802:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:24:33,802:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:33,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:34,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:34,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:34,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:34,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:34,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:34,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:34,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:34,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:34,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:34,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,209:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2023-11-23 14:24:35,209:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:35,210:INFO:[LightGBM] [Info] Total Bins 1344
2023-11-23 14:24:35,210:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:24:35,210:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:35,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:36,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:36,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:36,525:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2023-11-23 14:24:36,525:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:36,525:INFO:[LightGBM] [Info] Total Bins 889
2023-11-23 14:24:36,525:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:24:36,525:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:24:36,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:36,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:36,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:36,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:36,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:36,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:36,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:36,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:37,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:37,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:37,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:37,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:37,801:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000557 seconds.
2023-11-23 14:24:37,802:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:37,802:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:24:37,802:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:24:37,802:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:37,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:38,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:38,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:38,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:38,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:38,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:38,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:38,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:38,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:38,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:38,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2023-11-23 14:24:39,277:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:39,277:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:24:39,277:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:24:39,277:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:39,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:39,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:40,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:40,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:40,700:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2023-11-23 14:24:40,700:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:40,700:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:24:40,700:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:24:40,700:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:40,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:40,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:41,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:41,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:41,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:41,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:41,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:41,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:41,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:41,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:41,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,158:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003680 seconds.
2023-11-23 14:24:42,158:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:42,159:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:24:42,160:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:24:42,165:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:42,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:42,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:43,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:43,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:43,637:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.
2023-11-23 14:24:43,637:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:43,637:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:24:43,637:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:24:43,637:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:43,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:43,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:43,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:43,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:43,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:43,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:44,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:44,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:44,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:44,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:44,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,093:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2023-11-23 14:24:45,093:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:45,093:INFO:[LightGBM] [Info] Total Bins 2762
2023-11-23 14:24:45,093:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:24:45,093:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:45,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:45,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:46,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:46,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:46,473:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
2023-11-23 14:24:46,473:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:46,473:INFO:[LightGBM] [Info] Total Bins 2307
2023-11-23 14:24:46,473:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:24:46,473:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:46,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:46,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:46,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:46,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:46,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:46,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:46,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:47,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:47,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:47,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:47,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:47,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
2023-11-23 14:24:47,809:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:47,809:INFO:[LightGBM] [Info] Total Bins 2256
2023-11-23 14:24:47,809:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:24:47,809:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:48,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:48,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:48,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:48,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:48,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:48,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:48,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:48,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:48,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:48,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,153:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2023-11-23 14:24:49,153:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:49,153:INFO:[LightGBM] [Info] Total Bins 1801
2023-11-23 14:24:49,153:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:24:49,154:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:49,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:49,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:50,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:50,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:50,482:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2023-11-23 14:24:50,482:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:50,482:INFO:[LightGBM] [Info] Total Bins 1346
2023-11-23 14:24:50,482:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:24:50,482:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:50,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:50,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:50,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:50,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:50,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:50,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:50,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:50,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:51,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:51,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:51,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:51,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:51,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2023-11-23 14:24:51,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:51,780:INFO:[LightGBM] [Info] Total Bins 891
2023-11-23 14:24:51,781:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:24:51,781:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:24:51,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:52,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:53,033:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
2023-11-23 14:24:53,033:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:53,033:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:24:53,033:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:24:53,033:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:24:53,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:53,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:53,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:53,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:53,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:53,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:53,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:53,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:53,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:53,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:54,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:54,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:54,433:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2023-11-23 14:24:54,434:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:54,434:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:24:54,434:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:24:54,434:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:24:54,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:54,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:54,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:54,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:54,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:54,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:54,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:54,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:55,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:55,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:55,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:55,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:55,840:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.
2023-11-23 14:24:55,840:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:24:55,840:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:24:55,840:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:24:55,840:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:24:55,841:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:24:55,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:56,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:56,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:56,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:56,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:56,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:56,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:56,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:56,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:57,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:57,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:57,455:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.
2023-11-23 14:24:57,455:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:57,455:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:24:57,455:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:24:57,455:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:24:57,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:57,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:57,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:57,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:57,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:57,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:57,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:57,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:58,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:58,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:58,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:58,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:58,861:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2023-11-23 14:24:58,861:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:24:58,861:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:24:58,861:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:24:58,861:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:24:58,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:59,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:59,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:59,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:59,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:59,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:59,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:59,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:59,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:59,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:24:59,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,274:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-11-23 14:25:00,274:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:00,274:INFO:[LightGBM] [Info] Total Bins 2764
2023-11-23 14:25:00,274:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:25:00,274:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:25:00,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:00,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:01,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:01,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:01,655:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2023-11-23 14:25:01,655:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:01,655:INFO:[LightGBM] [Info] Total Bins 2309
2023-11-23 14:25:01,655:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:25:01,655:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:25:01,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:01,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:01,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:01,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:01,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:01,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:02,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:02,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:02,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:02,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:02,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:02,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:03,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2023-11-23 14:25:03,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:03,034:INFO:[LightGBM] [Info] Total Bins 2258
2023-11-23 14:25:03,034:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:25:03,034:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:25:03,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:03,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:03,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:03,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:03,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:03,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:03,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:03,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:03,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:03,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:04,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:04,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:04,421:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
2023-11-23 14:25:04,421:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:04,421:INFO:[LightGBM] [Info] Total Bins 1803
2023-11-23 14:25:04,421:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:25:04,421:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:25:04,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:04,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:04,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:04,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:04,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:04,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:04,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:04,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:05,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:05,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:05,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:05,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:05,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2023-11-23 14:25:05,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:05,853:INFO:[LightGBM] [Info] Total Bins 1348
2023-11-23 14:25:05,854:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:25:05,854:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:25:05,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:06,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:06,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:06,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:06,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:06,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:06,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:06,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:06,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:06,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:06,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,161:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2023-11-23 14:25:07,161:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:07,161:INFO:[LightGBM] [Info] Total Bins 893
2023-11-23 14:25:07,161:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 2
2023-11-23 14:25:07,161:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:25:07,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:07,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:08,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:08,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:08,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
2023-11-23 14:25:08,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:08,446:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:25:08,446:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:25:08,446:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:25:08,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:08,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:08,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:08,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:08,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:08,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:08,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:08,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:09,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:09,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:09,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:09,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:09,874:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
2023-11-23 14:25:09,874:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:09,874:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:25:09,874:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:25:09,875:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:25:09,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:10,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:10,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:10,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:10,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:10,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:10,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:10,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:10,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:10,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:10,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,292:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
2023-11-23 14:25:11,292:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:11,292:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:25:11,292:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:25:11,293:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:25:11,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:11,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:12,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:12,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:12,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2023-11-23 14:25:12,743:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:12,743:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:25:12,743:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:25:12,743:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:25:12,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:13,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:13,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:13,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:13,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:13,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:13,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:13,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:13,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:13,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:13,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,160:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2023-11-23 14:25:14,160:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:14,160:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:25:14,160:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:25:14,160:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:25:14,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:14,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:15,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:15,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:15,622:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2023-11-23 14:25:15,622:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:15,622:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:25:15,622:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:25:15,623:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:25:15,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:15,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:15,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:15,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:15,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:15,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:16,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:16,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:16,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:16,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:16,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,119:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.
2023-11-23 14:25:17,119:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:17,119:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:25:17,120:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:25:17,120:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:25:17,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:17,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:18,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:18,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:18,521:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000546 seconds.
2023-11-23 14:25:18,521:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:18,521:INFO:[LightGBM] [Info] Total Bins 2260
2023-11-23 14:25:18,521:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 5
2023-11-23 14:25:18,521:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:25:18,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:18,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:18,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:18,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:18,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:18,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:19,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:19,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:19,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:19,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:19,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:19,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:20,057:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2023-11-23 14:25:20,058:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:20,058:INFO:[LightGBM] [Info] Total Bins 1805
2023-11-23 14:25:20,058:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 4
2023-11-23 14:25:20,058:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:25:20,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:20,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:20,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:20,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:20,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:20,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:20,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:20,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:20,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:20,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:21,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:21,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:21,539:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2023-11-23 14:25:21,539:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:21,539:INFO:[LightGBM] [Info] Total Bins 1350
2023-11-23 14:25:21,539:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 3
2023-11-23 14:25:21,539:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:25:21,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:21,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:21,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:21,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:21,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:21,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:22,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:22,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:22,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:22,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:22,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:22,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:22,892:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000549 seconds.
2023-11-23 14:25:22,892:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:22,892:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:25:22,892:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:25:22,893:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:25:22,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:23,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:23,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:23,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:23,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:23,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:23,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:23,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:23,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:23,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:23,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:24,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:24,333:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000299 seconds.
2023-11-23 14:25:24,334:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:24,334:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:25:24,334:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:25:24,334:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:25:24,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:24,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:24,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:24,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:24,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:24,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:24,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:24,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:24,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:25,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:25,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:25,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:25,798:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2023-11-23 14:25:25,798:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:25,798:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:25:25,798:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:25:25,799:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:25:25,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:26,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:26,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:26,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:26,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:26,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:26,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:26,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:26,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:26,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:26,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,214:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.
2023-11-23 14:25:27,214:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:27,214:INFO:[LightGBM] [Info] Total Bins 3213
2023-11-23 14:25:27,214:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:25:27,215:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:25:27,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:27,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:28,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:28,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:28,626:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2023-11-23 14:25:28,626:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:28,626:INFO:[LightGBM] [Info] Total Bins 3211
2023-11-23 14:25:28,626:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:25:28,626:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:25:28,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:28,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:28,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:28,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:28,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:28,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:29,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:29,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:29,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:29,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:29,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:29,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:30,068:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2023-11-23 14:25:30,068:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:30,068:INFO:[LightGBM] [Info] Total Bins 2756
2023-11-23 14:25:30,068:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:25:30,068:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:25:30,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:30,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:30,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:30,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:30,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:30,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:30,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:30,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:30,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:30,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:31,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:31,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:31,469:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2023-11-23 14:25:31,469:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:31,469:INFO:[LightGBM] [Info] Total Bins 2705
2023-11-23 14:25:31,469:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:25:31,470:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:25:31,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:31,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:31,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:31,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:31,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:31,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:31,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:31,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:32,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:32,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:32,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:32,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:32,825:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.
2023-11-23 14:25:32,825:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:32,825:INFO:[LightGBM] [Info] Total Bins 2250
2023-11-23 14:25:32,825:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 5
2023-11-23 14:25:32,825:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:25:32,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:33,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:33,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:33,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:33,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:33,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:33,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:33,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:33,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:33,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,164:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2023-11-23 14:25:34,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:34,164:INFO:[LightGBM] [Info] Total Bins 1795
2023-11-23 14:25:34,164:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 4
2023-11-23 14:25:34,164:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:25:34,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:34,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:35,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:35,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:35,493:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.
2023-11-23 14:25:35,493:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:35,493:INFO:[LightGBM] [Info] Total Bins 1340
2023-11-23 14:25:35,494:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 3
2023-11-23 14:25:35,494:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:25:35,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:35,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:35,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:35,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:35,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:36,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:36,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:36,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:36,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:36,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:36,897:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.
2023-11-23 14:25:36,897:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:36,897:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:25:36,897:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:25:36,897:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:25:36,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:37,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:37,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:37,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:37,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:37,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:37,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:37,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:37,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:37,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:38,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:38,333:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000205 seconds.
2023-11-23 14:25:38,334:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:25:38,334:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:25:38,334:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:25:38,334:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:25:38,334:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:25:38,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:38,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:38,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:38,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:38,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:38,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:38,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:38,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:39,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:39,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:39,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:39,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:40,044:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2023-11-23 14:25:40,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:40,044:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:25:40,044:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:25:40,045:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:25:40,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:40,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:40,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:40,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:40,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:40,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:40,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:40,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:40,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:41,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:41,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:41,519:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000569 seconds.
2023-11-23 14:25:41,519:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:41,519:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:25:41,519:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:25:41,519:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:25:41,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:41,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:41,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:41,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:41,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:41,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:42,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:42,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:42,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:42,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:42,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:42,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:42,949:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
2023-11-23 14:25:42,949:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:42,949:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:25:42,950:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:25:42,950:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:25:42,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:43,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:43,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:43,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:43,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:43,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:43,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:43,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:43,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:43,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2023-11-23 14:25:44,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:44,366:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:25:44,366:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:25:44,367:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:25:44,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:44,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:45,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:45,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:45,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:45,751:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2023-11-23 14:25:45,751:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:45,751:INFO:[LightGBM] [Info] Total Bins 2710
2023-11-23 14:25:45,751:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:25:45,751:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:25:45,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:46,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:46,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:46,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:46,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:46,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:46,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:46,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:46,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:46,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:46,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,104:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2023-11-23 14:25:47,104:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:47,104:INFO:[LightGBM] [Info] Total Bins 2255
2023-11-23 14:25:47,104:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:25:47,104:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:25:47,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:47,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:48,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:48,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:48,462:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
2023-11-23 14:25:48,462:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:48,462:INFO:[LightGBM] [Info] Total Bins 1800
2023-11-23 14:25:48,463:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:25:48,463:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:25:48,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:48,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:48,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:48,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:48,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:48,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:48,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:48,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:49,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:49,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:49,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:49,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:49,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
2023-11-23 14:25:49,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:49,785:INFO:[LightGBM] [Info] Total Bins 1345
2023-11-23 14:25:49,785:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:25:49,785:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:25:49,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:50,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:51,078:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2023-11-23 14:25:51,078:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:51,078:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:25:51,078:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:25:51,078:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:25:51,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:51,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:51,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:51,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:51,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:51,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:51,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:51,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:51,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:51,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:52,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:52,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:52,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2023-11-23 14:25:52,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:52,488:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:25:52,488:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:25:52,488:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:25:52,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:52,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:52,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:52,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:52,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:52,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:53,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:53,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:53,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:53,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:53,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:53,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:53,893:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.
2023-11-23 14:25:53,893:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:53,893:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:25:53,893:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:25:53,893:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:25:53,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:54,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:54,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:54,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:54,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:54,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:54,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:54,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:54,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:54,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,297:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2023-11-23 14:25:55,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:55,297:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:25:55,297:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:25:55,297:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:25:55,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:55,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:56,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:56,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:56,718:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.
2023-11-23 14:25:56,718:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:56,718:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:25:56,718:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:25:56,718:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:25:56,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:56,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:57,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:57,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:57,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:57,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:57,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:57,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:57,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:57,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,141:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.
2023-11-23 14:25:58,142:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:58,142:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:25:58,142:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:25:58,142:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:25:58,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:58,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:59,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:59,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:59,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.
2023-11-23 14:25:59,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:25:59,537:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:25:59,537:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:25:59,538:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:25:59,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:59,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:59,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:59,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:59,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:25:59,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:00,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:00,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:00,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:00,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:00,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:00,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:00,898:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2023-11-23 14:26:00,898:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:00,898:INFO:[LightGBM] [Info] Total Bins 2254
2023-11-23 14:26:00,898:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:26:00,898:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:26:00,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:01,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:01,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:01,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:01,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:01,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:01,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:01,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:01,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:01,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:01,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,257:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000512 seconds.
2023-11-23 14:26:02,257:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:02,257:INFO:[LightGBM] [Info] Total Bins 1799
2023-11-23 14:26:02,258:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:26:02,258:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:26:02,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:02,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:03,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:03,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:03,593:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.
2023-11-23 14:26:03,593:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:03,593:INFO:[LightGBM] [Info] Total Bins 1344
2023-11-23 14:26:03,593:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:26:03,593:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:26:03,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:03,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:03,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:03,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:03,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:03,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:04,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:04,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:04,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:04,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:04,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:04,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:04,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000216 seconds.
2023-11-23 14:26:04,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:26:04,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:26:04,889:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:26:04,889:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:26:04,889:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:26:04,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:05,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:05,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:05,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:05,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:05,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:05,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:05,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:06,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:06,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:06,509:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.
2023-11-23 14:26:06,509:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:06,509:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:26:06,510:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:26:06,510:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:26:06,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:06,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:06,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:06,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:06,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:06,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:07,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:07,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:07,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:07,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:07,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:07,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:07,917:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2023-11-23 14:26:07,917:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:07,917:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:26:07,917:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:26:07,918:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:26:07,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:08,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:08,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:08,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:08,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:08,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:08,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:08,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:08,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:08,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:08,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,317:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-23 14:26:09,317:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:09,317:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:26:09,318:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:26:09,318:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:26:09,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:09,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:10,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:10,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:10,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.
2023-11-23 14:26:10,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:10,717:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:26:10,717:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:26:10,718:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:26:10,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:10,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:11,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:11,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:11,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:11,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:11,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:11,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:11,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:11,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:11,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2023-11-23 14:26:12,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:12,157:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:26:12,157:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:26:12,157:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:26:12,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:12,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:13,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:13,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:13,537:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2023-11-23 14:26:13,537:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:13,537:INFO:[LightGBM] [Info] Total Bins 2306
2023-11-23 14:26:13,537:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:26:13,537:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:26:13,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:13,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:13,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:13,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:13,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:13,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:14,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:14,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:14,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:14,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:14,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:14,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:14,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2023-11-23 14:26:14,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:14,883:INFO:[LightGBM] [Info] Total Bins 2255
2023-11-23 14:26:14,883:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:26:14,883:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:26:14,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:15,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:15,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:15,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:15,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:15,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:15,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:15,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:15,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:15,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:15,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,237:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2023-11-23 14:26:16,237:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:16,237:INFO:[LightGBM] [Info] Total Bins 1800
2023-11-23 14:26:16,237:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:26:16,237:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:26:16,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:16,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:17,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:17,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:17,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2023-11-23 14:26:17,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:17,571:INFO:[LightGBM] [Info] Total Bins 1345
2023-11-23 14:26:17,571:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:26:17,571:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:26:17,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:17,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:17,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:17,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:17,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:17,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:18,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:18,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:18,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:18,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:18,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:18,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:18,874:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2023-11-23 14:26:18,874:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:18,875:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:26:18,875:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:26:18,875:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:26:18,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:19,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:19,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:19,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:19,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:19,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:19,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:19,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:19,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:19,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:19,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,281:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2023-11-23 14:26:20,282:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:20,282:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:26:20,282:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:26:20,282:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:26:20,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:20,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:21,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:21,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:21,682:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2023-11-23 14:26:21,682:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:21,682:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:26:21,682:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:26:21,682:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:26:21,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:21,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:21,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:22,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:22,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:22,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:22,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:22,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:22,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:22,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:22,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:22,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:23,081:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2023-11-23 14:26:23,081:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:23,081:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:26:23,081:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:26:23,081:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:26:23,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:23,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:23,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:23,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:23,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:23,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:23,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:23,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:23,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:23,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:24,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:24,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:24,481:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.
2023-11-23 14:26:24,481:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:24,482:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:26:24,482:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:26:24,482:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:26:24,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:24,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:24,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:24,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:24,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:24,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:25,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:25,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:25,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:25,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:25,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:25,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:25,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2023-11-23 14:26:25,884:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:25,884:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:26:25,884:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:26:25,884:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:26:25,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:26,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:26,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:26,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:26,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:26,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:26,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:26,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:26,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:26,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:26,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,260:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2023-11-23 14:26:27,260:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:27,260:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:26:27,260:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:26:27,260:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:26:27,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:27,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:28,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:28,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:28,607:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2023-11-23 14:26:28,607:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:28,607:INFO:[LightGBM] [Info] Total Bins 2260
2023-11-23 14:26:28,607:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:26:28,607:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:26:28,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:28,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:28,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:28,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:28,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:28,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:29,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:29,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:29,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:29,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:29,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:29,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:29,963:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2023-11-23 14:26:29,963:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:29,963:INFO:[LightGBM] [Info] Total Bins 1805
2023-11-23 14:26:29,963:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:26:29,963:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:26:29,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:30,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:30,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:30,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:30,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:30,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:30,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:30,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:30,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:30,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,357:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000408 seconds.
2023-11-23 14:26:31,358:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:31,358:INFO:[LightGBM] [Info] Total Bins 1350
2023-11-23 14:26:31,358:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:26:31,358:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:26:31,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:31,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:32,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:32,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:32,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2023-11-23 14:26:32,652:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:32,652:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:26:32,652:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:26:32,652:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:26:32,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:32,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:32,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:32,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:32,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:32,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:33,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:33,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:33,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:33,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:33,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:33,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:34,053:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000233 seconds.
2023-11-23 14:26:34,054:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:26:34,054:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:26:34,054:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:26:34,054:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:26:34,054:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:26:34,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:34,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:34,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:34,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:34,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:34,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:34,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:34,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:34,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:34,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:35,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:35,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:35,661:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2023-11-23 14:26:35,661:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:35,661:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:26:35,661:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:26:35,661:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:26:35,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:35,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:35,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:35,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:36,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:36,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:36,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:36,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:36,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:36,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:36,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:36,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:37,060:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.
2023-11-23 14:26:37,060:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:37,061:INFO:[LightGBM] [Info] Total Bins 3214
2023-11-23 14:26:37,061:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:26:37,061:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:26:37,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:37,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:37,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:37,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:37,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:37,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:37,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:37,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:37,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:37,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:38,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:38,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:38,459:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.
2023-11-23 14:26:38,459:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:38,459:INFO:[LightGBM] [Info] Total Bins 3212
2023-11-23 14:26:38,460:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:26:38,460:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:26:38,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:38,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:38,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:38,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:38,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:38,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:38,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:38,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:39,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:39,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:39,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:39,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:39,881:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2023-11-23 14:26:39,881:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:39,881:INFO:[LightGBM] [Info] Total Bins 2757
2023-11-23 14:26:39,881:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:26:39,881:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:26:39,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:40,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:40,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:40,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:40,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:40,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:40,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000263 seconds.
2023-11-23 14:26:41,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:41,254:INFO:[LightGBM] [Info] Total Bins 2302
2023-11-23 14:26:41,254:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:26:41,255:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:26:41,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:41,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:42,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:42,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:42,599:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
2023-11-23 14:26:42,599:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:42,599:INFO:[LightGBM] [Info] Total Bins 2251
2023-11-23 14:26:42,599:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:26:42,600:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:26:42,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:42,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:42,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:42,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:42,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:42,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:43,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:43,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:43,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:43,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:43,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:43,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:43,951:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2023-11-23 14:26:43,951:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:43,951:INFO:[LightGBM] [Info] Total Bins 1796
2023-11-23 14:26:43,951:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:26:43,951:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:26:43,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:44,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:44,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:44,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:44,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:44,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:44,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:44,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:44,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:44,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:44,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
2023-11-23 14:26:45,279:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:45,279:INFO:[LightGBM] [Info] Total Bins 1341
2023-11-23 14:26:45,279:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:26:45,279:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:26:45,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:45,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:46,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:46,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:46,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.
2023-11-23 14:26:46,592:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:46,592:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:26:46,592:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:26:46,593:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:26:46,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:46,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:46,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:46,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:47,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:47,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:47,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:47,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:48,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
2023-11-23 14:26:48,005:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:48,005:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:26:48,005:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:26:48,005:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:26:48,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:48,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:48,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:48,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:48,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:48,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:48,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:48,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:48,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:48,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:49,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:49,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:49,418:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
2023-11-23 14:26:49,418:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:49,418:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:26:49,418:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:26:49,418:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:26:49,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:49,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:49,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:49,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:49,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:49,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:49,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:49,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:50,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:50,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:50,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:50,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:50,825:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2023-11-23 14:26:50,825:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:50,825:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:26:50,826:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:26:50,826:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:26:50,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:51,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:51,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:51,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:51,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:51,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:51,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:51,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:51,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:51,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:51,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,223:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2023-11-23 14:26:52,223:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:52,223:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:26:52,223:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:26:52,223:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:26:52,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:52,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:53,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:53,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:53,625:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2023-11-23 14:26:53,625:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:53,625:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:26:53,625:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:26:53,625:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:26:53,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:53,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:53,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:53,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:53,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:53,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:54,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:54,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:54,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:54,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:54,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:54,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:55,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2023-11-23 14:26:55,005:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:55,005:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:26:55,005:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:26:55,005:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:26:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:55,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:55,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:55,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:55,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:55,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:55,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:55,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:55,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:55,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,348:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
2023-11-23 14:26:56,349:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:56,349:INFO:[LightGBM] [Info] Total Bins 2254
2023-11-23 14:26:56,349:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:26:56,349:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:26:56,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:56,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:57,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:57,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:57,699:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.
2023-11-23 14:26:57,699:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:57,699:INFO:[LightGBM] [Info] Total Bins 1799
2023-11-23 14:26:57,699:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:26:57,700:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:26:57,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:57,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:57,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:58,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:58,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:58,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:58,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:58,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:58,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:58,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:58,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:58,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,019:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2023-11-23 14:26:59,019:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:26:59,019:INFO:[LightGBM] [Info] Total Bins 1344
2023-11-23 14:26:59,019:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:26:59,019:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:26:59,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:26:59,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,331:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.
2023-11-23 14:27:00,331:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:00,331:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:27:00,332:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:27:00,332:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:27:00,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:00,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:01,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:01,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:01,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2023-11-23 14:27:01,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:01,735:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:27:01,735:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:27:01,735:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:27:01,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:01,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:02,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:02,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:02,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:02,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:02,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:02,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:02,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:02,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:02,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,137:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
2023-11-23 14:27:03,138:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:03,138:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:27:03,138:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:27:03,138:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:27:03,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:03,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:04,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:04,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:04,565:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2023-11-23 14:27:04,565:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:04,565:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:27:04,566:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:27:04,566:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:27:04,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:04,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:04,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:04,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:04,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:04,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:05,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:05,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:05,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:05,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:05,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:05,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:05,969:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2023-11-23 14:27:05,969:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:05,969:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:27:05,969:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:27:05,969:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:27:06,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:06,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:06,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:06,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:06,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:06,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:06,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:06,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:06,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:06,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.
2023-11-23 14:27:07,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:07,369:INFO:[LightGBM] [Info] Total Bins 2762
2023-11-23 14:27:07,369:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:27:07,370:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:27:07,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:07,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:08,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:08,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:08,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:08,744:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.
2023-11-23 14:27:08,744:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:08,744:INFO:[LightGBM] [Info] Total Bins 2307
2023-11-23 14:27:08,744:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:27:08,744:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:27:08,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:08,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:09,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:09,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:09,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:09,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:09,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:09,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:09,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:09,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:09,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,086:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
2023-11-23 14:27:10,086:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:10,086:INFO:[LightGBM] [Info] Total Bins 2256
2023-11-23 14:27:10,086:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:27:10,086:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:27:10,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:10,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:11,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:11,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:11,432:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2023-11-23 14:27:11,432:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:11,432:INFO:[LightGBM] [Info] Total Bins 1801
2023-11-23 14:27:11,432:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:27:11,433:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:27:11,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:11,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:11,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:11,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:11,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:11,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:11,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:11,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:12,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:12,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:12,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:12,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:12,763:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.
2023-11-23 14:27:12,763:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:12,763:INFO:[LightGBM] [Info] Total Bins 1346
2023-11-23 14:27:12,763:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:27:12,763:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:27:12,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:13,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:14,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2023-11-23 14:27:14,071:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:14,071:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:27:14,071:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:27:14,071:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:27:14,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:14,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:14,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:14,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:14,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:14,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:14,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:14,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:14,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:15,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:15,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:15,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-11-23 14:27:15,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:15,479:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:27:15,480:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:27:15,480:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:27:15,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:15,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:15,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:15,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:15,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:15,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:15,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:16,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:16,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:16,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:16,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:16,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:16,884:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
2023-11-23 14:27:16,884:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:16,885:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:27:16,885:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:27:16,885:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:27:16,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:17,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:17,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:17,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:17,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:17,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:17,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:17,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:17,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:17,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:17,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,286:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000536 seconds.
2023-11-23 14:27:18,287:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:18,287:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:27:18,287:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:27:18,287:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:27:18,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:18,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:19,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:19,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:19,692:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000534 seconds.
2023-11-23 14:27:19,692:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:19,692:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:27:19,692:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:27:19,693:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:27:19,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:19,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:20,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:20,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:20,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:20,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:20,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:20,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:20,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:20,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:20,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,109:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2023-11-23 14:27:21,109:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:21,109:INFO:[LightGBM] [Info] Total Bins 2764
2023-11-23 14:27:21,109:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:27:21,109:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:27:21,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:21,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:22,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:22,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:22,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2023-11-23 14:27:22,490:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:22,490:INFO:[LightGBM] [Info] Total Bins 2309
2023-11-23 14:27:22,491:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:27:22,491:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:27:22,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:22,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:22,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:22,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:22,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:22,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:23,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:23,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:23,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:23,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:23,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:23,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:23,919:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2023-11-23 14:27:23,919:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:23,919:INFO:[LightGBM] [Info] Total Bins 2258
2023-11-23 14:27:23,919:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:27:23,919:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:27:23,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:24,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:24,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:24,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:24,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:24,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:24,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:24,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:24,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:24,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:24,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2023-11-23 14:27:25,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:25,341:INFO:[LightGBM] [Info] Total Bins 1803
2023-11-23 14:27:25,341:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:27:25,342:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:27:25,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:25,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:26,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:26,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:26,691:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2023-11-23 14:27:26,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:26,691:INFO:[LightGBM] [Info] Total Bins 1348
2023-11-23 14:27:26,692:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 3
2023-11-23 14:27:26,692:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:27:26,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:26,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:26,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:26,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:27,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:27,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:27,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:27,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:27,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:27,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:27,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:27,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:28,038:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000602 seconds.
2023-11-23 14:27:28,038:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:28,039:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:27:28,039:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:27:28,039:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:27:28,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:28,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:28,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:28,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:28,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:28,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:28,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:28,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:28,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:28,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:29,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:29,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:29,556:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000562 seconds.
2023-11-23 14:27:29,556:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:29,556:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:27:29,556:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:27:29,557:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:27:29,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:29,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:29,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:29,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:29,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:29,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:30,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:30,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:30,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:30,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:30,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:30,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:30,967:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000522 seconds.
2023-11-23 14:27:30,967:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:30,967:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:27:30,967:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:27:30,967:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:27:31,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:31,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:31,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:31,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:31,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:31,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:31,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:31,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:31,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:31,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,366:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.
2023-11-23 14:27:32,366:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:32,366:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:27:32,366:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:27:32,366:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:27:32,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:32,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:33,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:33,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:33,767:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2023-11-23 14:27:33,767:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:33,767:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:27:33,767:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:27:33,767:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:27:33,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:34,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:34,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:34,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:34,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:34,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:34,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:34,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:34,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:34,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:34,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,168:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2023-11-23 14:27:35,168:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:35,168:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:27:35,169:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:27:35,169:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:27:35,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:35,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:36,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:36,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:36,547:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2023-11-23 14:27:36,547:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:36,547:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:27:36,547:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:27:36,547:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:27:36,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:36,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:36,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:36,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:36,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:36,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:37,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:37,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:37,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:37,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:37,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:37,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:37,894:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
2023-11-23 14:27:37,894:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:37,894:INFO:[LightGBM] [Info] Total Bins 2260
2023-11-23 14:27:37,895:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 5
2023-11-23 14:27:37,895:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:27:37,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:38,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:38,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:38,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:38,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:38,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:38,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:38,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:38,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:38,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:38,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,247:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-11-23 14:27:39,247:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:39,247:INFO:[LightGBM] [Info] Total Bins 1805
2023-11-23 14:27:39,247:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 4
2023-11-23 14:27:39,248:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:27:39,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:40,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:40,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:40,573:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2023-11-23 14:27:40,573:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:40,573:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:27:40,573:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:27:40,574:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:27:40,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:40,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:40,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:40,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:41,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:41,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:41,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:41,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:41,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:41,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:41,982:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2023-11-23 14:27:41,982:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:41,982:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:27:41,982:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:27:41,983:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:27:42,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:42,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:42,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:42,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:42,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:42,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:42,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:42,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:42,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:42,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,383:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
2023-11-23 14:27:43,383:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:43,383:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:27:43,383:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:27:43,383:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:27:43,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:43,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:44,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:44,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:44,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:44,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000556 seconds.
2023-11-23 14:27:44,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:44,780:INFO:[LightGBM] [Info] Total Bins 3213
2023-11-23 14:27:44,780:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:27:44,780:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:27:44,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:45,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:45,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:45,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:45,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:45,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:45,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:45,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:45,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:45,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,173:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.
2023-11-23 14:27:46,173:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:46,173:INFO:[LightGBM] [Info] Total Bins 3211
2023-11-23 14:27:46,173:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:27:46,173:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:27:46,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:46,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:47,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:47,573:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2023-11-23 14:27:47,573:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:47,574:INFO:[LightGBM] [Info] Total Bins 2756
2023-11-23 14:27:47,574:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:27:47,574:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:27:47,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:47,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:47,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:47,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:47,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:47,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:48,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:48,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:48,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:48,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:48,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:48,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:48,947:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2023-11-23 14:27:48,947:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:48,947:INFO:[LightGBM] [Info] Total Bins 2705
2023-11-23 14:27:48,948:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:27:48,948:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:27:48,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:49,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:49,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:49,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:49,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:49,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:49,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:49,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:49,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:49,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:49,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,300:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000406 seconds.
2023-11-23 14:27:50,300:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:50,301:INFO:[LightGBM] [Info] Total Bins 2250
2023-11-23 14:27:50,301:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 5
2023-11-23 14:27:50,301:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:27:50,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:50,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:51,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:51,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:51,653:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.
2023-11-23 14:27:51,653:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:51,653:INFO:[LightGBM] [Info] Total Bins 1795
2023-11-23 14:27:51,653:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 4
2023-11-23 14:27:51,654:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:27:51,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:51,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:51,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:51,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:51,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:51,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:52,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:52,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:52,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:52,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:52,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:52,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:52,981:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.
2023-11-23 14:27:52,981:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:52,982:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:27:52,982:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:27:52,982:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:27:53,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:53,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:53,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:53,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:53,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:53,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:53,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:53,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:53,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:53,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,385:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.
2023-11-23 14:27:54,385:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:54,385:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:27:54,386:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:27:54,386:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:27:54,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:54,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:55,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:55,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:55,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:55,794:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
2023-11-23 14:27:55,794:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:55,794:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:27:55,794:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:27:55,794:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:27:55,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:56,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:56,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:56,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:56,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:56,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:56,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:56,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:56,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:56,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:56,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,199:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
2023-11-23 14:27:57,199:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:57,199:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:27:57,199:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:27:57,199:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:27:57,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:57,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:58,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:58,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:58,605:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
2023-11-23 14:27:58,605:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:27:58,605:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:27:58,605:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:27:58,605:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:27:58,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:58,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:58,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:58,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:58,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:58,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:59,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:59,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:59,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:59,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:59,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:27:59,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:00,052:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.
2023-11-23 14:28:00,052:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:00,052:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:28:00,052:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:28:00,053:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:28:00,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:00,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:00,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:00,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:00,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:00,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:00,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:00,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:00,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:00,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:01,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:01,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:01,431:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
2023-11-23 14:28:01,431:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:01,431:INFO:[LightGBM] [Info] Total Bins 2710
2023-11-23 14:28:01,432:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:28:01,432:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:28:01,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:01,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:01,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:01,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:01,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:01,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:01,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:01,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:02,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:02,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:02,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:02,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:02,782:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2023-11-23 14:28:02,782:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:02,782:INFO:[LightGBM] [Info] Total Bins 2255
2023-11-23 14:28:02,782:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:28:02,782:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:28:02,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:03,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:03,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:03,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:03,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:03,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:03,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:03,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:03,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:03,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:03,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,138:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2023-11-23 14:28:04,138:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:04,138:INFO:[LightGBM] [Info] Total Bins 1800
2023-11-23 14:28:04,138:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:28:04,138:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:28:04,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:04,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:05,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:05,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:05,466:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2023-11-23 14:28:05,466:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:05,466:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:28:05,466:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:28:05,466:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:28:05,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:05,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:05,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:05,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:05,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:05,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:05,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:05,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:06,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:06,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:06,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:06,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:06,875:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2023-11-23 14:28:06,875:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:06,875:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:28:06,875:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:28:06,876:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:28:06,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:07,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:07,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:07,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:07,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:07,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:07,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:07,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:07,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:07,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:07,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-11-23 14:28:08,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:08,284:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:28:08,284:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:28:08,284:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:28:08,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:08,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:09,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:09,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:09,733:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
2023-11-23 14:28:09,733:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:09,733:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:28:09,733:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:28:09,733:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:28:09,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:09,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:10,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:10,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:10,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:10,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:10,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:10,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:10,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:10,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:10,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,130:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000412 seconds.
2023-11-23 14:28:11,130:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:11,131:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:28:11,131:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:28:11,131:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:28:11,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:11,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:12,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:12,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:12,538:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2023-11-23 14:28:12,538:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:12,538:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:28:12,539:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:28:12,539:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:28:12,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:12,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:12,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:12,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:12,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:12,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:13,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:13,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:13,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:13,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:13,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:13,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:13,915:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2023-11-23 14:28:13,915:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:13,915:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:28:13,915:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:28:13,915:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:28:13,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:14,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:14,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:14,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:14,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:14,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:14,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:14,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:14,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:14,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:14,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,267:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
2023-11-23 14:28:15,267:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:15,267:INFO:[LightGBM] [Info] Total Bins 2254
2023-11-23 14:28:15,267:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:28:15,267:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:28:15,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:15,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:16,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:16,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:16,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2023-11-23 14:28:16,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:16,623:INFO:[LightGBM] [Info] Total Bins 1799
2023-11-23 14:28:16,623:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:28:16,623:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:28:16,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:16,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:16,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:16,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:16,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:16,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:17,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:17,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:17,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:17,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:17,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:17,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:17,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000210 seconds.
2023-11-23 14:28:17,957:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:28:17,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:28:17,957:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:28:17,957:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:28:17,957:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:28:17,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:18,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:18,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:18,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:18,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:18,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:18,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:18,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:18,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:18,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:19,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:19,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:19,562:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000478 seconds.
2023-11-23 14:28:19,562:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:19,562:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:28:19,562:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:28:19,562:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:28:19,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:19,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:19,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:19,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:19,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:19,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:20,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:20,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:20,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:20,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:20,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:20,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:20,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2023-11-23 14:28:20,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:20,970:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:28:20,970:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:28:20,970:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:28:21,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:21,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:21,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:21,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:21,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:21,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:21,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:21,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:21,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,372:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000435 seconds.
2023-11-23 14:28:22,372:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:22,372:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:28:22,373:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:28:22,373:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:28:22,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:22,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:23,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:23,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:23,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:23,771:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
2023-11-23 14:28:23,771:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:23,771:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:28:23,771:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:28:23,772:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:28:23,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:24,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:24,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:24,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:24,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:24,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:24,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:24,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:24,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:24,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:24,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,173:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.
2023-11-23 14:28:25,173:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:25,173:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:28:25,173:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:28:25,174:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:28:25,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:25,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:26,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:26,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:26,554:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2023-11-23 14:28:26,554:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:26,554:INFO:[LightGBM] [Info] Total Bins 2306
2023-11-23 14:28:26,554:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:28:26,554:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:28:26,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:26,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:26,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:26,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:26,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:26,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:27,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:27,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:27,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:27,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:27,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:27,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:27,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2023-11-23 14:28:27,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:27,903:INFO:[LightGBM] [Info] Total Bins 2255
2023-11-23 14:28:27,903:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:28:27,903:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:28:27,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:28,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:28,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:28,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:28,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:28,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:28,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:28,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:28,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:28,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:28,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,298:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2023-11-23 14:28:29,298:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:29,299:INFO:[LightGBM] [Info] Total Bins 1800
2023-11-23 14:28:29,299:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:28:29,299:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:28:29,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:29,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:30,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:30,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:30,636:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000530 seconds.
2023-11-23 14:28:30,636:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:30,636:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:28:30,636:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:28:30,637:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:28:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:30,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:30,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:30,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:30,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:30,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:31,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:31,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:31,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:31,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:31,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:31,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:32,045:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000416 seconds.
2023-11-23 14:28:32,045:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:32,045:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:28:32,045:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:28:32,045:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:28:32,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:32,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:32,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:32,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:32,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:32,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:32,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:32,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:32,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:32,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:33,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:33,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:33,443:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
2023-11-23 14:28:33,443:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:33,443:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:28:33,444:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:28:33,444:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:28:33,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:33,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:33,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:33,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:33,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:33,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:33,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:33,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:34,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:34,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:34,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:34,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:34,844:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2023-11-23 14:28:34,844:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:34,844:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:28:34,845:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:28:34,845:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:28:34,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:35,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:35,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:35,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:35,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:35,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:35,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:35,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:35,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:35,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:35,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,245:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2023-11-23 14:28:36,245:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:36,245:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:28:36,245:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:28:36,246:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:28:36,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:36,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:37,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:37,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:37,648:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2023-11-23 14:28:37,648:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:37,648:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:28:37,649:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:28:37,649:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:28:37,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:37,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:37,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:37,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:37,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:37,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:38,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:38,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:38,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:38,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:38,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:38,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:39,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2023-11-23 14:28:39,028:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:39,028:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:28:39,028:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:28:39,028:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:28:39,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:39,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:39,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:39,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:39,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:39,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:39,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:39,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:39,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2023-11-23 14:28:40,380:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:40,380:INFO:[LightGBM] [Info] Total Bins 2260
2023-11-23 14:28:40,380:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:28:40,380:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:28:40,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:40,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:41,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:41,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:41,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:41,735:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2023-11-23 14:28:41,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:41,735:INFO:[LightGBM] [Info] Total Bins 1805
2023-11-23 14:28:41,736:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:28:41,736:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:28:41,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:41,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:42,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:42,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:42,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:42,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:42,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:42,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:42,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:42,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:42,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:42,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:43,063:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000535 seconds.
2023-11-23 14:28:43,063:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:43,063:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:28:43,063:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:28:43,063:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:28:43,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:43,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:43,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:43,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:43,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:43,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:43,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:43,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:43,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:44,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:44,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:44,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2023-11-23 14:28:44,480:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:44,480:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:28:44,480:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:28:44,480:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:28:44,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:44,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:44,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:44,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:44,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:44,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:44,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:45,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:45,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:45,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:45,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:45,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:45,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.
2023-11-23 14:28:45,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:45,883:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:28:45,883:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:28:45,884:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:28:45,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:46,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:46,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:46,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:46,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:46,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:46,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:46,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:46,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:46,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:46,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,283:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
2023-11-23 14:28:47,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:47,283:INFO:[LightGBM] [Info] Total Bins 3214
2023-11-23 14:28:47,283:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:28:47,283:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:28:47,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:48,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:48,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:48,686:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.
2023-11-23 14:28:48,686:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:48,686:INFO:[LightGBM] [Info] Total Bins 3212
2023-11-23 14:28:48,686:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:28:48,686:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:28:48,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:48,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:49,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:49,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:49,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:49,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:49,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:49,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:49,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:49,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:49,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,092:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2023-11-23 14:28:50,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:50,092:INFO:[LightGBM] [Info] Total Bins 2757
2023-11-23 14:28:50,092:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:28:50,093:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:28:50,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:50,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:51,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:51,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:51,470:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2023-11-23 14:28:51,470:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:51,470:INFO:[LightGBM] [Info] Total Bins 2302
2023-11-23 14:28:51,470:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:28:51,470:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:28:51,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:51,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:51,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:51,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:51,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:51,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:51,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:51,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:52,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:52,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:52,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:52,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:52,816:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.
2023-11-23 14:28:52,816:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:52,816:INFO:[LightGBM] [Info] Total Bins 2251
2023-11-23 14:28:52,817:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:28:52,817:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:28:52,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:53,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:53,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:53,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:53,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:53,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:53,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:53,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:53,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:53,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:53,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,169:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.
2023-11-23 14:28:54,169:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:54,169:INFO:[LightGBM] [Info] Total Bins 1796
2023-11-23 14:28:54,169:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:28:54,170:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:28:54,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:54,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:55,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:55,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:55,501:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
2023-11-23 14:28:55,501:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:55,501:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:28:55,501:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:28:55,502:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:28:55,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:55,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:55,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:55,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:55,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:55,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:56,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:56,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:56,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:56,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:56,909:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2023-11-23 14:28:56,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:56,910:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:28:56,910:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:28:56,910:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:28:56,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:57,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:57,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:57,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:57,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:57,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:57,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:57,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:57,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:57,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:57,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2023-11-23 14:28:58,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:58,313:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:28:58,313:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:28:58,313:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:28:58,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:58,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:59,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:59,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:59,714:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2023-11-23 14:28:59,714:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:28:59,714:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:28:59,714:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:28:59,714:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:28:59,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:28:59,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:00,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:00,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:00,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:00,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:00,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:00,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:00,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:00,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:00,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,112:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-23 14:29:01,112:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:01,112:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:29:01,112:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:29:01,113:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:29:01,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:01,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:02,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:02,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:02,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2023-11-23 14:29:02,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:02,515:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:29:02,516:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:29:02,516:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:29:02,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:02,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:02,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:02,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:02,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:02,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:03,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:03,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:03,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:03,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:03,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:03,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:03,890:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000457 seconds.
2023-11-23 14:29:03,890:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:03,890:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:29:03,890:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:29:03,890:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:29:03,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:04,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:04,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:04,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:04,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:04,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:04,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:04,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:04,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:04,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:04,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2023-11-23 14:29:05,233:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:05,233:INFO:[LightGBM] [Info] Total Bins 2254
2023-11-23 14:29:05,233:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:29:05,233:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:29:05,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:05,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:06,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:06,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:06,582:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
2023-11-23 14:29:06,582:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:06,582:INFO:[LightGBM] [Info] Total Bins 1799
2023-11-23 14:29:06,582:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:29:06,582:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:29:06,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:06,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:06,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:06,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:06,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:06,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:07,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:07,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:07,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:07,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:07,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:07,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:07,910:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2023-11-23 14:29:07,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:07,910:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:29:07,910:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:29:07,910:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:29:07,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:08,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:08,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:08,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:08,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:08,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:08,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:08,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:08,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:08,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:08,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:09,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:09,347:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2023-11-23 14:29:09,347:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:09,347:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:29:09,347:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:29:09,347:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:29:09,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:09,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:09,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:09,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:09,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:09,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:09,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:09,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:09,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:10,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:10,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:10,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:10,759:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
2023-11-23 14:29:10,759:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:10,759:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:29:10,760:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:29:10,760:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:29:10,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:11,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:11,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:11,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:11,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:11,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:11,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:11,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:11,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:11,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:11,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
2023-11-23 14:29:12,165:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:12,165:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:29:12,165:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:29:12,165:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:29:12,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:12,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:13,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:13,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:13,573:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2023-11-23 14:29:13,573:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:13,573:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:29:13,573:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:29:13,574:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:29:13,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:13,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:13,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:13,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:13,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:13,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:14,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:14,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:14,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:14,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:14,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:14,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:14,974:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2023-11-23 14:29:14,974:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:14,974:INFO:[LightGBM] [Info] Total Bins 2762
2023-11-23 14:29:14,974:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:29:14,975:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:29:15,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:15,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:15,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:15,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:15,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:15,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:15,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:15,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:15,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:15,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
2023-11-23 14:29:16,350:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:16,350:INFO:[LightGBM] [Info] Total Bins 2307
2023-11-23 14:29:16,350:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:29:16,350:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:29:16,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:16,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:17,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:17,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:17,693:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2023-11-23 14:29:17,693:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:17,693:INFO:[LightGBM] [Info] Total Bins 2256
2023-11-23 14:29:17,693:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:29:17,693:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:29:17,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:17,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:17,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:18,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:18,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:18,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:18,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:18,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:18,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:18,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:18,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:18,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:19,037:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.
2023-11-23 14:29:19,038:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:19,038:INFO:[LightGBM] [Info] Total Bins 1801
2023-11-23 14:29:19,038:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:29:19,038:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:29:19,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:19,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:19,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:19,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:19,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:19,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:19,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:19,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:19,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:19,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,377:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.
2023-11-23 14:29:20,377:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:20,377:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:29:20,378:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:29:20,378:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:29:20,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:20,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:21,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:21,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:21,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:21,787:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2023-11-23 14:29:21,787:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:21,787:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:29:21,787:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:29:21,787:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:29:21,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:22,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:22,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:22,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:22,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:22,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:22,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:22,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:22,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:22,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:22,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,191:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.
2023-11-23 14:29:23,191:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:23,191:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:29:23,191:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:29:23,191:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:29:23,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:23,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:24,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:24,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:24,617:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.
2023-11-23 14:29:24,617:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:24,617:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:29:24,617:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:29:24,617:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:29:24,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:24,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:24,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:24,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:24,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:25,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:25,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:25,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:25,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:25,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:25,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:26,015:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.
2023-11-23 14:29:26,015:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:26,015:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:29:26,015:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:29:26,015:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:29:26,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:26,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:26,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:26,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:26,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:26,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:26,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:26,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:26,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:26,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:27,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:27,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:27,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2023-11-23 14:29:27,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:27,420:INFO:[LightGBM] [Info] Total Bins 2764
2023-11-23 14:29:27,420:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:29:27,420:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:29:27,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:27,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:27,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:27,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:27,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:27,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:27,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:27,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:28,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:28,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:28,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:28,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:28,796:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.
2023-11-23 14:29:28,796:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:28,796:INFO:[LightGBM] [Info] Total Bins 2309
2023-11-23 14:29:28,796:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:29:28,796:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:29:28,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:29,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:29,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:29,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:29,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:29,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:29,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:29,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:29,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:29,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:29,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,150:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2023-11-23 14:29:30,151:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:30,151:INFO:[LightGBM] [Info] Total Bins 2258
2023-11-23 14:29:30,151:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:29:30,151:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:29:30,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:30,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:31,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:31,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:31,511:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-23 14:29:31,511:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:31,511:INFO:[LightGBM] [Info] Total Bins 1803
2023-11-23 14:29:31,511:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 4
2023-11-23 14:29:31,511:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:29:31,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:31,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:31,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:31,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:31,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:31,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:31,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:32,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:32,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:32,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:32,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:32,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:32,851:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2023-11-23 14:29:32,851:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:32,851:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:29:32,851:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:29:32,851:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:29:32,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:33,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:33,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:33,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:33,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:33,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:33,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:33,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:33,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:33,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:33,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,265:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2023-11-23 14:29:34,265:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:34,265:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:29:34,265:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:29:34,265:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:29:34,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:34,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:35,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:35,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:35,726:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
2023-11-23 14:29:35,726:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:35,726:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:29:35,726:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:29:35,726:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:29:35,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:35,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:36,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:36,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:36,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:36,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:36,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:36,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:36,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:36,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:36,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
2023-11-23 14:29:37,127:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:37,127:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:29:37,127:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:29:37,127:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:29:37,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:37,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:38,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:38,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:38,523:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.
2023-11-23 14:29:38,523:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:38,523:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:29:38,523:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:29:38,523:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:29:38,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:38,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:38,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:38,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:38,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:39,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:39,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:39,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:39,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,257:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000306 seconds.
2023-11-23 14:29:40,257:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:40,257:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:29:40,257:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:29:40,257:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:29:40,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:41,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:41,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:41,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
2023-11-23 14:29:41,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:41,628:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:29:41,628:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:29:41,629:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:29:41,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:41,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:41,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:41,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:41,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:41,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:42,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:42,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:42,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:42,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:42,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:42,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:43,029:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2023-11-23 14:29:43,029:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:43,029:INFO:[LightGBM] [Info] Total Bins 2260
2023-11-23 14:29:43,030:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 5
2023-11-23 14:29:43,030:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:29:43,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:43,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:43,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:43,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:43,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:43,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:43,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:43,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:43,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:43,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,373:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.
2023-11-23 14:29:44,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:44,373:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:29:44,373:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:29:44,373:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:29:44,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:44,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:45,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:45,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:45,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:45,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.
2023-11-23 14:29:45,789:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:29:45,789:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:29:45,789:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:29:45,790:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:29:45,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:46,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:46,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:46,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:46,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:29:46,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:21,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:21,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:21,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:22,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:22,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:22,519:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2023-11-23 14:30:22,519:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:22,519:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:30:22,519:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:30:22,519:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:30:22,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:22,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:22,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:22,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:22,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:22,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:23,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:23,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:23,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:23,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:23,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,121:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2023-11-23 14:30:24,121:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:24,121:INFO:[LightGBM] [Info] Total Bins 3213
2023-11-23 14:30:24,121:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:30:24,121:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:30:24,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:24,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:25,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:25,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:25,538:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2023-11-23 14:30:25,538:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:25,538:INFO:[LightGBM] [Info] Total Bins 3211
2023-11-23 14:30:25,538:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:30:25,538:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:30:25,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:25,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:25,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:25,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:25,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:25,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:26,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:26,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:26,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:26,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:26,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:26,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:26,946:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-23 14:30:26,947:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:26,947:INFO:[LightGBM] [Info] Total Bins 2756
2023-11-23 14:30:26,947:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:30:26,947:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:30:26,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:27,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:27,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:27,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:27,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:27,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:27,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:27,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:27,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:27,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:27,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,345:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2023-11-23 14:30:28,345:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:28,345:INFO:[LightGBM] [Info] Total Bins 2705
2023-11-23 14:30:28,345:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:30:28,346:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:30:28,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:28,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:29,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:29,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:29,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000344 seconds.
2023-11-23 14:30:29,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:29,696:INFO:[LightGBM] [Info] Total Bins 2250
2023-11-23 14:30:29,696:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 5
2023-11-23 14:30:29,696:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:30:29,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:29,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:30,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:30,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:30,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:30,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:30,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:30,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:30,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:30,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,092:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2023-11-23 14:30:31,092:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:31,092:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:30:31,092:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:30:31,092:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:30:31,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:31,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:32,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:32,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:32,493:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-11-23 14:30:32,493:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:32,493:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:30:32,493:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:30:32,494:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:30:32,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:32,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:32,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:32,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:32,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:32,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:33,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:33,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:33,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:33,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:33,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:33,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:33,893:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-11-23 14:30:33,893:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:33,893:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:30:33,893:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:30:33,893:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:30:33,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:34,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:34,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:34,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:34,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:34,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:34,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:34,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:34,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:34,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:34,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,290:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.
2023-11-23 14:30:35,290:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:35,290:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:30:35,290:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:30:35,291:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:30:35,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:35,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:36,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:36,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:36,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2023-11-23 14:30:36,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:36,685:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:30:36,685:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:30:36,685:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:30:36,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:36,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:36,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:37,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:37,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:37,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:37,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:37,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:37,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:37,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:37,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,085:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.
2023-11-23 14:30:38,085:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:38,085:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:30:38,085:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:30:38,085:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:30:38,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:38,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:39,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:39,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:39,461:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.
2023-11-23 14:30:39,461:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:39,461:INFO:[LightGBM] [Info] Total Bins 2710
2023-11-23 14:30:39,461:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:30:39,462:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:30:39,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:39,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:39,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:39,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:39,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:39,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:39,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:40,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:40,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:40,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:40,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:40,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2023-11-23 14:30:40,809:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:40,809:INFO:[LightGBM] [Info] Total Bins 2255
2023-11-23 14:30:40,809:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:30:40,809:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:30:40,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:41,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:41,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:41,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:41,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:41,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:41,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:41,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:41,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:41,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:41,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,164:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.
2023-11-23 14:30:42,164:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:42,164:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:30:42,164:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:30:42,164:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:30:42,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:42,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:43,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:43,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:43,587:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2023-11-23 14:30:43,587:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:43,587:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:30:43,587:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:30:43,587:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:30:43,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:43,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:43,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:43,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:43,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:43,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:44,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:44,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:44,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:44,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:44,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:44,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:44,991:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.
2023-11-23 14:30:44,991:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:44,991:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:30:44,991:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:30:44,991:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:30:45,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:45,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:45,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:45,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:45,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:45,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:45,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:45,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:45,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,386:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2023-11-23 14:30:46,386:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:46,386:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:30:46,386:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:30:46,387:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:30:46,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:46,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:47,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:47,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:47,779:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.
2023-11-23 14:30:47,779:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:47,779:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:30:47,779:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:30:47,779:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:30:47,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:48,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:48,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:48,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:48,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:48,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:48,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:48,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:48,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:48,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:48,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,183:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
2023-11-23 14:30:49,183:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:49,183:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:30:49,183:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:30:49,183:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:30:49,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:49,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:50,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:50,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:50,555:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.
2023-11-23 14:30:50,555:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:50,555:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:30:50,555:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:30:50,555:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:30:50,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:50,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:50,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:50,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:50,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:50,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:51,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:51,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:51,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:51,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:51,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:51,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:51,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000482 seconds.
2023-11-23 14:30:51,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:51,903:INFO:[LightGBM] [Info] Total Bins 2254
2023-11-23 14:30:51,903:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:30:51,903:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:30:51,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:52,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:52,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:52,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:52,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:52,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:52,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:52,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:52,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:52,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:52,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,278:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000523 seconds.
2023-11-23 14:30:53,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:53,278:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:30:53,278:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:30:53,279:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:30:53,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:53,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:54,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:54,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:54,694:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2023-11-23 14:30:54,694:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:54,694:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:30:54,694:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:30:54,694:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:30:54,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:54,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:55,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:55,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:55,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:55,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:55,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:55,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:55,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:55,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,106:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.
2023-11-23 14:30:56,106:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:56,106:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:30:56,106:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:30:56,106:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:30:56,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:56,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:57,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:57,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:57,515:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2023-11-23 14:30:57,515:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:57,515:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:30:57,515:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:30:57,515:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:30:57,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:57,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:57,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:57,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:57,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:58,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:58,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:58,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:58,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:58,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:58,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:58,968:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
2023-11-23 14:30:58,968:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:30:58,968:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:30:58,968:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:30:58,968:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:30:59,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:59,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:59,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:59,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:59,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:59,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:59,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:59,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:59,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:30:59,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,381:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.
2023-11-23 14:31:00,381:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:00,382:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:31:00,382:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:31:00,382:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:31:00,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:00,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:01,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:01,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:01,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:01,768:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2023-11-23 14:31:01,768:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:01,768:INFO:[LightGBM] [Info] Total Bins 2306
2023-11-23 14:31:01,768:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:31:01,768:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:31:01,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:02,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:02,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:02,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:02,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:02,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:02,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:02,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:02,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:02,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:02,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,125:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.
2023-11-23 14:31:03,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:03,126:INFO:[LightGBM] [Info] Total Bins 2255
2023-11-23 14:31:03,126:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:31:03,126:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:31:03,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:03,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:04,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:04,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:04,483:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2023-11-23 14:31:04,484:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:04,484:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:31:04,484:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:31:04,484:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:31:04,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:04,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:04,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:04,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:04,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:04,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:05,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:05,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:05,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:05,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:05,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:05,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:05,890:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2023-11-23 14:31:05,891:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:05,891:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:31:05,891:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:31:05,891:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:31:05,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:06,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:06,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:06,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:06,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:06,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:06,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:06,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:06,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:06,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:06,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,290:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2023-11-23 14:31:07,290:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:07,290:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:31:07,290:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:31:07,290:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:31:07,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:07,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:08,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:08,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:08,707:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2023-11-23 14:31:08,707:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:08,707:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:31:08,707:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:31:08,707:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:31:08,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:08,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:09,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:09,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:09,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:09,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:09,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:09,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:09,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:09,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:09,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,119:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.
2023-11-23 14:31:10,119:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:10,119:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:31:10,119:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:31:10,119:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:31:10,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:10,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:11,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:11,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:11,535:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2023-11-23 14:31:11,535:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:11,535:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:31:11,535:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:31:11,535:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:31:11,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:11,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:11,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:11,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:11,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:11,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:12,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:12,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:12,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:12,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:12,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:12,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:12,918:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-11-23 14:31:12,918:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:12,918:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:31:12,918:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:31:12,919:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:31:12,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:13,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:13,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:13,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:13,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:13,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:13,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:13,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:13,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:13,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:13,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,284:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.
2023-11-23 14:31:14,284:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:14,284:INFO:[LightGBM] [Info] Total Bins 2260
2023-11-23 14:31:14,284:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:31:14,285:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:31:14,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:14,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:15,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:15,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:15,655:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2023-11-23 14:31:15,655:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:15,655:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:31:15,655:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:31:15,655:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:31:15,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:15,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:15,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:15,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:15,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:16,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:16,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:16,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:16,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:16,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:16,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:16,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:17,060:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000199 seconds.
2023-11-23 14:31:17,060:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:31:17,060:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:31:17,060:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:31:17,060:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:31:17,061:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:31:17,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:17,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:17,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:17,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:17,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:17,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:17,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:17,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:17,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:17,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:18,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:18,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:18,674:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.
2023-11-23 14:31:18,674:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:18,674:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:31:18,674:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:31:18,674:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:31:18,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:18,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:18,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:18,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:19,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:19,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:19,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:19,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:19,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:19,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:19,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:19,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:20,076:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
2023-11-23 14:31:20,076:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:20,076:INFO:[LightGBM] [Info] Total Bins 3214
2023-11-23 14:31:20,076:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:31:20,077:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:31:20,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:20,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:20,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:20,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:20,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:20,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:20,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:20,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:20,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:20,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:21,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:21,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:21,485:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2023-11-23 14:31:21,485:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:21,485:INFO:[LightGBM] [Info] Total Bins 3212
2023-11-23 14:31:21,485:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:31:21,485:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:31:21,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:21,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:21,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:21,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:21,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:21,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:22,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:22,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:22,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:22,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:22,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:22,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:22,896:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2023-11-23 14:31:22,896:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:22,896:INFO:[LightGBM] [Info] Total Bins 2757
2023-11-23 14:31:22,896:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:31:22,896:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:31:22,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:23,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:23,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:23,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:23,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:23,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:23,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:23,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:23,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:23,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:23,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,279:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-23 14:31:24,280:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:24,280:INFO:[LightGBM] [Info] Total Bins 2302
2023-11-23 14:31:24,280:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:31:24,280:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:31:24,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:24,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:25,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:25,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:25,631:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2023-11-23 14:31:25,631:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:25,631:INFO:[LightGBM] [Info] Total Bins 2251
2023-11-23 14:31:25,631:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:31:25,631:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:31:25,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:25,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:25,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:25,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:25,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:25,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:26,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:26,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:26,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:26,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:26,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:26,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:26,992:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000527 seconds.
2023-11-23 14:31:26,992:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:26,992:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:31:26,992:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:31:26,992:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:31:27,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:27,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:27,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:27,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:27,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:27,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:27,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:27,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:27,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:27,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:28,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:28,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:28,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
2023-11-23 14:31:28,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:28,397:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:31:28,397:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:31:28,398:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:31:28,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:28,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:28,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:28,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:28,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:28,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:28,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:28,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:29,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:29,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:29,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:29,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:29,802:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
2023-11-23 14:31:29,802:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:29,802:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:31:29,802:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:31:29,802:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:31:29,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:30,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:30,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:30,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:30,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:30,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:30,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:30,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:30,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:30,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:30,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,204:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000521 seconds.
2023-11-23 14:31:31,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:31,205:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:31:31,205:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:31:31,205:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:31:31,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:31,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:32,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:32,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:32,603:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
2023-11-23 14:31:32,603:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:32,603:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:31:32,603:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:31:32,603:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:31:32,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:32,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:32,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:32,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:32,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:33,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:33,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:33,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:33,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:33,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:33,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:34,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
2023-11-23 14:31:34,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:34,013:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:31:34,014:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:31:34,014:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:31:34,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:34,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:34,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:34,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:34,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:34,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:34,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:34,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:34,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:34,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,401:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2023-11-23 14:31:35,401:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:35,401:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:31:35,401:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:31:35,401:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:31:35,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:35,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:36,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:36,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:36,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:36,754:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000401 seconds.
2023-11-23 14:31:36,754:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:36,754:INFO:[LightGBM] [Info] Total Bins 2254
2023-11-23 14:31:36,754:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:31:36,754:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:31:36,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:37,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:37,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:37,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:37,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:37,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:37,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:37,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:37,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:37,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:37,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.
2023-11-23 14:31:38,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:38,126:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:31:38,126:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:31:38,126:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:31:38,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:38,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:39,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:39,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:39,541:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
2023-11-23 14:31:39,541:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:39,541:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:31:39,541:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:31:39,541:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:31:39,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:39,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:39,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:39,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:40,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:40,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:40,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:40,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:40,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:40,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:40,948:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2023-11-23 14:31:40,948:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:40,948:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:31:40,948:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:31:40,948:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:31:40,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:41,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:41,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:41,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:41,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:41,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:41,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:41,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:41,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:41,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:41,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:42,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:42,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2023-11-23 14:31:42,351:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:42,351:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:31:42,351:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:31:42,351:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:31:42,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:42,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:42,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:42,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:42,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:42,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:42,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:42,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:42,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:43,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:43,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:43,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:43,753:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
2023-11-23 14:31:43,754:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:43,754:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:31:43,754:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:31:43,754:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:31:43,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:44,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:44,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:44,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:44,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:44,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:44,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:44,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:44,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:44,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:44,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,154:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2023-11-23 14:31:45,154:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:45,154:INFO:[LightGBM] [Info] Total Bins 2762
2023-11-23 14:31:45,154:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:31:45,154:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:31:45,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:45,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:46,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:46,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:46,529:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2023-11-23 14:31:46,529:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:46,530:INFO:[LightGBM] [Info] Total Bins 2307
2023-11-23 14:31:46,530:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:31:46,530:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:31:46,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:46,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:46,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:46,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:47,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:47,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:47,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:47,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:47,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:47,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:47,873:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2023-11-23 14:31:47,873:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:47,873:INFO:[LightGBM] [Info] Total Bins 2256
2023-11-23 14:31:47,873:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:31:47,874:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:31:47,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:48,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:48,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:48,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:48,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:48,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:48,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:48,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:48,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:48,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:48,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,229:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2023-11-23 14:31:49,229:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:49,229:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:31:49,229:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:31:49,230:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:31:49,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:49,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:50,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:50,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:50,636:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000229 seconds.
2023-11-23 14:31:50,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:31:50,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:31:50,637:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:31:50,637:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:31:50,637:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:31:50,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:50,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:51,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:51,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:51,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:51,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:51,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:51,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:51,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:51,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:51,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,254:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2023-11-23 14:31:52,254:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:52,254:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:31:52,254:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:31:52,255:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:31:52,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:52,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:53,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:53,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:53,657:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000339 seconds.
2023-11-23 14:31:53,657:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:53,657:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:31:53,657:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:31:53,657:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:31:53,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:53,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:53,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:53,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:54,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:54,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:54,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:54,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:54,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:54,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:54,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:55,058:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.
2023-11-23 14:31:55,058:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:55,058:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:31:55,058:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:31:55,059:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:31:55,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:55,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:55,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:55,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:55,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:55,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:55,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:55,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:55,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:55,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:56,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:56,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:56,462:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.
2023-11-23 14:31:56,463:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:56,463:INFO:[LightGBM] [Info] Total Bins 2764
2023-11-23 14:31:56,463:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:31:56,463:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:31:56,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:56,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:56,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:56,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:56,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:56,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:56,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:57,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:57,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:57,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:57,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:57,836:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.
2023-11-23 14:31:57,836:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:57,836:INFO:[LightGBM] [Info] Total Bins 2309
2023-11-23 14:31:57,836:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:31:57,837:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:31:57,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:58,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:58,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:58,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:58,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:58,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:58,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:58,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:58,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:58,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:58,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,184:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-23 14:31:59,184:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:31:59,184:INFO:[LightGBM] [Info] Total Bins 2258
2023-11-23 14:31:59,184:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 5
2023-11-23 14:31:59,185:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:31:59,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:31:59,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:00,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:00,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:00,542:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
2023-11-23 14:32:00,542:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:00,542:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:32:00,542:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:32:00,543:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:32:00,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:00,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:00,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:00,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:00,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:00,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:01,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:01,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:01,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:01,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:01,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:01,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:01,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.
2023-11-23 14:32:01,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:01,950:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:32:01,950:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:32:01,951:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:32:01,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:02,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:02,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:02,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:02,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:02,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:02,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:02,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:02,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:02,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:02,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:03,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:03,351:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.
2023-11-23 14:32:03,351:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:03,352:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:32:03,352:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:32:03,352:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:32:03,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:03,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:03,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:03,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:03,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:03,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:03,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:03,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:03,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:04,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:04,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:04,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:04,792:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000482 seconds.
2023-11-23 14:32:04,792:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:04,793:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:32:04,793:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:32:04,793:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:32:04,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:05,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:05,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:05,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:05,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:05,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:05,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:05,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:05,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:05,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:05,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,189:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2023-11-23 14:32:06,190:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:06,190:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:32:06,190:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:32:06,190:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:32:06,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:06,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:07,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:07,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:07,600:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000487 seconds.
2023-11-23 14:32:07,600:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:07,600:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:32:07,600:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:32:07,600:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:32:07,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:07,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:07,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:07,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:07,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:07,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:08,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:08,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:08,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:08,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:08,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:08,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:08,984:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2023-11-23 14:32:08,984:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:08,984:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:32:08,984:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:32:08,985:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:32:09,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:09,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:09,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:09,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:09,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:09,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:09,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:09,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:09,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:09,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:09,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:10,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:10,347:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000622 seconds.
2023-11-23 14:32:10,347:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:10,347:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:32:10,347:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:32:10,348:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:32:10,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:10,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:10,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:10,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:10,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:10,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:10,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:10,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:10,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:11,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:11,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:11,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:11,764:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2023-11-23 14:32:11,764:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:11,764:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:32:11,764:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:32:11,764:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:32:11,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:12,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:12,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:12,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:12,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:12,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:12,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:12,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:12,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:12,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,176:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000591 seconds.
2023-11-23 14:32:13,176:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:13,176:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:32:13,176:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:32:13,176:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:32:13,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:13,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:14,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:14,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:14,577:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2023-11-23 14:32:14,577:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:14,577:INFO:[LightGBM] [Info] Total Bins 3213
2023-11-23 14:32:14,577:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:32:14,578:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:32:14,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:14,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:14,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:14,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:14,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:14,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:15,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:15,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:15,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:15,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:15,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:15,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:15,983:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2023-11-23 14:32:15,983:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:15,983:INFO:[LightGBM] [Info] Total Bins 3211
2023-11-23 14:32:15,983:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:32:15,984:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:32:16,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:16,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:16,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:16,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:16,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:16,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:16,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:16,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:16,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:16,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:17,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:17,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:17,393:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000416 seconds.
2023-11-23 14:32:17,393:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:17,393:INFO:[LightGBM] [Info] Total Bins 2756
2023-11-23 14:32:17,393:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:32:17,394:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:32:17,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:17,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:17,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:17,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:17,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:17,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:17,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:17,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:18,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:18,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:18,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:18,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:18,776:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2023-11-23 14:32:18,776:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:18,776:INFO:[LightGBM] [Info] Total Bins 2705
2023-11-23 14:32:18,776:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 6
2023-11-23 14:32:18,776:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:32:18,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:19,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:19,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:19,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:19,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:19,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:19,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:19,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:19,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:19,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:19,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,139:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2023-11-23 14:32:20,139:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:20,139:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:32:20,139:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:32:20,139:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:32:20,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:20,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:21,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:21,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:21,550:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
2023-11-23 14:32:21,550:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:21,550:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:32:21,550:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:32:21,550:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:32:21,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:21,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:21,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:21,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:21,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:21,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:22,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:22,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:22,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:22,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:22,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:22,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:22,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
2023-11-23 14:32:22,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:22,950:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:32:22,950:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:32:22,950:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:32:22,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:23,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:23,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:23,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:23,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:23,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:23,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:23,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:23,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:23,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:23,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:24,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:24,352:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2023-11-23 14:32:24,352:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:24,352:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:32:24,352:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:32:24,352:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:32:24,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:24,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:24,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:24,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:24,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:24,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:24,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:24,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:25,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:25,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:25,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:25,756:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2023-11-23 14:32:25,756:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:25,756:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:32:25,756:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:32:25,757:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:32:25,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:26,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:26,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:26,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:26,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:26,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:26,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:26,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:26,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:26,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:26,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,165:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2023-11-23 14:32:27,166:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:27,166:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:32:27,166:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:32:27,166:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:32:27,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:27,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:28,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:28,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:28,544:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
2023-11-23 14:32:28,544:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:28,544:INFO:[LightGBM] [Info] Total Bins 2710
2023-11-23 14:32:28,544:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:32:28,544:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:32:28,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:28,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:28,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:28,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:28,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:28,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:29,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:29,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:29,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:29,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:29,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:29,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:29,934:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2023-11-23 14:32:29,934:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:29,934:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:32:29,934:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:32:29,934:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:32:29,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:30,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:30,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:30,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:30,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:30,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:30,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:30,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:30,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:30,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,374:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2023-11-23 14:32:31,374:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:31,374:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:32:31,374:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:32:31,374:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:32:31,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:31,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:32,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:32,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:32,780:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2023-11-23 14:32:32,780:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:32,780:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:32:32,781:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:32:32,781:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:32:32,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:33,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:33,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:33,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:33,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:33,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:33,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:33,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:33,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:33,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:33,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,184:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2023-11-23 14:32:34,184:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:34,184:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:32:34,184:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:32:34,184:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:32:34,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:34,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:35,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:35,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:35,585:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.
2023-11-23 14:32:35,585:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:35,585:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:32:35,585:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:32:35,585:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:32:35,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:35,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:35,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:35,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:35,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:35,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:36,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:36,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:36,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:36,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:36,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:36,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:36,990:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2023-11-23 14:32:36,991:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:36,991:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:32:36,991:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:32:36,991:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:32:37,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:37,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:37,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:37,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:37,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:37,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:37,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:37,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2023-11-23 14:32:38,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:38,365:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:32:38,365:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:32:38,365:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:32:38,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:38,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:39,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:39,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:39,718:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
2023-11-23 14:32:39,718:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:39,718:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:32:39,718:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:32:39,718:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:32:39,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:39,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:40,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:40,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:40,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:40,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:40,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:40,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,125:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2023-11-23 14:32:41,125:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:41,125:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:32:41,125:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:32:41,126:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:32:41,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:41,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:42,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:42,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:42,527:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2023-11-23 14:32:42,527:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:42,527:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:32:42,527:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:32:42,527:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:32:42,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:42,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:42,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:42,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:43,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:43,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:43,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:43,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:43,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:43,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:43,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.
2023-11-23 14:32:43,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:43,925:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:32:43,925:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:32:43,925:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:32:43,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:44,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:44,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:44,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:44,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:44,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:44,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:44,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:44,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:44,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:44,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,323:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2023-11-23 14:32:45,323:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:45,323:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:32:45,324:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:32:45,324:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:32:45,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:45,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:46,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:46,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:46,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2023-11-23 14:32:46,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:46,724:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:32:46,724:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:32:46,724:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:32:46,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:46,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:47,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:47,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:47,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:47,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:47,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:47,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:47,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:47,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:47,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,102:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-23 14:32:48,102:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:48,102:INFO:[LightGBM] [Info] Total Bins 2306
2023-11-23 14:32:48,102:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:32:48,103:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:32:48,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:48,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:49,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:49,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:49,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.
2023-11-23 14:32:49,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:32:49,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:32:49,454:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:32:49,454:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:32:49,454:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:32:49,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:49,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:49,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:49,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:49,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:49,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:50,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:50,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:50,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:50,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:50,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:50,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:51,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.
2023-11-23 14:32:51,066:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:51,066:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:32:51,066:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:32:51,067:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:32:51,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:51,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:51,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:51,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:51,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:51,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:51,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:51,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:51,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:51,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:52,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:52,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:52,464:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.
2023-11-23 14:32:52,464:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:52,464:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:32:52,464:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:32:52,465:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:32:52,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:52,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:52,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:52,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:52,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:52,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:52,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:52,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:53,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:53,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:53,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:53,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:53,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
2023-11-23 14:32:53,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:53,883:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:32:53,884:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:32:53,884:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:32:53,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:54,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:54,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:54,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:54,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:54,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:54,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:54,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:54,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:54,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:55,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:55,346:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2023-11-23 14:32:55,346:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:55,346:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:32:55,346:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:32:55,347:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:32:55,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:55,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:55,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:55,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:55,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:55,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:55,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:55,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:55,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:56,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:56,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:56,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:56,751:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2023-11-23 14:32:56,751:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:56,751:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:32:56,751:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:32:56,751:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:32:56,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:57,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:57,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:57,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:57,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:57,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:57,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:57,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:57,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:57,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,120:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
2023-11-23 14:32:58,120:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:58,120:INFO:[LightGBM] [Info] Total Bins 2311
2023-11-23 14:32:58,120:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:32:58,120:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:32:58,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:58,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:59,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:59,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:59,501:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-23 14:32:59,501:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:32:59,501:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:32:59,501:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:32:59,501:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:32:59,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:59,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:59,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:59,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:59,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:32:59,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:00,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:00,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:00,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:00,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:00,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:00,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:00,889:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2023-11-23 14:33:00,889:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:00,889:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:33:00,889:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:33:00,889:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:33:00,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:01,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:01,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:01,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:01,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:01,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:01,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:01,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:01,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:01,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:01,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,287:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
2023-11-23 14:33:02,287:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:02,287:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:33:02,287:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:33:02,288:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:33:02,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:02,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:03,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:03,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:03,692:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2023-11-23 14:33:03,692:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:03,692:INFO:[LightGBM] [Info] Total Bins 3214
2023-11-23 14:33:03,692:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:33:03,692:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:33:03,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:03,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:04,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:04,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:04,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:04,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:04,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:04,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:04,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:04,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:04,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,095:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.
2023-11-23 14:33:05,095:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:05,096:INFO:[LightGBM] [Info] Total Bins 3212
2023-11-23 14:33:05,096:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:33:05,096:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:33:05,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:05,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:06,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:06,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:06,501:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2023-11-23 14:33:06,501:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:06,501:INFO:[LightGBM] [Info] Total Bins 2757
2023-11-23 14:33:06,501:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:33:06,501:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:33:06,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:06,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:06,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:06,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:06,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:06,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:07,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:07,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:07,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:07,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:07,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:07,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:07,875:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
2023-11-23 14:33:07,875:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:07,875:INFO:[LightGBM] [Info] Total Bins 2302
2023-11-23 14:33:07,875:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:33:07,875:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:33:07,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:08,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:08,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:08,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:08,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:08,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:08,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:08,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:08,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:08,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:08,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.
2023-11-23 14:33:09,233:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:09,233:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:33:09,233:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:33:09,234:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:33:09,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:09,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:10,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:10,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:10,637:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2023-11-23 14:33:10,637:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:10,637:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:33:10,637:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:33:10,637:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:33:10,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:10,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:10,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:10,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:10,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:10,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:11,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:11,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:11,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:11,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:11,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:12,032:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2023-11-23 14:33:12,032:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:12,032:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:33:12,033:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:33:12,033:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:33:12,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:12,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:12,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:12,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:12,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:12,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:12,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:12,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:12,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:12,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:13,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:13,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:13,409:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2023-11-23 14:33:13,409:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:13,409:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:33:13,409:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:33:13,409:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:33:13,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:13,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:13,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:13,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:13,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:13,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:13,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:13,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:14,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:14,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:14,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:14,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:14,820:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2023-11-23 14:33:14,820:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:14,820:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:33:14,820:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:33:14,820:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:33:14,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:15,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:15,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:15,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:15,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:15,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:15,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:15,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:15,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:15,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:15,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,218:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.
2023-11-23 14:33:16,218:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:16,218:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:33:16,219:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:33:16,219:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:33:16,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:16,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:17,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:17,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:17,610:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2023-11-23 14:33:17,610:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:17,610:INFO:[LightGBM] [Info] Total Bins 2305
2023-11-23 14:33:17,610:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:33:17,611:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:33:17,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:17,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:17,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:17,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:17,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:17,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:18,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:18,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:18,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:18,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:18,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:18,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:18,949:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2023-11-23 14:33:18,949:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:18,950:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:33:18,950:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:33:18,950:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:33:18,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:19,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:19,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:19,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:19,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:19,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:19,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:19,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:19,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:19,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:19,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:20,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:20,355:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2023-11-23 14:33:20,355:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:20,355:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:33:20,355:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:33:20,355:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:33:20,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:20,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:20,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:20,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:20,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:20,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:20,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:20,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:20,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:21,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:21,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:21,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:21,766:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2023-11-23 14:33:21,766:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:21,766:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:33:21,766:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:33:21,767:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:33:21,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:22,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:22,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:22,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:22,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:22,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:22,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:22,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:22,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:22,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:22,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,158:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
2023-11-23 14:33:23,158:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:23,158:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:33:23,158:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:33:23,158:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:33:23,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:23,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:24,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:24,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:24,556:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.
2023-11-23 14:33:24,556:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:24,556:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:33:24,556:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:33:24,557:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:33:24,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:24,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:24,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:24,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:24,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:24,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:25,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:25,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:25,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:25,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:25,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:25,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:25,966:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000319 seconds.
2023-11-23 14:33:25,966:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:25,966:INFO:[LightGBM] [Info] Total Bins 2762
2023-11-23 14:33:25,966:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:33:25,966:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:33:26,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:26,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:26,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:26,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:26,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:26,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:26,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:26,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:26,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:26,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,369:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2023-11-23 14:33:27,369:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:27,369:INFO:[LightGBM] [Info] Total Bins 2307
2023-11-23 14:33:27,369:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:33:27,370:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:33:27,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:27,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:28,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:28,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:28,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:28,723:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.
2023-11-23 14:33:28,723:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:28,723:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:33:28,723:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:33:28,724:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:33:28,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:28,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:29,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:29,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:29,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:29,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:29,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:29,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:29,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:29,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:29,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,122:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.
2023-11-23 14:33:30,122:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:30,122:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:33:30,122:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:33:30,122:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:33:30,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:30,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:31,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:31,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:31,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000360 seconds.
2023-11-23 14:33:31,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:31,528:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:33:31,529:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:33:31,529:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:33:31,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:31,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:31,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:31,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:31,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:31,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:32,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:32,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:32,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:32,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:32,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:32,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:32,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2023-11-23 14:33:32,924:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:32,924:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:33:32,924:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:33:32,924:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:33:32,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:33,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:33,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:33,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:33,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:33,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:33,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:33,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:33,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:33,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:33,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,313:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2023-11-23 14:33:34,313:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:34,313:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:33:34,313:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:33:34,313:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:33:34,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:34,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:35,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:35,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:35,715:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-11-23 14:33:35,715:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:35,715:INFO:[LightGBM] [Info] Total Bins 2764
2023-11-23 14:33:35,715:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:33:35,715:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:33:35,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:35,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:36,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:36,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:36,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:36,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:36,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:36,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:36,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:36,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:36,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:36,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:37,076:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.
2023-11-23 14:33:37,076:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:37,076:INFO:[LightGBM] [Info] Total Bins 2309
2023-11-23 14:33:37,076:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 6
2023-11-23 14:33:37,076:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:33:37,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:37,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:37,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:37,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:37,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:37,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:37,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:37,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:37,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:37,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:38,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:38,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:38,416:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.
2023-11-23 14:33:38,416:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:38,416:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:33:38,416:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:33:38,416:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:33:38,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:38,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:38,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:38,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:38,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:38,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:38,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:38,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:39,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:39,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:39,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:39,820:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2023-11-23 14:33:39,820:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:39,820:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:33:39,821:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:33:39,821:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:33:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:40,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:40,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:40,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:40,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:40,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:40,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:40,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:40,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:40,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,216:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000479 seconds.
2023-11-23 14:33:41,216:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:41,216:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:33:41,216:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:33:41,216:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:33:41,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:41,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:42,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:42,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:42,604:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2023-11-23 14:33:42,604:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:42,604:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:33:42,604:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:33:42,605:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:33:42,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:42,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:42,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:42,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:42,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:42,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:43,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:43,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:43,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:43,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:43,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:43,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:43,997:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000534 seconds.
2023-11-23 14:33:43,997:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:43,997:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:33:43,997:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:33:43,997:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:33:44,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:44,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:44,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:44,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:44,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:44,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:44,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:44,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:44,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:44,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,393:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
2023-11-23 14:33:45,393:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:45,393:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:33:45,393:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:33:45,393:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:33:45,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:45,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:46,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:46,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:46,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:46,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.
2023-11-23 14:33:46,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:46,765:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:33:46,765:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:33:46,766:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:33:46,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:47,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:47,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:47,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:47,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:47,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:47,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:47,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:47,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:47,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,165:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000220 seconds.
2023-11-23 14:33:48,165:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:33:48,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:33:48,165:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:33:48,165:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:33:48,166:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:33:48,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:48,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:49,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:49,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:49,765:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2023-11-23 14:33:49,765:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:49,765:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:33:49,765:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:33:49,766:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:33:49,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:50,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:50,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:50,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:50,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:50,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:50,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:50,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:50,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:50,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,155:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2023-11-23 14:33:51,155:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:51,155:INFO:[LightGBM] [Info] Total Bins 3213
2023-11-23 14:33:51,155:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:33:51,156:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:33:51,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:51,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:52,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:52,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:52,575:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.
2023-11-23 14:33:52,575:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:52,575:INFO:[LightGBM] [Info] Total Bins 3211
2023-11-23 14:33:52,575:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:33:52,576:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:33:52,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:52,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:52,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:52,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:52,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:52,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:53,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:53,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:53,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:53,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:53,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:53,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:53,994:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000498 seconds.
2023-11-23 14:33:53,994:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:53,994:INFO:[LightGBM] [Info] Total Bins 2756
2023-11-23 14:33:53,994:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 7
2023-11-23 14:33:53,995:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:33:54,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:54,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:54,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:54,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:54,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:54,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:54,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:54,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:54,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:54,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:55,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:55,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:55,389:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2023-11-23 14:33:55,389:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:55,389:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:33:55,390:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:33:55,390:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:33:55,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:55,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:55,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:55,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:55,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:55,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:55,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:55,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:56,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:56,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:56,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:56,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:56,834:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2023-11-23 14:33:56,834:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:56,834:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:33:56,834:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:33:56,835:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:33:56,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:57,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:57,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:57,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:57,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:57,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:57,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:57,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:57,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:57,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:57,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.
2023-11-23 14:33:58,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:58,243:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:33:58,243:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:33:58,244:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:33:58,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:58,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:59,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:59,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:59,647:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2023-11-23 14:33:59,647:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:33:59,648:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:33:59,648:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:33:59,648:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:33:59,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:59,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:59,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:59,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:59,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:33:59,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:00,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:00,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:00,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:00,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:00,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:00,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:01,054:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.
2023-11-23 14:34:01,054:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:01,054:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:34:01,054:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:34:01,055:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:34:01,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:01,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:01,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:01,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:01,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:01,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:01,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:01,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:01,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:01,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:02,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:02,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:02,458:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.
2023-11-23 14:34:02,458:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:02,458:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:34:02,458:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:34:02,458:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:34:02,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:02,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:02,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:02,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:02,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:02,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:02,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:02,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:03,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:03,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:03,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:03,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:03,844:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2023-11-23 14:34:03,844:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:03,844:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:34:03,844:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:34:03,844:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:34:03,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:04,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:04,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:04,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:04,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:04,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:04,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:04,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:04,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:04,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:04,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.
2023-11-23 14:34:05,252:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:05,252:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:34:05,252:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:34:05,252:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:34:05,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:05,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:06,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:06,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:06,684:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.
2023-11-23 14:34:06,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:06,685:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:34:06,685:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:34:06,685:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:34:06,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:06,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:06,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:07,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:07,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:07,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:07,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:07,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:07,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:07,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:07,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:07,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:08,082:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2023-11-23 14:34:08,082:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:08,082:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:34:08,082:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:34:08,082:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:34:08,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:08,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:08,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:08,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:08,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:08,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:08,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:08,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:08,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:08,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:09,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:09,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:09,481:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2023-11-23 14:34:09,481:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:09,481:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:34:09,481:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:34:09,481:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:34:09,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:09,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:09,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:09,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:09,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:09,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:10,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:10,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:10,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:10,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:10,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:10,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:10,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000199 seconds.
2023-11-23 14:34:10,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:34:10,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:34:10,889:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:34:10,889:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:34:10,890:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:34:10,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:11,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:11,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:11,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:11,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:11,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:11,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:11,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:11,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:11,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:12,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:12,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:12,480:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2023-11-23 14:34:12,480:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:12,480:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:34:12,480:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:34:12,481:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:34:12,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:12,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:12,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:12,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:12,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:12,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:13,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:13,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:13,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:13,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:13,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:13,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:13,895:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2023-11-23 14:34:13,895:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:13,895:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:34:13,896:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:34:13,896:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:34:13,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:14,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:14,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:14,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:14,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:14,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:14,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:14,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:14,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:14,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:14,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2023-11-23 14:34:15,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:15,308:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:34:15,308:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:34:15,308:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:34:15,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:15,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:16,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:16,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:16,714:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000513 seconds.
2023-11-23 14:34:16,714:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:16,714:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:34:16,714:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:34:16,714:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:34:16,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:16,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:17,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:17,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:17,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:17,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:17,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:17,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:17,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:17,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:17,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,123:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.
2023-11-23 14:34:18,123:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:18,123:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:34:18,123:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:34:18,124:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:34:18,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:18,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:19,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:19,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:19,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.
2023-11-23 14:34:19,568:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:19,568:INFO:[LightGBM] [Info] Total Bins 2761
2023-11-23 14:34:19,568:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:34:19,568:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:34:19,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:19,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:19,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:19,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:19,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:19,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:20,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:20,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:20,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:20,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:20,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:20,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:20,978:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-11-23 14:34:20,978:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:20,978:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:34:20,978:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:34:20,978:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:34:21,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:21,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:21,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:21,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:21,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:21,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:21,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:22,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:22,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:22,390:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2023-11-23 14:34:22,390:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:22,390:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:34:22,390:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:34:22,390:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:34:22,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:22,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:22,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:22,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:22,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:22,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:22,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:22,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:23,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:23,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:23,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:23,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:23,826:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000564 seconds.
2023-11-23 14:34:23,827:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:23,827:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:34:23,827:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:34:23,827:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:34:23,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:24,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:24,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:24,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:24,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:24,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:24,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:24,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:24,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:24,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:24,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,229:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.
2023-11-23 14:34:25,229:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:25,229:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:34:25,229:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:34:25,230:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:34:25,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:25,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:26,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:26,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:26,628:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.
2023-11-23 14:34:26,628:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:26,628:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:34:26,628:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:34:26,628:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:34:26,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:26,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:26,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:26,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:26,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:26,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:27,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:27,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:27,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:27,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:27,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:27,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:28,033:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.
2023-11-23 14:34:28,033:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:28,034:INFO:[LightGBM] [Info] Total Bins 2766
2023-11-23 14:34:28,034:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:34:28,034:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:34:28,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:28,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:28,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:28,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:28,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:28,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:28,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:28,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:28,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:28,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:29,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:29,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:29,428:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.
2023-11-23 14:34:29,428:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:29,428:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:34:29,429:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:34:29,429:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:34:29,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:29,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:29,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:29,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:29,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:29,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:29,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:29,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:30,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:30,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:30,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:30,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:30,855:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000475 seconds.
2023-11-23 14:34:30,855:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:30,856:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:34:30,856:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:34:30,856:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:34:30,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:31,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:31,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:31,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:31,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:31,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:31,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:31,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:31,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:31,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:31,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.
2023-11-23 14:34:32,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:32,308:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:34:32,308:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:34:32,308:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:34:32,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:32,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:33,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:33,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:33,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000180 seconds.
2023-11-23 14:34:33,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:34:33,721:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:34:33,721:INFO:[LightGBM] [Info] Total Bins 3214
2023-11-23 14:34:33,722:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:34:33,722:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:34:33,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:34,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:34,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:34,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:34,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:34,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:34,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:34,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:34,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:34,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:34,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:35,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:35,378:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
2023-11-23 14:34:35,378:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:35,378:INFO:[LightGBM] [Info] Total Bins 3212
2023-11-23 14:34:35,378:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:34:35,378:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:34:35,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:35,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:35,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:35,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:35,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:35,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:35,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:35,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:35,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:36,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:36,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:36,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:36,790:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2023-11-23 14:34:36,791:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:36,791:INFO:[LightGBM] [Info] Total Bins 2757
2023-11-23 14:34:36,791:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:34:36,791:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:34:36,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:37,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:37,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:37,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:37,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:37,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:37,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:37,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:37,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:37,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:37,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2023-11-23 14:34:38,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:38,177:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:34:38,177:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:34:38,177:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:34:38,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:38,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:39,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:39,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:39,614:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.
2023-11-23 14:34:39,614:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:39,614:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:34:39,614:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:34:39,614:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:34:39,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:39,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:39,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:39,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:39,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:39,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:40,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:40,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:40,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:40,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:41,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.
2023-11-23 14:34:41,028:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:41,028:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:34:41,028:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:34:41,028:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:34:41,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:41,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:41,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:41,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:41,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:41,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:41,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:41,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:41,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:41,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:42,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:42,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:42,440:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2023-11-23 14:34:42,440:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:42,440:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:34:42,440:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:34:42,440:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:34:42,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:42,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:42,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:42,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:42,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:42,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:42,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:42,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:43,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:43,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:43,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:43,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:43,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.
2023-11-23 14:34:43,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:43,853:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:34:43,853:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:34:43,853:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:34:43,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:44,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:44,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:44,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:44,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:44,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:44,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:44,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:44,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:44,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:44,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,241:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-11-23 14:34:45,241:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:45,241:INFO:[LightGBM] [Info] Total Bins 2760
2023-11-23 14:34:45,241:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:34:45,241:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:34:45,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:45,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:46,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:46,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:46,708:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.
2023-11-23 14:34:46,708:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:46,708:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:34:46,708:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:34:46,708:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:34:46,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:46,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:47,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:47,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:47,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:47,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:47,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:47,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:47,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:47,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,187:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.
2023-11-23 14:34:48,187:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:48,187:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:34:48,188:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:34:48,188:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:34:48,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:48,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:49,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:49,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:49,626:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2023-11-23 14:34:49,626:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:49,627:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:34:49,627:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:34:49,627:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:34:49,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:49,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:49,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:49,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:49,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:49,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:50,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:50,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:50,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:50,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:50,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:50,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:51,027:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2023-11-23 14:34:51,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:51,028:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:34:51,028:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:34:51,028:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:34:51,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:51,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:51,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:51,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:51,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:51,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:51,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:51,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:51,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:51,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:52,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:52,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:52,432:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2023-11-23 14:34:52,432:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:52,432:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:34:52,432:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:34:52,432:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:34:52,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:52,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:52,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:52,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:52,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:52,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:52,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:52,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:53,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:53,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:53,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:53,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:53,844:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2023-11-23 14:34:53,844:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:53,844:INFO:[LightGBM] [Info] Total Bins 2762
2023-11-23 14:34:53,844:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:34:53,844:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:34:53,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:54,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:54,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:54,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:54,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:54,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:54,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:54,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:54,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:54,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:54,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2023-11-23 14:34:55,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:55,308:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:34:55,308:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:34:55,308:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:34:55,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:55,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:56,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:56,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:56,719:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000372 seconds.
2023-11-23 14:34:56,719:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:56,719:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:34:56,719:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:34:56,719:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:34:56,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:56,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:57,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:57,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:57,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:57,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:57,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:57,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:57,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:57,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:57,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,132:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
2023-11-23 14:34:58,132:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:58,132:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:34:58,132:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:34:58,132:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:34:58,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:58,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:59,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:59,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:59,532:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.
2023-11-23 14:34:59,532:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:34:59,532:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:34:59,532:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:34:59,532:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:34:59,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:59,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:59,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:59,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:59,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:34:59,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:00,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:00,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:00,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:00,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:00,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:00,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:00,916:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.
2023-11-23 14:35:00,916:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:00,916:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:35:00,917:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:35:00,917:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:35:00,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:01,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:01,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:01,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:01,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:01,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:01,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:01,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:01,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:01,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:01,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,297:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-23 14:35:02,297:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:02,298:INFO:[LightGBM] [Info] Total Bins 2764
2023-11-23 14:35:02,298:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 7
2023-11-23 14:35:02,298:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:35:02,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:02,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:03,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:03,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:03,657:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2023-11-23 14:35:03,657:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:03,657:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:35:03,657:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:35:03,657:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:35:03,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:03,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:03,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:03,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:03,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:03,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:04,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:04,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:04,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:04,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:04,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:04,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:05,054:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2023-11-23 14:35:05,054:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:05,054:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:35:05,054:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:35:05,054:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:35:05,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:05,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:05,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:05,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:05,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:05,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:05,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:05,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:05,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:05,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:06,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:06,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:06,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2023-11-23 14:35:06,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:06,467:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:35:06,467:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:35:06,467:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:35:06,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:06,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:06,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:06,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:06,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:06,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:06,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:06,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:07,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:07,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:07,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:07,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:07,869:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.
2023-11-23 14:35:07,869:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:07,869:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:35:07,869:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:35:07,869:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:35:07,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:08,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:08,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:08,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:08,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:08,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:08,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:08,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:08,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:08,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:08,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,284:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000476 seconds.
2023-11-23 14:35:09,284:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:09,284:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:35:09,285:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:35:09,285:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:35:09,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:09,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:10,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:10,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:10,703:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2023-11-23 14:35:10,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:10,703:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:35:10,703:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:35:10,703:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:35:10,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:10,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:11,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:11,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:11,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:11,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:11,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:11,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:11,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:11,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:11,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,118:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2023-11-23 14:35:12,118:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:12,118:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:35:12,118:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:35:12,119:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:35:12,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:12,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:13,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:13,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:13,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2023-11-23 14:35:13,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:13,517:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:35:13,517:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:35:13,517:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:35:13,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:13,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:13,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:13,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:13,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:13,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:14,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:14,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:14,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:14,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:14,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:14,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:14,905:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2023-11-23 14:35:14,905:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:14,905:INFO:[LightGBM] [Info] Total Bins 3213
2023-11-23 14:35:14,905:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:35:14,905:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:35:14,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:15,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:15,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:15,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:15,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:15,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:15,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:15,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:15,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:15,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:15,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,292:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-23 14:35:16,292:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:16,292:INFO:[LightGBM] [Info] Total Bins 3211
2023-11-23 14:35:16,292:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 8
2023-11-23 14:35:16,292:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:35:16,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:16,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:17,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:17,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:17,719:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2023-11-23 14:35:17,719:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:17,719:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:35:17,719:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:35:17,719:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:35:17,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:17,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:18,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:18,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:18,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:18,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:18,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:18,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:18,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:18,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:18,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,111:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000341 seconds.
2023-11-23 14:35:19,111:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:19,111:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:35:19,111:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:35:19,111:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:35:19,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:19,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:20,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:20,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:20,511:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2023-11-23 14:35:20,511:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:20,511:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:35:20,511:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:35:20,511:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:35:20,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:20,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:20,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:20,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:20,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:20,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:21,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:21,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:21,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:21,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:21,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:21,883:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000486 seconds.
2023-11-23 14:35:21,883:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:21,883:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:35:21,883:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:35:21,883:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:35:21,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:22,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:22,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:22,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:22,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:22,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:22,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:22,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:22,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:22,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:22,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,265:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.
2023-11-23 14:35:23,265:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:23,265:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:35:23,265:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:35:23,265:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:35:23,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:23,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:24,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:24,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:24,652:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2023-11-23 14:35:24,653:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:24,653:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:35:24,653:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:35:24,653:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:35:24,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:24,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:24,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:24,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:24,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:25,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:25,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:25,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:25,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:25,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:25,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:26,021:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2023-11-23 14:35:26,021:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:26,021:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:35:26,021:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:35:26,021:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:35:26,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:26,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:26,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:26,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:26,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:26,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:26,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:26,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:26,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:26,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:27,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:27,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:27,413:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000207 seconds.
2023-11-23 14:35:27,413:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:35:27,413:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:35:27,413:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:35:27,414:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:35:27,414:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:35:27,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:27,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:27,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:27,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:27,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:27,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:28,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:28,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:28,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:28,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:28,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:28,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:29,016:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.
2023-11-23 14:35:29,016:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:29,016:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:35:29,016:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:35:29,016:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:35:29,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:29,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:29,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:29,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:29,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:29,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:29,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:29,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:29,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:29,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:30,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:30,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:30,423:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.
2023-11-23 14:35:30,423:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:30,423:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:35:30,424:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:35:30,424:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:35:30,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:30,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:30,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:30,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:30,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:30,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:30,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:30,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:31,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:31,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:31,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:31,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:31,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000211 seconds.
2023-11-23 14:35:31,847:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:35:31,847:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:35:31,847:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:35:31,847:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:35:31,847:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:35:31,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:32,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:32,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:32,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:32,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:32,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:32,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:32,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:32,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:32,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:33,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:33,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:33,465:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.
2023-11-23 14:35:33,465:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:33,465:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:35:33,465:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:35:33,466:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:35:33,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:33,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:33,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:33,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:33,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:33,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:34,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:34,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:34,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:34,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:34,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:34,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:34,898:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.
2023-11-23 14:35:34,898:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:34,898:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:35:34,898:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:35:34,898:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:35:34,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:35,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:35,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:35,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:35,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:35,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:35,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:35,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:35,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:35,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:35,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,329:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2023-11-23 14:35:36,329:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:36,329:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:35:36,329:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:35:36,329:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:35:36,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:36,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:37,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:37,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:37,754:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
2023-11-23 14:35:37,754:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:37,754:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:35:37,754:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:35:37,754:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:35:37,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:38,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:38,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:38,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:38,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:38,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:38,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:38,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:38,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:38,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-23 14:35:39,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:39,187:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:35:39,187:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:35:39,187:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:35:39,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:39,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:40,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:40,622:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.
2023-11-23 14:35:40,622:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:40,622:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:35:40,622:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:35:40,623:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:35:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:40,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:40,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:40,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:40,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:41,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:41,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:41,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:41,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:41,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:41,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:42,061:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-11-23 14:35:42,061:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:42,061:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:35:42,061:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:35:42,061:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:35:42,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:42,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:42,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:42,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:42,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:42,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:42,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:42,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:42,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:42,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:43,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:43,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:43,481:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2023-11-23 14:35:43,481:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:43,481:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:35:43,481:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:35:43,481:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:35:43,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:43,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:43,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:43,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:43,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:43,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:44,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:44,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:44,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:44,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:44,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:44,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:44,908:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2023-11-23 14:35:44,908:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:44,908:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:35:44,909:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:35:44,909:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:35:44,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:45,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:45,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:45,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:45,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:45,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:45,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:45,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:45,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:45,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:46,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:46,339:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.
2023-11-23 14:35:46,339:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:46,339:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:35:46,339:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:35:46,339:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:35:46,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:46,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:46,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:46,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:46,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:46,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:46,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:47,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:47,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:47,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:47,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000393 seconds.
2023-11-23 14:35:47,743:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:47,743:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:35:47,743:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:35:47,743:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:35:47,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:48,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:48,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:48,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:48,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:48,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:48,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:48,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:48,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:48,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:48,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:49,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:49,202:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
2023-11-23 14:35:49,202:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:49,202:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:35:49,203:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:35:49,203:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:35:49,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:49,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:49,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:49,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:49,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:49,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:49,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:49,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:49,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:50,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:50,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:50,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:50,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.
2023-11-23 14:35:50,749:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:50,749:INFO:[LightGBM] [Info] Total Bins 3214
2023-11-23 14:35:50,749:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:35:50,749:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:35:50,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:51,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:51,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:51,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:51,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:51,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:51,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:51,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:51,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:51,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:51,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,162:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.
2023-11-23 14:35:52,162:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:52,162:INFO:[LightGBM] [Info] Total Bins 3212
2023-11-23 14:35:52,162:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:35:52,163:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:35:52,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:52,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:53,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:53,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:53,584:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.
2023-11-23 14:35:53,584:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:53,584:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:35:53,584:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:35:53,584:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:35:53,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:53,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:53,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:53,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:53,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:53,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:54,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:54,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:54,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:54,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:54,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:54,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:55,003:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.
2023-11-23 14:35:55,003:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:55,004:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:35:55,004:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:35:55,004:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:35:55,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:55,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:55,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:55,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:55,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:55,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:55,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:55,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:55,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:55,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:56,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:56,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:56,416:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000529 seconds.
2023-11-23 14:35:56,416:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:56,416:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:35:56,416:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:35:56,417:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:35:56,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:56,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:56,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:56,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:56,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:56,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:56,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:56,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:57,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:57,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:57,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:57,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:57,832:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.
2023-11-23 14:35:57,832:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:57,832:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:35:57,832:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:35:57,832:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:35:57,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:58,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:58,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:58,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:58,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:58,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:58,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:58,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:58,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:58,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:58,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,240:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.
2023-11-23 14:35:59,241:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:35:59,241:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:35:59,241:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:35:59,241:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:35:59,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:35:59,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:00,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:00,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:00,659:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000462 seconds.
2023-11-23 14:36:00,659:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:00,659:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:36:00,659:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:36:00,659:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:36:00,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:00,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:00,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:00,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:01,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:01,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:01,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:01,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:01,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:01,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:01,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:01,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:02,069:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2023-11-23 14:36:02,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:02,069:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:36:02,069:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:36:02,070:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:36:02,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:02,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:02,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:02,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:02,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:02,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:02,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:02,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:02,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:02,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:03,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:03,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:03,540:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000497 seconds.
2023-11-23 14:36:03,540:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:03,540:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:36:03,540:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:36:03,540:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:36:03,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:03,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:03,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:03,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:03,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:03,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:04,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:04,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:04,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:04,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:04,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:04,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:05,038:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-23 14:36:05,038:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:05,038:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:36:05,038:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:36:05,038:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:36:05,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:05,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:05,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:05,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:05,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:05,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:05,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:05,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:05,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:05,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:06,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:06,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:06,493:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
2023-11-23 14:36:06,493:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:06,493:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:36:06,493:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:36:06,493:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:36:06,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:06,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:06,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:06,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:06,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:06,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:07,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:07,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:07,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:07,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:07,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:07,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:07,928:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
2023-11-23 14:36:07,928:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:07,928:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:36:07,928:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:36:07,928:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:36:07,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:08,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:08,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:08,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:08,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:08,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:08,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:08,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:08,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:08,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:08,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:09,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:09,365:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000544 seconds.
2023-11-23 14:36:09,365:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:09,365:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:36:09,365:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:36:09,365:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:36:09,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:09,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:09,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:09,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:09,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:09,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:09,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:09,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:09,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:10,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:10,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:10,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:10,805:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.
2023-11-23 14:36:10,805:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:10,805:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:36:10,805:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:36:10,805:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:36:10,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:11,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:11,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:11,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:11,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:11,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:11,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:11,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:11,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:11,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:11,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,231:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2023-11-23 14:36:12,231:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:12,231:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:36:12,231:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:36:12,232:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:36:12,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:12,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:13,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:13,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:13,653:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000351 seconds.
2023-11-23 14:36:13,653:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:13,653:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:36:13,653:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 8
2023-11-23 14:36:13,653:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:36:13,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:13,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:13,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:13,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:14,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:14,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:14,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:14,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:14,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:14,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:14,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,103:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.
2023-11-23 14:36:15,103:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:15,103:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:36:15,103:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:36:15,103:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:36:15,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:15,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:16,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:16,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:16,551:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.
2023-11-23 14:36:16,551:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:16,551:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:36:16,551:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:36:16,551:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:36:16,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:16,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:16,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:16,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:16,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:16,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:17,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:17,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:17,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:17,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:17,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:17,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:18,008:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000466 seconds.
2023-11-23 14:36:18,008:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:18,008:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:36:18,009:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:36:18,009:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:36:18,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:18,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:18,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:18,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:18,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:18,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:18,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:18,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:18,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:18,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:19,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:19,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:19,430:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.
2023-11-23 14:36:19,430:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:19,430:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:36:19,430:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:36:19,431:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:36:19,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:19,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:19,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:19,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:19,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:19,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:19,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:19,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:20,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:20,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:20,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:20,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:20,847:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.
2023-11-23 14:36:20,847:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:20,847:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:36:20,847:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:36:20,847:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:36:20,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:21,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:21,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:21,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:21,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:21,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:21,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:21,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:21,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,302:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000373 seconds.
2023-11-23 14:36:22,302:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:22,302:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:36:22,303:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:36:22,303:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:36:22,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:22,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:23,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:23,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:23,799:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
2023-11-23 14:36:23,800:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:23,800:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:36:23,800:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:36:23,800:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:36:23,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:24,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:24,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:24,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:24,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:24,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:24,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:24,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:24,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:24,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,303:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-23 14:36:25,303:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:25,304:INFO:[LightGBM] [Info] Total Bins 3213
2023-11-23 14:36:25,304:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 9
2023-11-23 14:36:25,304:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:36:25,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:25,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:26,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:26,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:26,742:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2023-11-23 14:36:26,742:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:26,742:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:36:26,742:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:36:26,742:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:36:26,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:27,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:27,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:27,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:27,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:27,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:27,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:27,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:27,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:27,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:27,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,223:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000481 seconds.
2023-11-23 14:36:28,223:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:28,223:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:36:28,223:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:36:28,223:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:36:28,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:28,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:29,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:29,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:29,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000469 seconds.
2023-11-23 14:36:29,686:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:29,686:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:36:29,686:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:36:29,686:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:36:29,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:29,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:30,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:30,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:30,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:30,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:30,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:30,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:30,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:30,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:30,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,109:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
2023-11-23 14:36:31,109:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:31,109:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:36:31,109:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:36:31,109:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:36:31,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:31,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:32,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:32,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:32,524:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000442 seconds.
2023-11-23 14:36:32,524:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:32,524:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:36:32,524:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:36:32,524:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:36:32,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:32,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:32,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:32,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:32,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:32,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:33,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:33,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:33,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:33,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:33,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:33,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:33,947:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.
2023-11-23 14:36:33,947:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:33,947:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:36:33,947:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:36:33,947:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:36:33,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:34,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:34,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:34,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:34,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:34,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:34,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:34,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:34,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:34,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.
2023-11-23 14:36:35,362:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:35,362:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:36:35,362:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:36:35,362:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:36:35,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:35,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:36,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:36,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:36,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:36,785:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.
2023-11-23 14:36:36,785:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:36,785:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:36:36,785:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:36:36,785:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:36:36,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:37,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:37,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:37,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:37,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:37,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:37,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:37,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:37,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:37,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:37,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,198:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.
2023-11-23 14:36:38,198:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:38,198:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:36:38,198:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:36:38,198:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:36:38,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:38,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:39,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:39,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:39,617:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000475 seconds.
2023-11-23 14:36:39,617:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:39,617:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:36:39,617:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:36:39,618:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:36:39,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:39,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:39,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:39,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:39,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:39,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:40,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:40,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:40,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:40,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:40,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,126:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-23 14:36:41,126:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:41,126:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:36:41,126:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:36:41,126:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:36:41,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:41,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:42,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:42,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:42,555:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000474 seconds.
2023-11-23 14:36:42,555:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:42,555:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:36:42,555:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:36:42,556:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:36:42,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:42,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:42,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:42,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:42,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:42,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:43,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:43,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:43,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:43,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:43,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:43,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:43,990:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000309 seconds.
2023-11-23 14:36:43,990:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:43,990:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:36:43,990:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:36:43,990:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:36:44,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:44,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:44,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:44,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:44,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:44,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:44,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:44,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:44,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:44,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:45,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:45,474:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.
2023-11-23 14:36:45,474:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:45,474:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:36:45,474:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:36:45,474:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:36:45,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:45,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:45,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:45,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:45,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:45,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:46,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:46,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:46,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:46,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:46,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:46,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:46,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000458 seconds.
2023-11-23 14:36:46,924:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:46,924:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:36:46,924:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:36:46,924:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:36:46,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:47,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:47,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:47,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:47,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:47,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:47,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:47,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:47,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:48,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:48,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:48,392:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-11-23 14:36:48,392:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:48,392:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:36:48,392:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:36:48,392:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:36:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:48,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:48,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:48,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:48,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:48,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:48,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:48,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:49,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:49,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:49,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:49,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:49,846:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2023-11-23 14:36:49,846:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:49,846:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:36:49,846:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:36:49,847:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:36:49,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:50,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:50,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:50,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:50,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:50,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:50,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:50,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:50,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:50,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:50,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,306:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000845 seconds.
2023-11-23 14:36:51,306:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:51,306:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:36:51,306:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:36:51,307:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:36:51,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:51,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:52,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:52,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:52,769:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000418 seconds.
2023-11-23 14:36:52,769:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:52,769:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:36:52,769:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:36:52,769:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:36:52,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:53,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:53,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:53,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:53,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:53,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:53,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:53,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:53,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:53,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:53,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,249:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2023-11-23 14:36:54,250:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:54,250:INFO:[LightGBM] [Info] Total Bins 3214
2023-11-23 14:36:54,250:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:36:54,250:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:36:54,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:54,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:55,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:55,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:55,755:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
2023-11-23 14:36:55,755:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:55,756:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:36:55,756:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:36:55,756:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:36:55,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:56,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:56,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:56,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:56,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:56,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:56,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:56,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:56,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:56,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:56,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:57,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:57,279:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000225 seconds.
2023-11-23 14:36:57,279:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:36:57,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:36:57,279:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:36:57,279:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:36:57,279:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:36:57,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:57,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:57,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:57,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:57,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:57,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:57,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:58,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:58,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:58,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:58,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:58,957:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2023-11-23 14:36:58,957:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:36:58,957:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:36:58,957:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:36:58,957:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:36:58,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:59,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:59,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:59,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:59,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:59,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:59,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:59,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:59,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:36:59,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:00,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:00,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:00,394:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2023-11-23 14:37:00,394:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:00,394:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:37:00,394:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:37:00,394:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:37:00,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:00,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:00,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:00,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:00,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:00,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:00,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:00,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:01,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:01,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:01,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:01,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:01,815:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.
2023-11-23 14:37:01,815:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:01,815:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:37:01,815:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:37:01,815:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:37:01,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:02,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:02,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:02,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:02,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:02,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:02,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:02,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:02,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:02,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:02,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,274:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2023-11-23 14:37:03,274:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:03,274:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:37:03,274:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:37:03,274:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:37:03,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:03,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:04,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:04,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:04,794:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2023-11-23 14:37:04,794:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:04,794:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:37:04,794:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:37:04,795:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:37:04,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:05,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:05,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:05,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:05,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:05,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:05,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:05,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:05,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:05,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,273:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000382 seconds.
2023-11-23 14:37:06,273:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:06,273:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:37:06,273:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:37:06,274:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:37:06,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:06,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:07,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:07,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:07,872:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2023-11-23 14:37:07,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:07,872:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:37:07,873:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:37:07,873:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:37:07,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:08,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:08,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:08,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:08,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:08,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:08,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:08,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:08,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:08,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:09,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:09,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:09,430:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.
2023-11-23 14:37:09,430:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:09,430:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:37:09,430:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:37:09,431:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:37:09,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:09,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:09,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:09,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:09,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:09,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:10,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:10,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:10,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:10,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:10,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:10,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:10,994:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.
2023-11-23 14:37:10,994:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:10,994:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:37:10,995:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:37:10,995:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:37:11,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:11,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:11,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:11,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:11,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:11,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:11,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:11,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:11,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:11,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:12,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:12,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:12,525:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2023-11-23 14:37:12,525:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:12,525:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:37:12,525:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 9
2023-11-23 14:37:12,525:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:37:12,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:12,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:12,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:12,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:12,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:12,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:13,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:13,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:13,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:13,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:13,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:13,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:14,012:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.
2023-11-23 14:37:14,012:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:14,012:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:37:14,012:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:37:14,013:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:37:14,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:14,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:14,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:14,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:14,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:14,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:14,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:14,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:14,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:14,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:15,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:15,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:15,443:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-11-23 14:37:15,443:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:15,443:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:37:15,443:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:37:15,444:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:37:15,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:15,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:15,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:15,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:15,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:15,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:15,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:15,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:16,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:16,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:16,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:16,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:16,887:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.
2023-11-23 14:37:16,887:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:16,887:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:37:16,887:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:37:16,887:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:37:16,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:17,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:17,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:17,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:17,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:17,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:17,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:17,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:17,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:17,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:17,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,308:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000267 seconds.
2023-11-23 14:37:18,308:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:18,308:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:37:18,308:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:37:18,308:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:37:18,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:18,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:19,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:19,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:19,732:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.
2023-11-23 14:37:19,732:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:19,732:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:37:19,732:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:37:19,732:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:37:19,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:20,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:20,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:20,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:20,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:20,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:20,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:20,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:20,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:20,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:20,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,144:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.
2023-11-23 14:37:21,144:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:21,144:INFO:[LightGBM] [Info] Total Bins 3215
2023-11-23 14:37:21,144:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 10
2023-11-23 14:37:21,144:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:37:21,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:21,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:22,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:22,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:22,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2023-11-23 14:37:22,534:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:22,534:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:37:22,534:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:37:22,534:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:37:22,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:22,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:22,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:22,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:22,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:22,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:23,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:23,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:23,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:23,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:23,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:23,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:23,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000225 seconds.
2023-11-23 14:37:23,919:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:37:23,919:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:37:23,919:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:37:23,920:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:37:23,920:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:37:23,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:24,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:24,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:24,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:24,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:24,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:24,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:24,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:24,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:24,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:25,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:25,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:25,527:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2023-11-23 14:37:25,527:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:25,527:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:37:25,527:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:37:25,528:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:37:25,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:25,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:25,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:25,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:25,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:25,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:26,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:26,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:26,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:26,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:26,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:26,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:26,939:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.
2023-11-23 14:37:26,940:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:26,940:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:37:26,940:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:37:26,940:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:37:26,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:27,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:27,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:27,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:27,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:27,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:27,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:27,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:27,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:27,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:27,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:28,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:28,352:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2023-11-23 14:37:28,352:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:28,352:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:37:28,352:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:37:28,352:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:37:28,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:28,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:28,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:28,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:28,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:28,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:28,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:28,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:28,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:29,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:29,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:29,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:29,758:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.
2023-11-23 14:37:29,758:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:29,759:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:37:29,759:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:37:29,759:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:37:29,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:30,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:30,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:30,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:30,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:30,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:30,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:30,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:30,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:30,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:30,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,157:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000391 seconds.
2023-11-23 14:37:31,157:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:31,157:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:37:31,157:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:37:31,157:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:37:31,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:31,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:32,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:32,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:32,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-23 14:37:32,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:32,543:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:37:32,543:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:37:32,544:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:37:32,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:32,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:32,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:32,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:32,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:32,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:33,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:33,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:33,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:33,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:33,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:33,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:33,944:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.
2023-11-23 14:37:33,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:33,945:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:37:33,945:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:37:33,945:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:37:33,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:34,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:34,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:34,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:34,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:34,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:34,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:34,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:34,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:34,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,364:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2023-11-23 14:37:35,364:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:35,364:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:37:35,364:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:37:35,364:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:37:35,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:35,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:36,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:36,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:36,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:36,773:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000441 seconds.
2023-11-23 14:37:36,773:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:36,773:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:37:36,773:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:37:36,774:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:37:36,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:37,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:37,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:37,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:37,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:37,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:37,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:37,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:37,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:37,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:37,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,169:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000471 seconds.
2023-11-23 14:37:38,170:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:38,170:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:37:38,170:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:37:38,170:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:37:38,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:38,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:39,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:39,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:39,570:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
2023-11-23 14:37:39,570:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:39,570:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:37:39,570:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:37:39,570:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:37:39,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:39,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:39,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:39,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:39,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:39,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:40,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:40,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:40,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:40,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:40,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:40,964:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.
2023-11-23 14:37:40,964:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:40,964:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:37:40,965:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:37:40,965:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:37:40,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:41,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:41,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:41,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:41,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:41,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:41,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:41,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:41,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:41,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:42,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:42,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
2023-11-23 14:37:42,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:42,356:INFO:[LightGBM] [Info] Total Bins 3216
2023-11-23 14:37:42,356:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:37:42,356:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:37:42,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:42,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:42,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:42,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:42,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:42,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:42,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:42,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:42,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:43,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:43,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:43,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:43,770:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.
2023-11-23 14:37:43,770:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:43,770:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:37:43,770:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:37:43,770:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:37:43,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:44,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:44,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:44,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:44,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:44,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:44,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:44,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:44,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:44,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:44,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,212:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000195 seconds.
2023-11-23 14:37:45,212:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 14:37:45,212:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 14:37:45,213:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:37:45,213:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:37:45,213:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:37:45,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:45,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:46,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:46,825:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.
2023-11-23 14:37:46,825:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:46,825:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:37:46,825:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:37:46,825:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:37:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:47,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:47,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:47,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:47,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:47,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:47,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:47,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:47,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,273:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.
2023-11-23 14:37:48,273:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:48,273:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:37:48,273:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:37:48,273:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:37:48,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:48,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:49,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:49,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:49,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.
2023-11-23 14:37:49,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:49,724:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:37:49,724:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:37:49,725:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:37:49,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:49,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:50,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:50,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:50,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:50,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:50,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:50,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:50,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:50,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:50,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,155:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-23 14:37:51,155:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:51,155:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:37:51,155:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:37:51,155:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:37:51,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:51,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:52,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:52,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:52,770:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000755 seconds.
2023-11-23 14:37:52,770:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:52,770:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:37:52,770:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:37:52,771:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:37:52,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:53,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:53,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:53,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:53,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:53,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:53,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:53,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:53,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:53,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:53,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:54,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:54,316:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000384 seconds.
2023-11-23 14:37:54,316:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:54,316:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:37:54,316:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:37:54,316:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:37:54,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:54,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:54,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:54,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:54,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:54,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:54,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:54,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:54,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:55,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:55,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:55,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:55,828:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000619 seconds.
2023-11-23 14:37:55,828:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:55,828:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:37:55,828:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 10
2023-11-23 14:37:55,829:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:37:55,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:56,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:56,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:56,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:56,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:56,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:56,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:56,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:56,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:56,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:56,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:57,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:57,352:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000363 seconds.
2023-11-23 14:37:57,352:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:57,352:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:37:57,352:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:37:57,352:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:37:57,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:57,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:57,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:57,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:57,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:57,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:57,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:57,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:58,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:58,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:58,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:58,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:58,865:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2023-11-23 14:37:58,865:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:37:58,865:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:37:58,865:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:37:58,865:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:37:58,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:59,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:59,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:59,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:59,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:59,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:59,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:59,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:59,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:59,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:37:59,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:00,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:00,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000443 seconds.
2023-11-23 14:38:00,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:00,376:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:38:00,376:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:38:00,376:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:38:00,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:00,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:00,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:00,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:00,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:00,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:00,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:00,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:01,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:01,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:01,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:01,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:01,896:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000598 seconds.
2023-11-23 14:38:01,896:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:01,896:INFO:[LightGBM] [Info] Total Bins 3217
2023-11-23 14:38:01,897:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 11
2023-11-23 14:38:01,897:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:38:01,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:02,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:02,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:02,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:02,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:02,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:02,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:02,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:02,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:02,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:03,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:03,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:03,438:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.
2023-11-23 14:38:03,438:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:03,438:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:38:03,439:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:03,439:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:38:03,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:03,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:03,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:03,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:03,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:03,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:03,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:03,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:04,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:04,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:04,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:04,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:04,926:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.
2023-11-23 14:38:04,926:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:04,926:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:38:04,926:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:38:04,927:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:38:04,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:05,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:05,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:05,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:05,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:05,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:05,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:05,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:05,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:05,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:06,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:06,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:06,404:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.
2023-11-23 14:38:06,404:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:06,405:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:38:06,405:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:06,405:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:38:06,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:06,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:06,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:06,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:06,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:06,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:06,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:06,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:07,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:07,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:07,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:07,854:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.
2023-11-23 14:38:07,855:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:07,855:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:38:07,855:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:38:07,855:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:38:07,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:08,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:08,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:08,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:08,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:08,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:08,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:08,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:08,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:08,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:08,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:09,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:09,304:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.
2023-11-23 14:38:09,304:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:09,304:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:38:09,304:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:09,304:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:38:09,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:09,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:09,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:09,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:09,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:09,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:09,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:09,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:10,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:10,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:10,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:10,849:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.
2023-11-23 14:38:10,849:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:10,850:INFO:[LightGBM] [Info] Total Bins 3222
2023-11-23 14:38:10,850:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:38:10,850:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:38:10,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:11,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:11,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:11,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:11,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:11,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:11,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:11,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:11,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:11,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:11,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:12,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:12,340:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.
2023-11-23 14:38:12,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:12,341:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:38:12,341:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:12,341:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:38:12,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:12,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:12,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:12,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:12,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:12,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:12,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:12,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:12,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:13,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:13,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:13,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:13,792:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000488 seconds.
2023-11-23 14:38:13,792:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:13,792:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:38:13,793:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:38:13,793:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:38:13,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:14,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:14,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:14,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:14,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:14,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:14,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:14,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:14,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:14,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:14,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,255:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000531 seconds.
2023-11-23 14:38:15,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:15,255:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:38:15,255:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:15,256:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:38:15,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:15,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:16,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:16,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:16,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.
2023-11-23 14:38:16,712:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:16,712:INFO:[LightGBM] [Info] Total Bins 3218
2023-11-23 14:38:16,712:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:38:16,712:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:38:16,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:16,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:17,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:17,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:17,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:17,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:17,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:17,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:17,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:17,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:17,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,169:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.
2023-11-23 14:38:18,169:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:18,169:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:38:18,170:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:18,170:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:38:18,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:18,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:19,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:19,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:19,657:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.
2023-11-23 14:38:19,657:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:19,657:INFO:[LightGBM] [Info] Total Bins 3221
2023-11-23 14:38:19,658:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:38:19,658:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:38:19,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:19,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:19,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:19,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:20,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:20,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:20,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:20,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:20,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:20,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:20,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,145:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.
2023-11-23 14:38:21,145:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:21,145:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:38:21,145:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:21,145:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:38:21,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:21,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:22,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:22,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:22,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.
2023-11-23 14:38:22,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:22,649:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:38:22,649:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:38:22,649:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:38:22,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:22,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:22,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:22,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:23,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:23,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:23,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:23,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:23,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:23,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:23,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,088:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.
2023-11-23 14:38:24,088:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:24,088:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:38:24,089:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:24,089:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:38:24,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:24,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:25,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:25,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:25,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000431 seconds.
2023-11-23 14:38:25,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:25,558:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:38:25,558:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 11
2023-11-23 14:38:25,558:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:38:25,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:25,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:25,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:25,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:25,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:25,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:26,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:26,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:26,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:26,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:26,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:26,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:26,989:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-23 14:38:26,989:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:26,989:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:38:26,989:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:38:26,990:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 14:38:27,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:27,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:27,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:27,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:27,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:27,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:27,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:27,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:27,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:27,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:28,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:28,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:28,424:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.
2023-11-23 14:38:28,424:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:28,424:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 14:38:28,424:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 14:38:28,425:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 14:38:28,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:28,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:28,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:28,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:28,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:28,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:28,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:28,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:29,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:29,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:29,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:29,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:29,910:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.
2023-11-23 14:38:29,910:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:29,910:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:38:29,911:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:29,911:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 14:38:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:30,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:30,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:30,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:30,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:30,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:30,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:30,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:30,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:30,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:31,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:31,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:31,508:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000464 seconds.
2023-11-23 14:38:31,508:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:31,508:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:38:31,508:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:31,508:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 14:38:31,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:31,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:31,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:31,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:31,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:31,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:32,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:32,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:32,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:32,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:32,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:32,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:33,069:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.
2023-11-23 14:38:33,069:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:33,069:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 14:38:33,069:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:33,069:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 14:38:33,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:33,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:33,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:33,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:33,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:33,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:33,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:33,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:33,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:33,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:34,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:34,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:34,660:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.
2023-11-23 14:38:34,660:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:34,660:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:38:34,660:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:34,661:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 14:38:34,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:34,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:34,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:35,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:35,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:35,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:35,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:35,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:35,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:35,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:35,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,171:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.
2023-11-23 14:38:36,172:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:36,172:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 14:38:36,172:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:36,172:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 14:38:36,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:36,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:37,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:37,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:37,660:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000487 seconds.
2023-11-23 14:38:37,660:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:37,660:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:38:37,661:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:37,661:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 14:38:37,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:37,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:38,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:38,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:38,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:38,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:38,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:38,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:38,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:38,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,155:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.
2023-11-23 14:38:39,156:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:39,156:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:38:39,156:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:39,156:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 14:38:39,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:39,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:40,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:40,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:40,681:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000355 seconds.
2023-11-23 14:38:40,681:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:40,681:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:38:40,681:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 14:38:40,681:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 14:38:40,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:40,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:41,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:41,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:41,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:41,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:41,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:41,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:41,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:41,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:41,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,186:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-23 14:38:42,186:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:42,186:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 14:38:42,186:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 14:38:42,187:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 14:38:42,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:42,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:43,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:43,809:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.
2023-11-23 14:38:43,809:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:43,809:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 14:38:43,809:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 11
2023-11-23 14:38:43,809:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 14:38:43,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:44,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:44,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:44,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:44,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:44,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:44,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:44,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:44,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:44,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:44,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:45,406:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000516 seconds.
2023-11-23 14:38:45,406:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:45,406:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 14:38:45,406:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 10
2023-11-23 14:38:45,406:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 14:38:45,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:45,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:45,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:45,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:45,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:45,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:45,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:45,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:46,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:46,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:46,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:46,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:46,931:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.
2023-11-23 14:38:46,931:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:46,931:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 14:38:46,931:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 9
2023-11-23 14:38:46,931:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 14:38:46,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:47,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:47,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:47,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:47,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:47,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:47,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:47,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:47,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:47,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:48,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:48,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:48,385:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000390 seconds.
2023-11-23 14:38:48,385:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 14:38:48,385:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 14:38:48,385:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 8
2023-11-23 14:38:48,385:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 14:38:48,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:48,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:48,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:48,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:48,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:48,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:48,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:48,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:49,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:49,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:49,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:49,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 14:38:49,971:INFO:Visual Rendered Successfully
2023-11-23 14:38:50,096:INFO:plot_model() successfully completed......................................
2023-11-23 14:53:15,838:INFO:Initializing predict_model()
2023-11-23 14:53:15,839:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x2890fb670>)
2023-11-23 14:53:15,839:INFO:Checking exceptions
2023-11-23 14:53:15,839:INFO:Preloading libraries
2023-11-23 15:11:13,046:INFO:Initializing create_model()
2023-11-23 15:11:13,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))]), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 15:11:13,047:INFO:Checking exceptions
2023-11-23 15:11:13,082:INFO:Importing libraries
2023-11-23 15:11:13,084:INFO:Copying training dataset
2023-11-23 15:11:13,099:INFO:Defining folds
2023-11-23 15:11:13,100:INFO:Declaring metric variables
2023-11-23 15:11:13,101:INFO:Importing untrained model
2023-11-23 15:11:13,102:INFO:Declaring custom model
2023-11-23 15:11:13,105:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 15:11:13,110:INFO:Starting cross validation
2023-11-23 15:11:13,111:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 15:11:15,016:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:15,016:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:15,016:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:15,017:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:15,018:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:15,019:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001320 seconds.
2023-11-23 15:11:15,019:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 15:11:15,019:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001483 seconds.
2023-11-23 15:11:15,019:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 15:11:15,019:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 15:11:15,019:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000616 seconds.
2023-11-23 15:11:15,019:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 15:11:15,020:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 15:11:15,020:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 15:11:15,020:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 15:11:15,020:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 15:11:15,020:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 15:11:15,020:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 15:11:15,021:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 15:11:15,021:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 15:11:15,021:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 15:11:15,021:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001390 seconds.
2023-11-23 15:11:15,021:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 15:11:15,021:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 15:11:15,022:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004057 seconds.
2023-11-23 15:11:15,022:INFO:You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 15:11:15,022:INFO:
2023-11-23 15:11:15,022:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 15:11:15,022:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 15:11:15,023:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 15:11:15,024:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 15:11:15,038:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:15,039:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.
2023-11-23 15:11:15,039:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 15:11:15,039:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 15:11:15,040:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 15:11:15,040:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 15:11:15,040:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:15,041:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000688 seconds.
2023-11-23 15:11:15,041:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 15:11:15,041:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 15:11:15,042:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 15:11:15,042:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 15:11:15,065:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:15,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000830 seconds.
2023-11-23 15:11:15,067:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 15:11:15,067:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 15:11:15,067:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 15:11:15,067:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 15:11:15,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:15,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:15,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:15,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:15,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:15,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:15,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:15,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:16,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:16,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:16,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:16,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:16,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:17,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:18,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:19,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:20,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:20,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:20,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:20,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:21,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:21,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:21,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:21,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:22,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:22,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:22,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:22,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:23,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:23,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:23,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:24,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:24,250:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:24,252:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.
2023-11-23 15:11:24,252:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 15:11:24,252:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 15:11:24,252:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 15:11:24,252:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 15:11:24,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:24,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:24,347:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:24,350:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002086 seconds.
2023-11-23 15:11:24,350:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 15:11:24,350:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 15:11:24,350:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 15:11:24,351:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 15:11:24,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:24,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:24,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:24,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:25,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:26,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:26,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:26,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:26,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:26,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,219:INFO:Calculating mean and std
2023-11-23 15:11:27,220:INFO:Creating metrics dataframe
2023-11-23 15:11:27,226:INFO:Finalizing model
2023-11-23 15:11:27,241:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 15:11:27,243:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000835 seconds.
2023-11-23 15:11:27,243:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 15:11:27,243:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 15:11:27,243:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 15:11:27,244:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 15:11:27,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:27,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:28,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 15:11:28,766:INFO:Uploading results into container
2023-11-23 15:11:28,767:INFO:Uploading model into container now
2023-11-23 15:11:28,775:INFO:_master_model_container: 29
2023-11-23 15:11:28,775:INFO:_display_container: 16
2023-11-23 15:11:28,800:INFO:Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))])
2023-11-23 15:11:28,801:INFO:create_model() successfully completed......................................
2023-11-23 16:02:30,946:INFO:Initializing predict_model()
2023-11-23 16:02:30,947:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x281d390d0>)
2023-11-23 16:02:30,947:INFO:Checking exceptions
2023-11-23 16:02:30,947:INFO:Preloading libraries
2023-11-23 16:02:30,954:INFO:Set up data.
2023-11-23 16:02:30,984:INFO:Set up index.
2023-11-23 16:54:25,255:INFO:Initializing create_model()
2023-11-23 16:54:25,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=lightgbm, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 16:54:25,256:INFO:Checking exceptions
2023-11-23 16:54:25,273:INFO:Importing libraries
2023-11-23 16:54:25,273:INFO:Copying training dataset
2023-11-23 16:54:25,278:INFO:Defining folds
2023-11-23 16:54:25,279:INFO:Declaring metric variables
2023-11-23 16:54:25,280:INFO:Importing untrained model
2023-11-23 16:54:25,282:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 16:54:25,285:INFO:Cross validation set to False
2023-11-23 16:54:25,285:INFO:Fitting Model
2023-11-23 16:54:25,489:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:54:25,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.
2023-11-23 16:54:25,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 16:54:25,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 16:54:25,493:INFO:[LightGBM] [Info] Total Bins 1844
2023-11-23 16:54:25,494:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 16:54:25,494:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 16:54:25,873:INFO:Initializing predict_model()
2023-11-23 16:54:25,873:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x281b04940>)
2023-11-23 16:54:25,873:INFO:Checking exceptions
2023-11-23 16:54:25,873:INFO:Preloading libraries
2023-11-23 16:54:25,976:INFO:_display_container: 18
2023-11-23 16:54:25,976:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2023-11-23 16:54:25,976:INFO:create_model() successfully completed......................................
2023-11-23 16:54:26,044:INFO:Initializing create_model()
2023-11-23 16:54:26,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=rf, fold=None, round=4, cross_validation=False, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 16:54:26,045:INFO:Checking exceptions
2023-11-23 16:54:26,051:INFO:Importing libraries
2023-11-23 16:54:26,051:INFO:Copying training dataset
2023-11-23 16:54:26,056:INFO:Defining folds
2023-11-23 16:54:26,056:INFO:Declaring metric variables
2023-11-23 16:54:26,058:INFO:Importing untrained model
2023-11-23 16:54:26,061:INFO:Random Forest Regressor Imported successfully
2023-11-23 16:54:26,078:INFO:Cross validation set to False
2023-11-23 16:54:26,078:INFO:Fitting Model
2023-11-23 16:54:26,623:INFO:Initializing predict_model()
2023-11-23 16:54:26,623:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x282f20dc0>)
2023-11-23 16:54:26,623:INFO:Checking exceptions
2023-11-23 16:54:26,623:INFO:Preloading libraries
2023-11-23 16:54:26,719:INFO:_display_container: 19
2023-11-23 16:54:26,719:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2023-11-23 16:54:26,719:INFO:create_model() successfully completed......................................
2023-11-23 16:57:13,382:INFO:Initializing create_model()
2023-11-23 16:57:13,383:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x2891f8520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))]), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-23 16:57:13,383:INFO:Checking exceptions
2023-11-23 16:57:13,396:INFO:Importing libraries
2023-11-23 16:57:13,397:INFO:Copying training dataset
2023-11-23 16:57:13,402:INFO:Defining folds
2023-11-23 16:57:13,402:INFO:Declaring metric variables
2023-11-23 16:57:13,405:INFO:Importing untrained model
2023-11-23 16:57:13,405:INFO:Declaring custom model
2023-11-23 16:57:13,408:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-23 16:57:13,411:INFO:Starting cross validation
2023-11-23 16:57:13,412:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-23 16:57:15,442:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:15,449:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:15,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005945 seconds.
2023-11-23 16:57:15,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 16:57:15,450:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 16:57:15,451:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:15,451:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:15,451:INFO:
2023-11-23 16:57:15,452:INFO:[LightGBM] [Info] Start training from score 186511.945832
2023-11-23 16:57:15,453:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002584 seconds.
2023-11-23 16:57:15,454:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 16:57:15,454:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 16:57:15,455:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 16:57:15,459:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004598 seconds.
2023-11-23 16:57:15,459:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 16:57:15,460:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 16:57:15,460:INFO:[LightGBM] [Info] Start training from score 186785.260970
2023-11-23 16:57:15,460:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.
2023-11-23 16:57:15,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-23 16:57:15,460:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-23 16:57:15,460:INFO:[LightGBM] [Info] Total Bins 3220
2023-11-23 16:57:15,460:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 16:57:15,460:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 16:57:15,461:INFO:[LightGBM] [Info] Start training from score 186669.682763
2023-11-23 16:57:15,462:INFO:[LightGBM] [Info] Start training from score 186407.811424
2023-11-23 16:57:15,465:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:15,465:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:15,466:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:15,468:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002020 seconds.
2023-11-23 16:57:15,468:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 16:57:15,468:INFO:[LightGBM] [Info] Total Bins 3223
2023-11-23 16:57:15,468:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 16:57:15,468:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002231 seconds.
2023-11-23 16:57:15,468:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 16:57:15,469:INFO:[LightGBM] [Info] Total Bins 3229
2023-11-23 16:57:15,469:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 16:57:15,470:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002645 seconds.
2023-11-23 16:57:15,470:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 16:57:15,470:INFO:[LightGBM] [Info] Total Bins 3224
2023-11-23 16:57:15,470:INFO:[LightGBM] [Info] Start training from score 186812.869830
2023-11-23 16:57:15,470:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 16:57:15,471:INFO:[LightGBM] [Info] Start training from score 186508.250682
2023-11-23 16:57:15,471:INFO:[LightGBM] [Info] Start training from score 187045.748058
2023-11-23 16:57:15,471:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:15,473:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001430 seconds.
2023-11-23 16:57:15,473:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 16:57:15,473:INFO:[LightGBM] [Info] Total Bins 3219
2023-11-23 16:57:15,474:INFO:[LightGBM] [Info] Number of data points in the train set: 4762, number of used features: 12
2023-11-23 16:57:15,474:INFO:[LightGBM] [Info] Start training from score 186387.273835
2023-11-23 16:57:15,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:15,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:15,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:15,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:15,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:15,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:15,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:15,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:16,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:17,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:18,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:19,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:20,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:21,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:22,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:22,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:22,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:22,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:22,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:22,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:23,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:23,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:24,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:24,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:24,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:24,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:24,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:24,639:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:24,641:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000964 seconds.
2023-11-23 16:57:24,641:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 16:57:24,641:INFO:[LightGBM] [Info] Total Bins 3225
2023-11-23 16:57:24,641:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 16:57:24,642:INFO:[LightGBM] [Info] Start training from score 186319.756036
2023-11-23 16:57:24,864:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:24,865:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000993 seconds.
2023-11-23 16:57:24,865:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 16:57:24,866:INFO:[LightGBM] [Info] Total Bins 3227
2023-11-23 16:57:24,866:INFO:[LightGBM] [Info] Number of data points in the train set: 4763, number of used features: 12
2023-11-23 16:57:24,866:INFO:[LightGBM] [Info] Start training from score 186105.185387
2023-11-23 16:57:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:24,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:25,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:26,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:26,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:26,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:26,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:26,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:26,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:26,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:26,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:26,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:27,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:27,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:27,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:27,602:INFO:Calculating mean and std
2023-11-23 16:57:27,604:INFO:Creating metrics dataframe
2023-11-23 16:57:27,609:INFO:Finalizing model
2023-11-23 16:57:27,648:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-11-23 16:57:27,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.
2023-11-23 16:57:27,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-23 16:57:27,650:INFO:[LightGBM] [Info] Total Bins 3231
2023-11-23 16:57:27,651:INFO:[LightGBM] [Info] Number of data points in the train set: 5292, number of used features: 12
2023-11-23 16:57:27,651:INFO:[LightGBM] [Info] Start training from score 186555.385110
2023-11-23 16:57:27,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:27,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:27,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:27,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:28,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:28,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:28,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:28,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:28,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:28,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:29,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-23 16:57:29,114:INFO:Uploading results into container
2023-11-23 16:57:29,115:INFO:Uploading model into container now
2023-11-23 16:57:29,122:INFO:_master_model_container: 30
2023-11-23 16:57:29,122:INFO:_display_container: 20
2023-11-23 16:57:29,150:INFO:Pipeline(memory=Memory(location=None),
         steps=[('custom_step',
                 TransformerWrapper(transformer=Pipeline(steps=[('feature_engineering',
                                                                 Pipeline(steps=[('preprocessor',
                                                                                  ColumnTransformer(remainder='passthrough',
                                                                                                    transformers=[('num',
                                                                                                                   RobustScaler(),
                                                                                                                   ['housing_median_age',
                                                                                                                    'total_rooms',
                                                                                                                    'total_bedrooms',
                                                                                                                    'population',
                                                                                                                    'households',
                                                                                                                    'median_income']),
                                                                                                                  ('One '
                                                                                                                   'Hot',
                                                                                                                   OneHotEncoder(handle_unknown='ignore'),
                                                                                                                   ['ocean_proximity'])]))]))]))),
                ('actual_estimator',
                 LGBMRegressor(boosting_type='dart', colsample_bytree=0.9,
                               max_bin=455, min_child_samples=30,
                               n_estimators=200, n_jobs=-1, num_leaves=75,
                               random_state=123, reg_alpha=1, reg_lambda=1,
                               subsample=0.9))])
2023-11-23 16:57:29,150:INFO:create_model() successfully completed......................................
